{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a9a70a7-067a-4a57-a211-98735d229fac",
   "metadata": {},
   "source": [
    "<h1>Final Project: Financial Analysis</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4829289c-d38c-4c23-bb9e-d84b3d75f7ca",
   "metadata": {},
   "source": [
    "# Table of Contents <a id='back'></a>\n",
    "\n",
    "* [Introduction](#intro)\n",
    "* [1. Data preprocessing](#data_preprocessing)\n",
    "    * [1.1. Table dim_customer](#dim_customer)\n",
    "        * [Conclusion](#conclusion_1)\n",
    "    * [1.2. Table dim_product](#dim_product)\n",
    "        * [Conclusion](#conclusion_2)\n",
    "    * [1.3. Table fact_pre_discount](#fact_pre_discount)\n",
    "        * [Conclusion](#conclusion_3)\n",
    "    * [1.4. Table fact_manufacturing_cost](#fact_manufacturing_cost)\n",
    "        * [Conclusion](#conclusion_4)\n",
    "    * [1.5. Table fact_gross_price](#fact_gross_price)\n",
    "        * [Conclusion](#conclusion_5)\n",
    "    * [1.6. Table fact_sales_monthly](#fact_sales_monthly)\n",
    "        * [Table overview](#table_overview)\n",
    "        * [Data types](#data_types)\n",
    "        * [Missing and duplicate values](#missing_duplicate)\n",
    "        * [Conclusion](#conclusion_6)\n",
    "    * [Data summary](#summary_1)\n",
    "* [2. EDA](#eda)\n",
    "    * [2.1. Table dim_customer](#eda_customer)\n",
    "        * [Conclusion](#conclusion_7)\n",
    "    * [2.2. Table dim_product](#eda_product)\n",
    "        * [Conclusion](#conclusion_8)\n",
    "    * [2.3. Table fact_pre_discount](#eda_discount)\n",
    "        * [Conclusion](#conclusion_9)\n",
    "    * [2.4. Table fact_manufacturing_cost](#eda_manufacture_cost)\n",
    "        * [Conclusion](#conclusion_10)\n",
    "    * [2.5. Table fact_gross_price](#eda_gross_price)\n",
    "        * [Conclusion](#conclusion_11)\n",
    "    * [2.6. Table fact_sales_monthly](#eda_sales)\n",
    "        * [Unique customers and years range](#customers_years)\n",
    "        * [Unique products, regions and markets](#unique_products_regions)\n",
    "        * [Sold quantities](#sold_quantity)\n",
    "        * [Conclusion](#conclusion_12)\n",
    "    * [EDA summary](#summary_2)\n",
    "* [3. Financial analysis](#analysis)\n",
    "    * [3.1. Revenue](#revenue)\n",
    "        * [3.1.1. Gross revenue](#gross_revenue)\n",
    "            * [Total gross revenue](#total_gross_revenue)\n",
    "            * [Gross revenue per year](#gross_revenue_per_year)\n",
    "            * [Gross revenue growth rate](#gross_revenue_growth_rate)\n",
    "            * [Gross revenue per region](#gross_revenue_per_region)\n",
    "            * [Gross revenue per region over time](#gross_revenue_per_region_year)\n",
    "            * [Conclusion](#conclusion_13)\n",
    "        * [3.1.2. Net revenue](#net_revenue)\n",
    "            * [Total net revenue](#total_net_revenue)\n",
    "            * [Net revenue per year](#net_revenue_per_year)\n",
    "            * [Net revenue growth rate](#net_revenue_growth_rate)\n",
    "            * [Net revenue per region](#net_revenue_per_region)\n",
    "            * [Net revenue per region over time](#net_revenue_per_region_year)\n",
    "            * [Conclusion](#conclusion_14)\n",
    "    * [3.2. Gross profit](#gross_profit)\n",
    "        * [Total gross profit](#total_gross_profit)\n",
    "        * [Gross profit per year](#gross_profit_per_year)\n",
    "        * [Gross profit vs revenues per year](#profit_revenues_year)\n",
    "        * [Gross profit per region](#gross_profit_per_region)\n",
    "        * [Gross profit vs revenues per region](#profit_revenues_region)\n",
    "        * [Gross profit per region over time](#gross_profit_per_region_year)\n",
    "        * [Conclusion](#conclusion_15)\n",
    "    * [3.3. Gross margin](#gross_margin)\n",
    "        * [Total gross margin](#total_gross_margin)\n",
    "        * [Gross margin per year](#gross_margin_per_year)\n",
    "        * [Gross margin per regional segment](#gross_margin_per_region)\n",
    "        * [Gross margin per region over time](#gross_margin_per_region_year)\n",
    "        * [Gross margin decline in 2020 and 2021](#gross_margin_decline)\n",
    "        * [Conclusion](#conclusion_16)\n",
    "    * [Financial analysis summary](#summary_3)\n",
    "* [4. Hypothesis testing](#hypothesis)\n",
    "    * [4.1. Data preparation](#data_preparation)\n",
    "        * [EDA](#data_preparation_eda)\n",
    "        * [Outliers and normality](#data_preparation_outliers)\n",
    "        * [Conclusion](#conclusion_17)\n",
    "    * [4.2. Statistical test 1: average gross margin](#statistical_test_1)\n",
    "        * [Data aggregation](#data_preparation_aggregation)\n",
    "        * [Case 1: biggest difference in manufacturing costs](#case_2018_2022)\n",
    "            * [raw data](#case_2018_2022_raw)\n",
    "            * [clean data](#case_2018_2022_clean)\n",
    "        * [Case 2: difference in gross margins](#case_2018_2019)\n",
    "            * [raw data](#case_2018_2019_raw)\n",
    "            * [clean data](#case_2018_2019_clean)\n",
    "        * [Case 3: equal sample sizes](#case_2020_2021)\n",
    "            * [raw data](#case_2020_2021_raw)\n",
    "            * [clean data](#case_2020_2021_clean)\n",
    "        * [Conclusion](#conclusion_18)\n",
    "    * [4.3. Statistical tests 2 and 3: relationship between manufacturing cost and gross margin](#statistical_test_2)\n",
    "        * [Correlation analysis](#correlation_analysis)\n",
    "        * [Regression analysis](#regression_analysis)\n",
    "        * [Conclusion](#conclusion_19)\n",
    "    * [Hypothesis testing summary](#summary_4)\n",
    "* [5. ML model](#ml_model)\n",
    "    * [5.1. Data preparation](#data_preparation_ml)\n",
    "        * [Data aggregation](#data_aggregation_ml)\n",
    "        * [EDA](#eda_ml)\n",
    "        * [Data split](#split_ml)\n",
    "        * [Feature engineering](#feature_engineering_ml)\n",
    "            * [Encoding categorical variables](#categorical_variables_ml)\n",
    "            * [Transforming outliers](#transforming_outliers_ml)\n",
    "            * [Scaling numerical variables](#numerical_variables_ml)\n",
    "        * [Conclusion](#conclusion_20)\n",
    "    * [5.2. Model building and validation](#model_building_ml)\n",
    "        * [Linear Regression model](#linear_regression_ml)\n",
    "        * [Random Forest Regressor model](#random_forest_ml)\n",
    "        * [Conclusion](#conclusion_21)\n",
    "    * [5.3. Testing model](#model_testing_ml)\n",
    "        * [Conclusion](#conclusion_22)\n",
    "    * [ML model summary](#summary_5)\n",
    "* [Project summary](#project_summary)\n",
    "* [Conclusions and recommendations](#recommendations)\n",
    "* [Regional trends](#regional_trends)\n",
    "* [Recommendations by region](#recommendations_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fb25c1-2ed4-48e8-9d7d-2c7e4330dec0",
   "metadata": {},
   "source": [
    "<h1>Introduction</h1> <a id='intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e316233-457c-46a6-be92-0df363af2b68",
   "metadata": {},
   "source": [
    "__Business task:__ \\\n",
    "Perform a financial analysis for AtliQ Hardware.\n",
    "\n",
    "__Data description:__ \\\n",
    "A database in SQLite format, consisting of 6 tables.\n",
    "\n",
    "__Project goals:__\n",
    "1. research the financial area:\n",
    "    * explore how revenue, profit, and margin have changed over time\n",
    "    * investigate if the market has shifted\n",
    "    * find out what regions are most profitable\n",
    "2. test a hypothesis about the effect of manufacturing costs on profit margins\n",
    "3. build a machine learning model for profit forecasting\n",
    "4. create a dashboard for the company\n",
    "\n",
    "__Main steps:__\n",
    "1. data preprocessing\n",
    "2. exploratory data analysis\n",
    "3. financial analysis: revenue, profit, and margin change research\n",
    "4. hypothesis testing: relationship between manufacturing costs and profit margins\n",
    "5. ML model for profit predictions\n",
    "\n",
    "__Tools used:__\n",
    "- Segment margin analysis: for calculation of margins per geographic segment (region)\n",
    "- Mann-Whitney U test: to test the hypothesis\n",
    "- Spearman's Rank Correlation: for correlation analysis of manufacturing costs and profit margins\n",
    "- Linear least-squares regression: for regression analysis to evaluate the linear relationship between manufacturing costs and profit margins\n",
    "- One-Hot encoding: to encode categorical variables for machine learning (ML)\n",
    "- Clipping: to transform outliers for ML\n",
    "- PowerTransformer with Yeo-Johnson transformation: to scale numerical variables for ML\n",
    "- Linear Regression and Random Forest Regressor algorithms: for profit prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b6b33-b487-475b-89e9-bc6abc29e9c1",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143eb85c-f7a6-4977-ad03-5ce440543d64",
   "metadata": {},
   "source": [
    "<h1>1. Data preprocessing</h1> <a id='data_preprocessing'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0fb344-b048-41f6-b91d-f78bac2ec22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26d73d-fc2e-40ca-a3f6-ca594ca6ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating SQL connection to the SQLite database\n",
    "## connecting to the database by specifying the path to the downloaded database\n",
    "con = sqlite3.connect('atliq_db.sqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51946ea-57ec-4a14-8414-712c29d02598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking all tables in the database\n",
    "cursor = con.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e01370c-e52b-4ddb-b39d-f295e22aa261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a custom function to count missing values\n",
    "def missing_values(table_name):\n",
    "    # fetching column names from the table\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "    columns = cursor.fetchall()\n",
    "    # preparing the dynamic SQL to count missing values in each column\n",
    "    missing_counts = []\n",
    "    for col in columns:\n",
    "        column_name = col[1]\n",
    "        query = f\"SELECT COUNT(*) - COUNT({column_name}) FROM {table_name};\"\n",
    "        cursor.execute(query)\n",
    "        missing_values = cursor.fetchone()[0]\n",
    "        missing_counts.append((column_name, missing_values))\n",
    "    return missing_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8647f2-53e7-4069-8c89-f7eaf7fc7eba",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e51716-2fb0-4c79-b129-f2b7cd845f4a",
   "metadata": {},
   "source": [
    "<h2>1.1. Table dim_customer</h2> <a id='dim_customer'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b4927-e40b-4bb6-85c2-3ce3a298629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing all columns and properties using the PRAGMA statement\n",
    "## notnull: whether or not the column can be NULL\n",
    "## dflt_value: the default value for the column\n",
    "## pk: 0 for columns that are not part of the primary key, or 1 for columns that are part of the primary key\n",
    "### Python: dim_customer.info()\n",
    "query=\"\"\"PRAGMA table_info(dim_customer)\"\"\"\n",
    "info=pd.read_sql_query(query, con)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86a504-66a6-4301-ac8b-4f3a89fbb964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting an overview of the table\n",
    "## Python: dim_customer.head()\n",
    "query=\"\"\"SELECT *\n",
    "FROM dim_customer\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "overview=pd.read_sql_query(query, con)\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e563a3-be45-4c39-832c-ec4e547f0797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking missing values with the custom function\n",
    "missing_values('dim_customer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8752d92-7605-4622-88e4-7061538c8664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking obvious duplicates (fully identical rows)\n",
    "## Python: dim_customer.duplicated().sum()\n",
    "query=\"\"\"SELECT *, COUNT(*)\n",
    "FROM dim_customer\n",
    "GROUP BY customer_code, customer, platform, channel, market, sub_zone, region\n",
    "HAVING COUNT(*) > 1\n",
    "\"\"\"\n",
    "duplicates=pd.read_sql_query(query, con)\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15454da3-5785-4ad5-964d-a0cde9e45e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking implicit duplicates in the column 'market'\n",
    "## Python: sorted(customer['market'].unique())\n",
    "query=\"\"\"SELECT DISTINCT market\n",
    "FROM dim_customer\n",
    "ORDER BY market\n",
    "\"\"\"\n",
    "unique_market=pd.read_sql_query(query, con)\n",
    "unique_market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff52903d-f5b0-414b-916a-4c4027482d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking implicit duplicates in the column 'region'\n",
    "## Python: sorted(customer['region'].unique())\n",
    "query=\"\"\"SELECT DISTINCT region\n",
    "FROM dim_customer\n",
    "ORDER BY region\n",
    "\"\"\"\n",
    "unique_region=pd.read_sql_query(query, con)\n",
    "unique_region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1ac702-6c77-4d97-bbfa-935e3ddd3930",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_1'></a>\n",
    "\n",
    "In the table dim_customer:\n",
    "- column names are correct and follow the snake_case naming convention\n",
    "- data types are correct\n",
    "- there are no missing values\n",
    "- there are no duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aaa7fa-2373-4dc3-b118-65fec9a1b595",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015b57e-fdc9-4498-b17e-313d42d36c52",
   "metadata": {},
   "source": [
    "<h2>1.2. Table dim_product</h2> <a id='dim_product'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4c170e-7646-4082-9dcb-0f2ab454a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general information\n",
    "query=\"\"\"PRAGMA table_info(dim_product)\"\"\"\n",
    "info=pd.read_sql_query(query, con)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be65aa-b483-4a1f-a28b-0da508e31bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table overview\n",
    "query=\"\"\"SELECT *\n",
    "FROM dim_product\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "overview=pd.read_sql_query(query, con)\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f792d86-05c3-4f3f-90d5-3a254e809d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "missing_values('dim_product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582e8c4-59a7-4671-82f3-4ad117f0196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obvious duplicates\n",
    "query=\"\"\"SELECT *, COUNT(*)\n",
    "FROM dim_product\n",
    "GROUP BY product_code, division, segment, category, product, variant\n",
    "HAVING COUNT(*) > 1\n",
    "\"\"\"\n",
    "duplicates=pd.read_sql_query(query, con)\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cdc5f7-f7c4-4b81-8ce5-6e2aad5425b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit duplicates in the column 'division'\n",
    "query=\"\"\"SELECT DISTINCT division\n",
    "FROM dim_product\n",
    "ORDER BY division\n",
    "\"\"\"\n",
    "unique_division=pd.read_sql_query(query, con)\n",
    "unique_division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d934479-fa3f-4f18-8fc8-81066bb5e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit duplicates in the column 'segment'\n",
    "query=\"\"\"SELECT DISTINCT segment\n",
    "FROM dim_product\n",
    "ORDER BY segment\n",
    "\"\"\"\n",
    "unique_segment=pd.read_sql_query(query, con)\n",
    "unique_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3b28d-7948-4781-92d1-c704714f3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit duplicates in the column 'category'\n",
    "query=\"\"\"SELECT DISTINCT category\n",
    "FROM dim_product\n",
    "ORDER BY category\n",
    "\"\"\"\n",
    "unique_category=pd.read_sql_query(query, con)\n",
    "unique_category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec09ce-0c90-4ee4-b9e3-8c55fcee8972",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_2'></a>\n",
    "\n",
    "In the table dim_product:\n",
    "- column names are correct and follow the snake_case naming convention\n",
    "- data types are correct\n",
    "- there are no missing values\n",
    "- there are no duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19555ef1-1d1b-413c-98e2-50c45164975c",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85ca78-a1ff-40b6-8fe3-4f8a507ef1ce",
   "metadata": {},
   "source": [
    "<h2>1.3. Table fact_pre_discount</h2> <a id='fact_pre_discount'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c1281-201a-49c5-ae7f-a0669d6d5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general information\n",
    "query=\"\"\"PRAGMA table_info(fact_pre_discount)\"\"\"\n",
    "info=pd.read_sql_query(query, con)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4faf28-1834-400c-8fb5-65af6f79d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table overview\n",
    "query=\"\"\"SELECT *\n",
    "FROM fact_pre_discount\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "overview=pd.read_sql_query(query, con)\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74159f6-e659-42c9-b552-28957f454705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "missing_values('fact_pre_discount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10eec9-5d80-456a-b0f4-266dda965706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obvious duplicates\n",
    "query=\"\"\"SELECT *, COUNT(*)\n",
    "FROM fact_pre_discount\n",
    "GROUP BY customer_code, fiscal_year, pre_invoice_discount_pct\n",
    "HAVING COUNT(*) > 1\n",
    "\"\"\"\n",
    "duplicates=pd.read_sql_query(query, con)\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f066cc-8dae-4597-848c-01cecf6e0103",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_3'></a>\n",
    "\n",
    "In the table fact_pre_discount:\n",
    "- column names are correct and follow the snake_case naming convention\n",
    "- data types are correct\n",
    "- there are no missing values\n",
    "- there are no duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fe5aff-4136-4bdb-9677-594f12434f8e",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1cb477-c170-47d3-9895-8002b24fde4e",
   "metadata": {},
   "source": [
    "<h2>1.4. Table fact_manufacturing_cost</h2> <a id='fact_manufacturing_cost'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a30f95f-9431-4fb9-b7b6-27dde22fd2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general information\n",
    "query=\"\"\"PRAGMA table_info(fact_manufacturing_cost)\"\"\"\n",
    "info=pd.read_sql_query(query, con)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f1cfb-6a3f-42fb-acbc-6bd3b9e19d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table overview\n",
    "query=\"\"\"SELECT *\n",
    "FROM fact_manufacturing_cost\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "overview=pd.read_sql_query(query, con)\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a9d949-f78b-4f61-be00-1887d26f4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "missing_values('fact_manufacturing_cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41446ccd-5d22-4eef-bb31-3a996742cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obvious duplicates\n",
    "query=\"\"\"SELECT *, COUNT(*)\n",
    "FROM fact_manufacturing_cost\n",
    "GROUP BY product_code, cost_year, manufacturing_cost\n",
    "HAVING COUNT(*) > 1\n",
    "\"\"\"\n",
    "duplicates=pd.read_sql_query(query, con)\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a17af-7849-45ed-8a20-3bae195f890a",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_4'></a>\n",
    "\n",
    "In the table fact_manufacturing_cost:\n",
    "- column names are correct and follow the snake_case naming convention\n",
    "- according to the database documentation, the data type of the column 'product_code' is int64 \\\n",
    "  according to the data given in the table, the data type of the column 'product_code' is string \\\n",
    "  Since 'product_code' contains letters, the more correct data type is string. \\\n",
    "  So there is no need to convert the data type of this column, because it is correct.\n",
    "- the data types of other columns are correct\n",
    "- there are no missing values\n",
    "- there are no duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb4f3fc-e318-4d7d-9a2d-3476522ae9ff",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a71d4ac-b074-496c-bf93-2cf3be4b4b4e",
   "metadata": {},
   "source": [
    "<h2>1.5. Table fact_gross_price</h2> <a id='fact_gross_price'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be8f25-f35d-4218-9c38-20d4bc72820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general information\n",
    "query=\"\"\"PRAGMA table_info(fact_gross_price)\"\"\"\n",
    "info=pd.read_sql_query(query, con)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b8110-c0ad-479d-9fc5-a8ba1ace3f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table overview\n",
    "query=\"\"\"SELECT *\n",
    "FROM fact_gross_price\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "overview=pd.read_sql_query(query, con)\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64499fd-a970-41d8-9891-e1fc3b970281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "missing_values('fact_gross_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935a118-62a2-4d79-8cfa-8614aa1c4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obvious duplicates\n",
    "query=\"\"\"SELECT *, COUNT(*)\n",
    "FROM fact_gross_price\n",
    "GROUP BY product_code, fiscal_year, gross_price\n",
    "HAVING COUNT(*) > 1\n",
    "\"\"\"\n",
    "duplicates=pd.read_sql_query(query, con)\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca63624-23ca-4e12-bfeb-195a5f6fba65",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_5'></a>\n",
    "\n",
    "In the table fact_gross_price:\n",
    "- column names are correct and follow the snake_case naming convention\n",
    "- according to the database documentation, the data type of the column 'product_code' is int64 \\\n",
    "  according to the data given in the table, the data type of the column 'product_code' is string \\\n",
    "  Since 'product_code' contains letters, the more correct data type is string. \\\n",
    "  So there is no need to convert the data type of this column, because it is correct.\n",
    "- the data types of other columns are correct\n",
    "- there are no missing values\n",
    "- there are no duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9329236-a199-43f5-9b8c-3e42546382fe",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa47144-2ae3-4240-9546-ff72623602a5",
   "metadata": {},
   "source": [
    "<h2>1.6. Table fact_sales_monthly</h2> <a id='fact_sales_monthly'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ab3bcb-482e-44f7-a78c-41d95ed82852",
   "metadata": {},
   "source": [
    "<h3>Table overview</h3> <a id='table_overview'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec29bc92-cda9-4f0a-ac1d-02b676b23c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general information\n",
    "query=\"\"\"PRAGMA table_info(fact_sales_monthly)\"\"\"\n",
    "info=pd.read_sql_query(query, con)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86b564-4a7d-46a7-a0c8-e84e72377691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table overview\n",
    "query=\"\"\"SELECT *\n",
    "FROM fact_sales_monthly\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "overview=pd.read_sql_query(query, con)\n",
    "overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e6f5e-7d9a-4ad0-9813-dd33c6b88048",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac2aaa6-4445-4707-aac2-4d99f3c8c401",
   "metadata": {},
   "source": [
    "<h3>Data types</h3> <a id='data_types'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d12daa-f1c5-43e5-8728-613064770cd2",
   "metadata": {},
   "source": [
    "__column 'date'__\n",
    "\n",
    "According to the database documentation, the data type of the column 'date' is string. \\\n",
    "SQLite does not have a separate class for storing dates and/or times. \\\n",
    "Since this column will not be used further, there is no need to cast it to datetime data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f67fc0-1086-470f-9562-151769792270",
   "metadata": {},
   "source": [
    "__column 'customer_code'__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb2b2be-07ea-4da0-9e15-60995ee0553c",
   "metadata": {},
   "source": [
    "According to the database documentation, the data type of the column 'customer_code' in th table 'fact_sales_monthly' is float64. \\\n",
    "In the tables 'dim_customer' and 'fact_pre_discount' it is specified as int64, according to the documentation. \\\n",
    "To check whether the data type of this column in the table 'fact_sales_monthly' is indeed float64, the following approach is used:\n",
    "1. CAST() converts the value in the column to an integer by truncating the decimal part\n",
    "2. The query checks the difference between the value and its integer part to identify numbers with a fractional component\n",
    "3. The query returns all rows where the column contains float values. \\\n",
    "   If the result is not 0, it means the original value had a fractional part (it was a float)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb00ee-e2c6-4f2f-ac43-c8a2b28a6ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the column values have a fractional part\n",
    "query=\"\"\"SELECT *\n",
    "FROM fact_sales_monthly\n",
    "WHERE customer_code - CAST(customer_code AS INTEGER) != 0\n",
    "\"\"\"\n",
    "non_integer=pd.read_sql_query(query, con)\n",
    "non_integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f260875-cc90-4a0a-90de-0d12913b3c15",
   "metadata": {},
   "source": [
    "The column 'customer_code' does not contain values with a fractional part.\n",
    "\n",
    "To check whether this column contains non-numeric values, CAST() is used. \\\n",
    "It identifies rows where the column contains letters or non-numeric characters. \\\n",
    "Using  regular expressions via REGEXP is not available in SQLite to perform this check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bdb215-840f-4d76-87d3-ca26ab8d2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the column 'customer_code' contains letters or non-numeric characters\n",
    "query=\"\"\"SELECT *\n",
    "FROM fact_sales_monthly\n",
    "WHERE CAST(customer_code AS INTEGER) IS NULL\n",
    "\"\"\"\n",
    "non_numeric=pd.read_sql_query(query, con)\n",
    "non_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5202795-366f-4353-b105-d9de81f74c50",
   "metadata": {},
   "source": [
    "In the column 'customer_code' all values are integers, except for one row with the missing value. \\\n",
    "So there is no need to convert the data type of this column, because it is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb42115-9c0e-4ff5-bf06-d553c76daff5",
   "metadata": {},
   "source": [
    "__columns 'sold_quantity' and 'fiscal_year'__\n",
    "\n",
    "The database documentation marks columns 'sold_quantity' and 'fiscal_year' as float64. \\\n",
    "The table information marks their type as integer. \\\n",
    "To check whether these columns contain float or non-numeric values, the CAST() function is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956bbe4-1e4e-43e9-8e67-30edd1d646c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the column 'sold_quantity' contains float or non-numeric values\n",
    "query=\"\"\"SELECT *\n",
    "FROM fact_sales_monthly\n",
    "WHERE CAST(sold_quantity AS INTEGER) IS NULL\n",
    "\"\"\"\n",
    "non_numeric=pd.read_sql_query(query, con)\n",
    "non_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a03823-ce79-42ce-8aa7-f4f614989f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the column 'fiscal_year' contains float or non-numeric values\n",
    "query=\"\"\"SELECT *\n",
    "FROM fact_sales_monthly\n",
    "WHERE CAST(fiscal_year AS INTEGER) IS NULL\n",
    "\"\"\"\n",
    "non_numeric=pd.read_sql_query(query, con)\n",
    "non_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670ddd46-b759-4ede-a084-bf610c5b5b51",
   "metadata": {},
   "source": [
    "Both columns do not contain values with a fractional part or non-numeric characters,  except for one row with the missing value. \\\n",
    "So there is no need to convert their data type, because it is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e3bc6c-d427-4285-8572-9c2397e112c7",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56362cb3-5804-42c2-9a94-fc260b87a4fe",
   "metadata": {},
   "source": [
    "<h3>Missing and duplicate values</h3> <a id='missing_duplicate '></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b0721-b283-4610-b793-d238ce6cf336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "missing_values('fact_sales_monthly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c377d93-21c1-402d-aa62-2200220cebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the rows with the missing values\n",
    "query=\"\"\"SELECT *\n",
    "FROM fact_sales_monthly\n",
    "WHERE customer_code IS NULL\n",
    "\"\"\"\n",
    "missing=pd.read_sql_query(query, con)\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc012ff0-a7b4-4fda-8cc1-b11fe3bfcf20",
   "metadata": {},
   "source": [
    "All 3 missing values are from the row with the product code A0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ddc97-0645-4448-a5f2-2f01c9e14ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking products with the code A0 in the table 'fact_sales_monthly'\n",
    "query=\"\"\"SELECT *\n",
    "FROM fact_sales_monthly\n",
    "WHERE product_code='A0'\n",
    "\"\"\"\n",
    "codeA0=pd.read_sql_query(query, con)\n",
    "codeA0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f32237e-ce1a-41e8-b674-5ac634e8b1e6",
   "metadata": {},
   "source": [
    "There is only 1 product with the code A0, and all values for it are missing except for the date. \\\n",
    "To decide what to do with it, it is necessary to check if this product code is present in other tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465bbf09-270d-432d-a9da-f059a90e2841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking products with the code A0 in the table 'dim_product'\n",
    "query = \"\"\"SELECT * FROM dim_product WHERE product_code='A0'\"\"\"\n",
    "codeA0=pd.read_sql_query(query, con)\n",
    "codeA0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45d6f6e-ccab-448e-8d59-20b495c1aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking products with the code A0 in the table 'fact_manufacturing_cost'\n",
    "query = \"\"\"SELECT * FROM fact_manufacturing_cost WHERE product_code='A0'\"\"\"\n",
    "codeA0=pd.read_sql_query(query, con)\n",
    "codeA0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c68de-fdc8-4f1e-bbf8-1048b5d023f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking products with the code A0 in the table 'fact_gross_price'\n",
    "query = \"\"\"SELECT * FROM fact_gross_price WHERE product_code='A0'\"\"\"\n",
    "codeA0=pd.read_sql_query(query, con)\n",
    "codeA0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba6ab8c-5226-4090-b9cd-5d5e927de5fc",
   "metadata": {},
   "source": [
    "This product is not present in any other table. \\\n",
    "It is safe to remove it, so it won't influence the further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc0aee4-4cf1-45b7-84ad-3d065beb22f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the row with the product_code A0\n",
    "query=\"\"\"DELETE FROM fact_sales_monthly\n",
    "WHERE product_code='A0'\n",
    "\"\"\"\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1892e69-8d48-4fc9-bf7d-277aad8cb61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the product with the code A0 is removed from the table 'fact_sales_monthly'\n",
    "query = \"\"\"SELECT * FROM fact_sales_monthly WHERE product_code='A0'\"\"\"\n",
    "codeA0=pd.read_sql_query(query, con)\n",
    "codeA0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f770a332-3d38-44be-98ad-cf6f4ddd8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obvious duplicates\n",
    "query=\"\"\"SELECT *, COUNT(*)\n",
    "FROM fact_sales_monthly\n",
    "GROUP BY date, product_code, customer_code, sold_quantity, fiscal_year\n",
    "HAVING COUNT(*) > 1\n",
    "\"\"\"\n",
    "duplicates=pd.read_sql_query(query, con)\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3be636-1a99-4d31-b9ce-653acc833a02",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_6'></a>\n",
    "\n",
    "In the table fact_sales_monthly:\n",
    "- column names are correct and follow the snake_case naming convention\n",
    "- data types:\n",
    "    - column 'date' is stored as string, since SQLite does not have a separate class for storing dates\n",
    "    - columns 'customer_code', 'sold_quantity' and 'fiscal_year' are marked as float64 in the documentation \\\n",
    "      They're marked as integer in the table information. \\\n",
    "      In all 3 columns all values are integers, except for one row with missing values. \\\n",
    "      There is no need to convert the data type of these columns, because it is correct.\n",
    "- there is 1 row with values missing in 3 out of 5 columns \\\n",
    "  Only date and product_code are available for this row. \\\n",
    "  This product code A0 is not present in any other table. \\\n",
    "  The row with the product code A0 is removed in order not to influence the further analysis.\n",
    "- there are no duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae244972-fc29-495d-a68f-325eaf49a5fd",
   "metadata": {},
   "source": [
    "<h2>Data summary</h2> <a id='summary_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c17581-bff4-4902-ba91-51cfc557dd4b",
   "metadata": {},
   "source": [
    "1. All column names are correct and follow the snake_case naming style.\n",
    "2. The dataset has no duplicate values.\n",
    "3. The table 'fact_sales_monthly' has 1 row with missing values, and the product code of this row is A0.\n",
    "4. This product code is not present in other tables, so the row with missing values was removed from the table 'fact_sales_monthly'.\n",
    "6. All other tables have no missing values.\n",
    "7. The columns data types stored in the tables differ from those mentioned in the database documentation.\n",
    "8. Data types stored in the tables are correct and do not need casting. \n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c869c3f-44f5-496f-a3da-7dda7cddd2cb",
   "metadata": {},
   "source": [
    "<h1>2. EDA</h1> <a id='eda'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7cfa89-bb93-4440-9b16-bd17ea57a1f3",
   "metadata": {},
   "source": [
    "The following methods will be used in exploratory data analysis:\n",
    "* id columns: nunique(), count()\n",
    "* categorical columns: value_counts(), nunique()\n",
    "* numerical columns: describe(), np.percentile(), histogram\n",
    "* years range: count(), groupby()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b12dc-8119-4b36-a486-8b61c02b5a35",
   "metadata": {},
   "source": [
    "<h2>2.1. Table dim_customer</h2> <a id='eda_customer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a253f-238a-41c4-b98e-6efe2ebb9d6b",
   "metadata": {},
   "source": [
    "In this project the table dim_customer is used to explore the market and how it has shifted.\n",
    "\n",
    "The following columns are needed from the table dim_customer for this analysis:\n",
    "* customer_code\n",
    "* market\n",
    "* region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de37d2c-deec-4d74-bdce-56d41992c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of rows in the table dim_customer\n",
    "## Python: len(dim_customer)\n",
    "query=\"\"\"SELECT COUNT(*)\n",
    "FROM dim_customer\n",
    "\"\"\"\n",
    "number_rows=pd.read_sql_query(query, con)\n",
    "number_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd64da-2799-40fe-9e3c-e1922459018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of unique customers\n",
    "## Python: dim_customer['customer_code'].nunique()\n",
    "query=\"\"\"SELECT COUNT(DISTINCT customer_code)\n",
    "FROM dim_customer\n",
    "\"\"\"\n",
    "number_customers=pd.read_sql_query(query, con)\n",
    "number_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909630fc-2252-40d4-b00a-eb7f803bd614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the distribution of values in the column 'region'\n",
    "## Python: dim_customer['region'].value_counts()\n",
    "query=\"\"\"SELECT region, COUNT(*)\n",
    "FROM dim_customer\n",
    "GROUP BY region\n",
    "ORDER BY COUNT(*) DESC\n",
    "\"\"\"\n",
    "region_values=pd.read_sql_query(query, con)\n",
    "region_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90d9224-8cd4-4fc4-8193-a464b2b5b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the distribution of values in the column 'market'\n",
    "## Python: dim_customer['market'].value_counts()\n",
    "query=\"\"\"SELECT market, COUNT(*)\n",
    "FROM dim_customer\n",
    "GROUP BY market\n",
    "ORDER BY COUNT(*) DESC\n",
    "\"\"\"\n",
    "market_values=pd.read_sql_query(query, con)\n",
    "market_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b7f6c-e065-46a4-aac5-0f3533589c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how values are distributed per both 'region' and 'market' columns\n",
    "## Python: dim_customer[['region', 'market']].value_counts()\n",
    "query=\"\"\"SELECT region, market, COUNT(*)\n",
    "FROM dim_customer\n",
    "GROUP BY region, market\n",
    "ORDER BY COUNT(*) DESC\n",
    "\"\"\"\n",
    "region_market_values=pd.read_sql_query(query, con)\n",
    "region_market_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98946c4-78ac-4d94-aaa4-d2d2bc500aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one market there should be one region, according to the database documentation\n",
    "## Python: dim_customer.groupby('market')['region'].nunique()\n",
    "query=\"\"\"SELECT market, COUNT(DISTINCT region)\n",
    "FROM dim_customer\n",
    "GROUP BY market\n",
    "\"\"\"\n",
    "market_region=pd.read_sql_query(query, con)\n",
    "market_region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e88b697-d4fd-4989-97c0-47b386516f43",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_7'></a>\n",
    "\n",
    "* The table 'dim_customer' contains 209 unique customers.\n",
    "* The table 'dim_customer' has 209 rows, so one row represents one unique customer.\n",
    "* Most customers come from EU, followed by APAC countries.\n",
    "* The markets of India and USA have the largest amount of customers.\n",
    "* India represents APAC region, and USA - NA region.\n",
    "* The requirement that for one market there should be one region, is satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cec8d6-b009-487b-a44e-55dc44140a96",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1420556-7189-47b4-903e-d98a2da2b62f",
   "metadata": {},
   "source": [
    "<h2>2.2. Table dim_product</h2> <a id='eda_product'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0828be-9549-44d5-b2cc-1ed767ab4cca",
   "metadata": {},
   "source": [
    "The table dim_product can be used to find out what product segments and categories are most profitable.\n",
    "\n",
    "The following columns are needed from the table dim_product:\n",
    "* product_code\n",
    "* division\n",
    "* segment\n",
    "* category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8b4c2-17f6-4d73-8402-36386d0fe4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of rows in the table dim_product\n",
    "query=\"\"\"SELECT COUNT(*)\n",
    "FROM dim_product\n",
    "\"\"\"\n",
    "number_rows=pd.read_sql_query(query, con)\n",
    "number_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690fff0-063d-4323-872c-ae268f5ff4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of unique products\n",
    "query=\"\"\"SELECT COUNT(DISTINCT product_code)\n",
    "FROM dim_product\n",
    "\"\"\"\n",
    "number_products=pd.read_sql_query(query, con)\n",
    "number_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f5679b-e3e1-4929-a393-d080e7f5f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of unique categories\n",
    "query=\"\"\"SELECT COUNT(DISTINCT category)\n",
    "FROM dim_product\n",
    "\"\"\"\n",
    "number_categories=pd.read_sql_query(query, con)\n",
    "number_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd96dc7-a0a0-404a-ad56-ecbc929e8fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the distribution of values in the column 'division'\n",
    "query=\"\"\"SELECT division, COUNT(*)\n",
    "FROM dim_product\n",
    "GROUP BY division\n",
    "ORDER BY COUNT(*) DESC\n",
    "\"\"\"\n",
    "division_values=pd.read_sql_query(query, con)\n",
    "division_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e447303-b64d-41dd-b753-1def6c790a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the distribution of values in the column 'segment'\n",
    "query=\"\"\"SELECT segment, COUNT(*)\n",
    "FROM dim_product\n",
    "GROUP BY segment\n",
    "ORDER BY COUNT(*) DESC\n",
    "\"\"\"\n",
    "segment_values=pd.read_sql_query(query, con)\n",
    "segment_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57242ba-9c4c-480d-9527-2968a9a99069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the distribution of values in the column 'category'\n",
    "query=\"\"\"SELECT category, COUNT(*)\n",
    "FROM dim_product\n",
    "GROUP BY category\n",
    "ORDER BY COUNT(*) DESC\n",
    "\"\"\"\n",
    "category_values=pd.read_sql_query(query, con)\n",
    "category_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a6de0f-192e-45df-b531-3e13ab8874f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how values are distributed per 'division', 'segment' and 'category' columns\n",
    "query=\"\"\"SELECT division, segment, category, COUNT(*)\n",
    "FROM dim_product\n",
    "GROUP BY division, segment, category\n",
    "ORDER BY COUNT(*) DESC\n",
    "\"\"\"\n",
    "div_seg_cat_values=pd.read_sql_query(query, con)\n",
    "div_seg_cat_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d06cf-0f26-4ad4-84ca-bc9d18630b3e",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_8'></a>\n",
    "\n",
    "\n",
    "* The table 'dim_product' contains 397 unique products.\n",
    "* The table 'dim_product' has 397 rows, so one row represents one unique product.\n",
    "* There are 3 unique divisions, 6 unique segments, and 14 unique product categories.\n",
    "* The category Business Laptop belongs to 2 segments: Notebook and Desktop, but to one division - PC.\n",
    "* N & S (Networking and Storage) division has the lowest number of products.\n",
    "* P & A (Peripherals and Accessories) division has the highest amount of products.\n",
    "* In segments, most products are in the Notebook and Accessories segment.\n",
    "* In the Notebook segment most of the products are in the Personal Laptop category.\n",
    "* From Accessories, Keyboard and Mouse categories have the most products, from Peripherals - Graphic Card category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4301cd9-d459-411b-81d8-05f226fbe8f8",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded89e4-d393-46ac-abe0-46e9e1cb9101",
   "metadata": {},
   "source": [
    "<h2>2.3. Table fact_pre_discount</h2> <a id='eda_discount'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e142f5-7ed3-47e9-872d-4d27d593026f",
   "metadata": {},
   "source": [
    "The table fact_pre_discount is used to calculate gross profit.\n",
    "\n",
    "All columns are needed from the table fact_pre_discount:\n",
    "* customer_code\n",
    "* fiscal_year\n",
    "* pre_invoice_discount_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b59f9-0af3-472c-9ecf-8259ce7bbba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of rows in the table fact_pre_discount\n",
    "query=\"\"\"SELECT COUNT(*)\n",
    "FROM fact_pre_discount\n",
    "\"\"\"\n",
    "number_rows=pd.read_sql_query(query, con)\n",
    "number_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed51d2-7e8b-47aa-942d-0a5048f377d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of unique customers\n",
    "query=\"\"\"SELECT COUNT(DISTINCT customer_code)\n",
    "FROM fact_pre_discount\n",
    "\"\"\"\n",
    "number_customers=pd.read_sql_query(query, con)\n",
    "number_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afe26f-982b-4f46-a729-aa211e1ee4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the range of years and the distribution of values in the column 'fiscal_year'\n",
    "query=\"\"\"SELECT fiscal_year, COUNT(DISTINCT customer_code)\n",
    "FROM fact_pre_discount\n",
    "GROUP BY fiscal_year\n",
    "\"\"\"\n",
    "year_values=pd.read_sql_query(query, con)\n",
    "year_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1602e3-312e-41e5-88e0-5138ad75fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if there are several discounts per year for a customer\n",
    "query=\"\"\"SELECT customer_code, fiscal_year, COUNT(pre_invoice_discount_pct)\n",
    "FROM fact_pre_discount\n",
    "GROUP BY customer_code, fiscal_year\n",
    "HAVING COUNT(pre_invoice_discount_pct) > 1\n",
    "\"\"\"\n",
    "several_discounts=pd.read_sql_query(query, con)\n",
    "several_discounts.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b742220-1800-4c70-b031-7fab477c9093",
   "metadata": {},
   "source": [
    "To investigate the numerical column 'pre_invoice_discount_pct' for outliers:\n",
    "1. the column is saved in a separate variable\n",
    "2. the describe() method is applied to check the main statistics of the column\n",
    "3. a histogram is used to visualize the distribution of values in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ef0e5-303c-4e8d-8f77-c39ee7be585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the column with discounts in a separate variable\n",
    "query=\"\"\"SELECT pre_invoice_discount_pct\n",
    "FROM fact_pre_discount\n",
    "\"\"\"\n",
    "discount=pd.read_sql_query(query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435d003-c9d6-4594-9b38-57edea9cb62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general statistics\n",
    "discount.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b648d2c-0ad3-43f9-be9c-d84dccbd977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a histogram to check the distribution of the discount values\n",
    "plt.hist(discount['pre_invoice_discount_pct'], bins=50, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('discount (in %)')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Distribution of discounts')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7ec9f9-bc5a-4fd1-a3fe-c9853ac7a0a4",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_9'></a>\n",
    "\n",
    "* The tables 'dim_customer' and 'fact_pre_discount' both have 209 unique customers.\n",
    "* The table 'fact_pre_discount' has data for 5 years: 2018-2022.\n",
    "* Each year has 209 entries, as the amount of unique customers.\n",
    "* Each row corresponds to one discount value per year for each customer.\n",
    "* There are 2 groups of discount values: from 0.05 to around 0.11, and from around 0.17 to 0.31.\n",
    "* There are no extreme discounts that could count as outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c35f85-192d-4f5d-b43d-1fbd75ef51b2",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee7d94-47b2-4e12-ad22-829536f0c7e9",
   "metadata": {},
   "source": [
    "<h2>2.4. Table fact_manufacturing_cost</h2> <a id='eda_manufacture_cost'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0049552a-9919-4edd-9c0a-44125aec10ba",
   "metadata": {},
   "source": [
    "The table fact_manufacturing_cost is used to calculate gross profit.\n",
    "\n",
    "All columns are needed from the table fact_manufacturing_cost:\n",
    "* product_code\n",
    "* cost_year\n",
    "* manufacturing_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ca39d7-8bac-4dd6-939e-1491d414fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of rows in the table fact_manufacturing_cost\n",
    "query=\"\"\"SELECT COUNT(*)\n",
    "FROM fact_manufacturing_cost\n",
    "\"\"\"\n",
    "number_rows=pd.read_sql_query(query, con)\n",
    "number_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b6092-ae3a-444c-a485-20e94fe50260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of unique products\n",
    "query=\"\"\"SELECT COUNT(DISTINCT product_code)\n",
    "FROM fact_manufacturing_cost\n",
    "\"\"\"\n",
    "number_products=pd.read_sql_query(query, con)\n",
    "number_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd4d4b-73f0-4bd2-9e1c-3efb1d6683bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking what product categories are represented in the table 'fact_manufacturing_cost'\n",
    "query=\"\"\"SELECT division, segment, category, COUNT (category)\n",
    "FROM dim_product\n",
    "WHERE product_code IN (SELECT product_code FROM fact_manufacturing_cost)\n",
    "GROUP BY category\n",
    "\"\"\"\n",
    "manufacture_products=pd.read_sql_query(query, con)\n",
    "manufacture_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5909f66-0eb9-453f-817b-26c8db84fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the range of years and the distribution of values in the column 'cost_year'\n",
    "query=\"\"\"SELECT cost_year, COUNT(*)\n",
    "FROM fact_manufacturing_cost\n",
    "GROUP BY cost_year\n",
    "\"\"\"\n",
    "year_values=pd.read_sql_query(query, con)\n",
    "year_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb59aaf8-a251-4a9c-9cb8-c38235033542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if there are several manufacturing costs per year for a product\n",
    "query=\"\"\"SELECT product_code, cost_year, COUNT(manufacturing_cost)\n",
    "FROM fact_manufacturing_cost\n",
    "GROUP BY product_code, cost_year\n",
    "HAVING COUNT(manufacturing_cost) > 1\n",
    "\"\"\"\n",
    "several_costs=pd.read_sql_query(query, con)\n",
    "several_costs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e458ce-b85b-4692-8fe0-98190b6b9866",
   "metadata": {},
   "source": [
    "To investigate the numerical column 'manufacturing_cost' for outliers:\n",
    "1. the column is saved in a separate variable\n",
    "2. the describe() method is applied to check the main statistics of the column\n",
    "3. a histogram is used to visualize the distribution of values in the column\n",
    "4. the function numpy.percentile() is used to calculate the percentiles for the manufacturing cost values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28735c6b-8ea8-427b-8016-a05a91341303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the column with manufacturing costs in a separate variable\n",
    "query=\"\"\"SELECT manufacturing_cost\n",
    "FROM fact_manufacturing_cost\n",
    "\"\"\"\n",
    "manufacture_cost=pd.read_sql_query(query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5637f-52f9-4eff-8950-57faa45aa535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general statistics\n",
    "manufacture_cost.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6efc396-4901-4f3d-a605-210e8f60b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a histogram to check the distribution of the manufacturing cost values\n",
    "plt.hist(manufacture_cost['manufacturing_cost'], bins=50, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('manufacturing cost')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Distribution of manufacturing costs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad1e3a6-39e5-4227-8a75-2c9b1c98b154",
   "metadata": {},
   "source": [
    "There are 2 groups of manufacturing cost values: from 1 to around 15, and from around 25 to 263."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba530ce-76c1-4419-8f3b-7374c8a5adf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating percentiles for the manufacturing cost values\n",
    "print(np.percentile(manufacture_cost['manufacturing_cost'], [80, 85, 90, 95, 99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fc053d-ad78-4c54-a88e-dceb6bb025ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking products with manufacturing costs higher than or equal to 144 (80th percentile)\n",
    "query=\"\"\"SELECT category, COUNT (category)\n",
    "FROM dim_product\n",
    "WHERE product_code IN (SELECT product_code FROM fact_manufacturing_cost WHERE manufacturing_cost >= 144)\n",
    "GROUP By category\n",
    "\"\"\"\n",
    "percentile80=pd.read_sql_query(query, con)\n",
    "percentile80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4c0f0-8b6e-42ee-9447-5dfa75acb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking products with manufacturing costs higher than or equal to 212 (95th percentile)\n",
    "query=\"\"\"SELECT category, COUNT (category)\n",
    "FROM dim_product\n",
    "WHERE product_code IN (SELECT product_code FROM fact_manufacturing_cost WHERE manufacturing_cost >= 212)\n",
    "GROUP By category\n",
    "\"\"\"\n",
    "percentile95=pd.read_sql_query(query, con)\n",
    "percentile95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f693ad64-01e9-4249-aba5-dd0c0770562f",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_10'></a>\n",
    "\n",
    "* The table 'dim_product' has 397 unique products, while the table 'fact_manufacturing_cost' has 389.\n",
    "* 8 products have no data on manufacturing costs.\n",
    "* The table 'fact_manufacturing_cost' has data for 5 years: 2018-2022.\n",
    "* Each year has a different amount of entries, which means not every product is represented in the table each year.\n",
    "* Each row corresponds to a manufacturing cost per product for one production year.\n",
    "* There are 2 groups of manufacturing cost values: from 1 to around 15, and from around 25 to 263.\n",
    "* Half of the manufacturing costs is less than 11.\n",
    "* No more than 5% of costs is more than 212.\n",
    "* There are outliers in manufacturing costs, but these values correspond to categories that require high costs in the hardware production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e83de00-4b1d-4b75-971f-975e72d68346",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e9faba-f92b-4384-95de-71aa40e87f2d",
   "metadata": {},
   "source": [
    "<h2>2.5. Table fact_gross_price</h2> <a id='eda_gross_price'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84a8ad-1163-4f29-8158-191b61cefafd",
   "metadata": {},
   "source": [
    "The table fact_gross_price is used to calculate gross revenue.\n",
    "\n",
    "All columns are needed from the table fact_gross_price:\n",
    "* product_code\n",
    "* fiscal_year\n",
    "* gross_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c10b97-fee5-4aec-83eb-63d1a9090d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of rows in the table fact_gross_price\n",
    "query=\"\"\"SELECT COUNT(*)\n",
    "FROM fact_gross_price\n",
    "\"\"\"\n",
    "number_rows=pd.read_sql_query(query, con)\n",
    "number_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceaeeed-fce3-46ce-aafa-3572e6dbc8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of unique products\n",
    "query=\"\"\"SELECT COUNT(DISTINCT product_code)\n",
    "FROM fact_gross_price\n",
    "\"\"\"\n",
    "number_products=pd.read_sql_query(query, con)\n",
    "number_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86963a9f-d85a-4916-8ab7-5002a2463e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking what product categories are represented in the table 'fact_gross_price'\n",
    "query=\"\"\"SELECT division, segment, category, COUNT (category)\n",
    "FROM dim_product\n",
    "WHERE product_code IN (SELECT product_code FROM fact_gross_price)\n",
    "GROUP BY category\n",
    "\"\"\"\n",
    "gross_price_products=pd.read_sql_query(query, con)\n",
    "gross_price_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e969ec-7a43-433c-b1c1-f831b525b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the range of years and the distribution of values in the column 'fiscal_year'\n",
    "query=\"\"\"SELECT fiscal_year, COUNT(*)\n",
    "FROM fact_gross_price\n",
    "GROUP BY fiscal_year\n",
    "\"\"\"\n",
    "year_values=pd.read_sql_query(query, con)\n",
    "year_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb108275-286d-49d9-a5b5-9b261c5d5db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if there are several prices for a product per year\n",
    "query=\"\"\"SELECT product_code, fiscal_year, COUNT(gross_price)\n",
    "FROM fact_gross_price\n",
    "GROUP BY product_code, fiscal_year\n",
    "HAVING COUNT(gross_price) > 1\n",
    "\"\"\"\n",
    "several_prices=pd.read_sql_query(query, con)\n",
    "several_prices.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7182b72-c5a5-42a7-8865-330ffea0aaf9",
   "metadata": {},
   "source": [
    "To investigate the numerical column 'gross_price' for outliers:\n",
    "1. the column is saved in a separate variable\n",
    "2. the describe() method is applied to check the main statistics of the column\n",
    "3. a histogram is used to visualize the distribution of values in the column\n",
    "4. the function numpy.percentile() is used to calculate the percentiles for the gross price values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79eb0ca-1d85-4aca-b183-1675c22a2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the column with gross prices in a separate variable\n",
    "query=\"\"\"SELECT gross_price\n",
    "FROM fact_gross_price\n",
    "\"\"\"\n",
    "gross_price=pd.read_sql_query(query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97954443-ee32-4113-a772-93a1d85ba38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general statistics\n",
    "gross_price.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c534416-885e-43ff-aedf-8106015b0c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a histogram to check the distribution of the gross prices\n",
    "plt.hist(gross_price['gross_price'], bins=50, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('gross price')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Distribution of gross prices')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d22c8e5-3e07-403d-948f-356488d5f33c",
   "metadata": {},
   "source": [
    "There are 2 groups of gross price values: from 3 to 38, and from around 90 to 890."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0d9a10-0307-4926-989e-bbe11112d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating percentiles for the gross price values\n",
    "print(np.percentile(gross_price['gross_price'], [80, 85, 90, 95, 99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c2ea30-c126-4e36-b9b3-ae1e8f85aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking products with gross prices higher than 477 (80th percentile)\n",
    "query=\"\"\"SELECT category, COUNT (category)\n",
    "FROM dim_product\n",
    "WHERE product_code IN (SELECT product_code FROM fact_gross_price WHERE gross_price > 477)\n",
    "GROUP By category\n",
    "\"\"\"\n",
    "percentile80=pd.read_sql_query(query, con)\n",
    "percentile80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a913bbe-5a74-4e5d-991c-1dade64a5aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking products with gross prices higher than 697 (95th percentile)\n",
    "query=\"\"\"SELECT category, COUNT (category)\n",
    "FROM dim_product\n",
    "WHERE product_code IN (SELECT product_code FROM fact_gross_price WHERE gross_price > 697)\n",
    "GROUP By category\n",
    "\"\"\"\n",
    "percentile95=pd.read_sql_query(query, con)\n",
    "percentile95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca575cd-7de0-46da-868c-05b2ea36b71b",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_11'></a>\n",
    "\n",
    "* The tables 'fact_manufacturing_cost' and 'fact_gross_price' have the same amount of rows: 1182, and the same number of unique products: 389.\n",
    "* The table 'fact_gross_price' has data for 5 years: 2018-2022.\n",
    "* Each year has a different amount of entries, which means not every product is represented in the table each year.\n",
    "* Each row corresponds to a gross price per product for each fiscal year.\n",
    "* There are 2 groups of gross price values: from 3 to 38, and from around 90 to 890.\n",
    "* Half of the gross price is less than 38.\n",
    "* No more than 5% of prices is more than 697.\n",
    "* The distribution of gross price values corresponds with the distribution of manufacturing costs.\n",
    "* There are outliers in gross prices, but these values correspond to categories that have high pricing.\n",
    "* These outliers are from the same product categories as the outliers from the table 'fact_manufacturing_cost'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d6cc0d-f0b3-4c18-ab6b-a7aed8bac9b1",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232ed9b4-a921-4e71-8089-bfcf8aaaec37",
   "metadata": {},
   "source": [
    "<h2>2.6. Table fact_sales_monthly</h2> <a id='eda_sales'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4269b540-46dd-4a77-a243-aac4b1fdf538",
   "metadata": {},
   "source": [
    "The table fact_sales_monthly is used to calculate gross revenue.\n",
    "\n",
    "The following columns are needed from the table fact_sales_monthly:\n",
    "* product_code\n",
    "* customer_code\n",
    "* sold_quantity\n",
    "* fiscal_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677c0dbf-088d-419d-a4c5-830aabe698f3",
   "metadata": {},
   "source": [
    "<h3>Unique customers and years range</h3> <a id='customers_years'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c419f1d7-5304-47fa-99b0-51e912558fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of rows in the table fact_sales_monthly\n",
    "query=\"\"\"SELECT COUNT(*)\n",
    "FROM fact_sales_monthly\n",
    "\"\"\"\n",
    "number_rows=pd.read_sql_query(query, con)\n",
    "number_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4725253a-4579-482c-89ba-511a3166524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of unique customers\n",
    "query=\"\"\"SELECT COUNT(DISTINCT customer_code)\n",
    "FROM fact_sales_monthly\n",
    "\"\"\"\n",
    "number_customers=pd.read_sql_query(query, con)\n",
    "number_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad034c05-1ddb-4d21-8eae-3d25fe16bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the range of years and the distribution of values in the column 'fiscal_year'\n",
    "query=\"\"\"SELECT fiscal_year, COUNT(*)\n",
    "FROM fact_sales_monthly\n",
    "GROUP BY fiscal_year\n",
    "\"\"\"\n",
    "year_values=pd.read_sql_query(query, con)\n",
    "year_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85499c0a-3cb6-4688-8286-93ee09e427fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if there are several values for product's sold quantity per customer per year\n",
    "query=\"\"\"SELECT product_code, customer_code, fiscal_year, COUNT(sold_quantity)\n",
    "FROM fact_sales_monthly\n",
    "GROUP BY product_code, customer_code, fiscal_year\n",
    "HAVING COUNT(sold_quantity) > 1\n",
    "\"\"\"\n",
    "several_quantities=pd.read_sql_query(query, con)\n",
    "several_quantities.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179bf021-6a2f-4672-807c-aabf5f343daa",
   "metadata": {},
   "source": [
    "<h3>Unique products, regions and markets</h3> <a id='unique_products_regions'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39b821-eb77-461a-8ef0-fe3744c0a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of unique products\n",
    "query=\"\"\"SELECT COUNT(DISTINCT product_code)\n",
    "FROM fact_sales_monthly\n",
    "\"\"\"\n",
    "number_products=pd.read_sql_query(query, con)\n",
    "number_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0979a5b-3766-4141-a734-aff28b5bff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking what product categories are represented in the table 'fact_sales_monthly'\n",
    "query=\"\"\"SELECT division, segment, category, COUNT (category)\n",
    "FROM dim_product\n",
    "WHERE product_code IN (SELECT product_code FROM fact_sales_monthly)\n",
    "GROUP BY category\n",
    "\"\"\"\n",
    "sales_product_categories=pd.read_sql_query(query, con)\n",
    "sales_product_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae9ae3b-a1cf-4964-ab2a-f4c29d90c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if in the table 'fact_sales_monthly' there are product segments other than Peripherals\n",
    "query=\"\"\"SELECT product_code, COUNT(product_code)\n",
    "FROM fact_sales_monthly\n",
    "WHERE product_code IN (SELECT product_code FROM dim_product WHERE segment != 'Peripherals')\n",
    "\"\"\"\n",
    "not_peripherals=pd.read_sql_query(query, con)\n",
    "not_peripherals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10891d19-0c42-403d-9a17-00563747cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking what regions are represented in the table 'fact_sales_monthly'\n",
    "query=\"\"\"SELECT region, COUNT (region)\n",
    "FROM dim_customer\n",
    "WHERE customer_code IN (SELECT customer_code FROM fact_sales_monthly)\n",
    "GROUP BY region\n",
    "\"\"\"\n",
    "sales_regions=pd.read_sql_query(query, con)\n",
    "sales_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281bb3f5-4810-4906-b765-daf23fd901c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking what markets are represented in the table 'fact_sales_monthly'\n",
    "query=\"\"\"SELECT market, COUNT (market)\n",
    "FROM dim_customer\n",
    "WHERE customer_code IN (SELECT customer_code FROM fact_sales_monthly)\n",
    "GROUP BY market\n",
    "\"\"\"\n",
    "sales_markets=pd.read_sql_query(query, con)\n",
    "sales_markets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a3bad-69fc-48bc-a835-25e5a1c87f1b",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad42f32-3176-4b0a-bb71-168768f3c868",
   "metadata": {},
   "source": [
    "<h3>Sold quantities</h3> <a id='sold_quantity'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b816f2-403b-4a36-b5f2-ae464407b46a",
   "metadata": {},
   "source": [
    "To investigate the numerical column 'sold_quantity' for outliers:\n",
    "1. the column is saved in a separate variable\n",
    "2. the describe() method is applied to check the main statistics of the column\n",
    "3. a histogram is used to visualize the distribution of values in the column\n",
    "4. the function numpy.percentile() is used to calculate the percentiles for the sold quantity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb40c0-6614-4aed-866f-e6565ea27963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the column with sold quantities in a separate variable\n",
    "query=\"\"\"SELECT sold_quantity\n",
    "FROM fact_sales_monthly\n",
    "\"\"\"\n",
    "sold_quantity=pd.read_sql_query(query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbfde3b-61fc-41b0-8542-f1b52e223867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general statistics\n",
    "sold_quantity.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0456c58c-addf-45c8-ae54-d00775516768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the amount of products with zero sold quantity in the table 'fact_sales_monthly'\n",
    "query=\"\"\"SELECT COUNT (product_code)\n",
    "FROM fact_sales_monthly\n",
    "WHERE sold_quantity =0\n",
    "\"\"\"\n",
    "zero_quantity=pd.read_sql_query(query, con)\n",
    "zero_quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1a9f3b-e9d3-4fd8-a329-09a944b75afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking products with the minimum sold quantity\n",
    "query=\"\"\"SELECT category, COUNT (category)\n",
    "FROM dim_product\n",
    "WHERE product_code IN (SELECT product_code FROM fact_sales_monthly WHERE sold_quantity = 0)\n",
    "GROUP By category\n",
    "\"\"\"\n",
    "min_quantity_product=pd.read_sql_query(query, con)\n",
    "min_quantity_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22957d97-8a30-49b9-a00e-038299c8930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking products with the maximum sold quantity\n",
    "query=\"\"\"SELECT product, category, COUNT (category)\n",
    "FROM dim_product\n",
    "WHERE product_code IN (SELECT product_code FROM fact_sales_monthly WHERE sold_quantity = 4127)\n",
    "\"\"\"\n",
    "max_quantity_product=pd.read_sql_query(query, con)\n",
    "max_quantity_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d6021a-0547-475b-887c-d081137c0094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a histogram to check the distribution of the sold quantities\n",
    "plt.hist(sold_quantity['sold_quantity'], bins=50, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('sold quantity')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Distribution of sold quantities')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a6a0a-701e-4f34-97a7-ad6cc4fa0314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating percentiles for the sold quantity values\n",
    "print(np.percentile(sold_quantity['sold_quantity'], [80, 85, 90, 95, 99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e17455-cabd-413c-a297-0053065238f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking products with sold quantities higher than or equal to 126 per year (90th percentile)\n",
    "query=\"\"\"SELECT category, COUNT (category)\n",
    "FROM dim_product\n",
    "WHERE product_code IN (SELECT product_code FROM fact_sales_monthly WHERE sold_quantity >= 126)\n",
    "GROUP By category\n",
    "\"\"\"\n",
    "percentile90=pd.read_sql_query(query, con)\n",
    "percentile90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2c35e6-0163-424d-8b92-c67cc9903fcc",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_12'></a>\n",
    "\n",
    "* The table 'fact_sales_monthly' has 209 unique customers.\n",
    "* The table contains data for 5 years: 2018-2022.\n",
    "* There are only 14 unique products represented in this table.\n",
    "* All these products are from division P & A, segment Peripherals.\n",
    "* There are no other segments represented in the table 'fact_sales_monthly' other than Peripherals.\n",
    "* These products belong to 2 categories: Graphic Card (4 products) and Internal HDD (10 products).\n",
    "* All 4 regions are represented in the table 'fact_sales_monthly'.\n",
    "* One and the same product is sold to the same customer several times during one fiscal year, with different sold quantities of the product.\n",
    "* The table contains products that were not sold, and their sold quantity is marked as 0.\n",
    "* Half of the products are sold in quantities less than 20.\n",
    "* There is a product with an extreme high sold quantity equal to 4127, and this is the graphic card AQ Mforce Gen X.\n",
    "* This high quantity can be due to an order from a big company.\n",
    "* The further analysis will be conducted per region and not per product category, \\\n",
    "  because the data on sold quantities is available only for 2 product categories out of 14, but is present for all 4 regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7411550f-da69-4a32-8b72-bdb56810e680",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526c6e5-7c62-4c6c-80f9-68172d34a44b",
   "metadata": {},
   "source": [
    "<h2>EDA summary</h2> <a id='summary_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5172e5-f55c-4e75-9142-42f1688d4306",
   "metadata": {},
   "source": [
    "* The __range of years__ in the tables: 2018-2022.\n",
    "* The __number of unique customers__ in the tables: 209.\n",
    "* The __number of unique products:__\n",
    "    * 'dim_product': 397\n",
    "    * 'fact_manufacturing_cost': 389\n",
    "    * 'fact_gross_price': 389\n",
    "    * 'fact_sales_monthly': 14\n",
    "* __Outliers:__\n",
    "    * 'fact_pre_discount': no extreme discounts that could count as outliers\n",
    "    * 'fact_manufacturing_cost': outliers values correspond to categories that require high costs in the hardware production\n",
    "    * 'fact_gross_price': outliers values correspond to categories that have high pricing \\\n",
    "      These outliers are from the same product categories as the outliers from the table 'fact_manufacturing_cost'.\n",
    "    * 'fact_sales_monthly': the graphic card AQ Mforce Gen X has an extreme high sold quantity, which can be due to an order from a big company\n",
    "* __The tables will be used as follows:__\n",
    "    * 'dim_customer': to explore the market and how it has shifted\n",
    "    * 'dim_product': to find out what product segments and categories are most profitable (when there is enough data on product segments)\n",
    "    * 'fact_pre_discount': to calculate net revenue\n",
    "    * 'fact_manufacturing_cost': to calculate gross profit\n",
    "    * 'fact_gross_price': to calculate gross revenue\n",
    "    * 'fact_sales_monthly': to calculate gross revenue\n",
    "* __The following variables were created:__\n",
    "    * 'discount': the column 'pre_invoice_discount_pct' with discounts from the table 'fact_pre_discount'\n",
    "    * 'manufacture_cost': the column 'manufacturing_cost' with manufacturing costs from the table 'fact_manufacturing_cost'\n",
    "    * 'gross_price': the column 'gross_price' with gross prices from the table 'fact_gross_price'\n",
    "    * 'sold_quantity': the column 'sold_quantity' with sold quantities from the table 'fact_sales_monthly'\n",
    "\n",
    "__*Conclusion:*__ \\\n",
    "  The further analysis will be conducted per region and not per product category, \\\n",
    "  because the data on sold quantities the table 'fact_sales_monthly' is available only for 2 product categories out of 14, but is present for all 4 regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7235e5-a10f-4123-96ca-b94591d25ca5",
   "metadata": {},
   "source": [
    "__In the table 'dim_customer':__\n",
    "* one row represents one unique customer\n",
    "* the requirement that for one market there should be one region, is satisfied\n",
    "* 8 products have no data on manufacturing costs\n",
    "\n",
    "__In the table 'dim_product':__\n",
    "* one row represents one unique product\n",
    "* there are 3 unique divisions, 6 unique segments, and 14 unique product categories\n",
    "* the category Business Laptop belongs to 2 segments: Notebook and Desktop, but to one division - PC\n",
    "\n",
    "__In the table 'fact_pre_discount':__\n",
    "* one row corresponds to one discount value per year for each customer\n",
    "\n",
    "__In the table 'fact_manufacturing_cost':__\n",
    "* one row corresponds to a manufacturing cost per product for one production year\n",
    "* not every product is represented in the table each year\n",
    "\n",
    "__In the table 'fact_gross_price':__\n",
    "* one row corresponds to a gross price per product for each fiscal year\n",
    "* not every product is represented in the table each year\n",
    "* the amount of rows and unique products is the same as in the table 'fact_manufacturing_cost'\n",
    "* the distribution of gross price values corresponds with the distribution of manufacturing costs\n",
    "\n",
    "__In the table 'fact_sales_monthly':__\n",
    "* there are only 14 unique products: division P & A, segment Peripherals, categories: Graphic Card (4 products) and Internal HDD (10 products)\n",
    "* there are no other product segments represented in the table\n",
    "* all 4 regions are represented in the table\n",
    "* one and the same product is sold to the same customer several times during one fiscal year, with different sold quantities of the product\n",
    "* there are products that were not sold, and their sold quantity is marked as 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dc4684-1b7f-4e8b-b7ef-ed0c63310a71",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85587f63-1824-48e6-96cb-50ad8307dbfa",
   "metadata": {},
   "source": [
    "<h1>3. Financial analysis</h1> <a id='analysis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a66de27-d8c5-4628-a823-bf6ff65eecd1",
   "metadata": {},
   "source": [
    "<h2>3.1. Revenue</h2> <a id='revenue'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c3b284-f400-46e9-88de-fc1960bafc46",
   "metadata": {},
   "source": [
    "__Gross revenue__ (total revenue, total sales) is the total income before subtracting any expenses. \\\n",
    "gross revenue = quantity * price = number of items sold * revenue per item \\\n",
    "Gross revenue is calculated as the total sales before discounts or returns.\n",
    "\n",
    "__Net revenue__ is the total amount the company makes from its operations minus any adjustments such as refunds, returns, discounts and allowances. \\\n",
    "net revenue = gross revenue - (returns + discounts + allowances) \\\n",
    "Sales allowance arises when the customer agrees to keep the products at a price lower than the original price.\n",
    "\n",
    "*__Assumption:__* \\\n",
    "In the dataset there is no information on refunds, returns and allowances. \\\n",
    "So net revenue will be calculated from the available data as gross revenue minus discounts. \\\n",
    "net revenue = gross revenue  discounts\n",
    "\n",
    "__Revenue per source:__\n",
    "* revenue per region \\\n",
    "  In this research the revenue will be calculated per region and not per product category, \\\n",
    "  because the table 'fact_sales_monthly' with sold quantities has data only on 2 product categories out of 14, but all 4 regions are represented there.\n",
    "* changes in revenue of different regions per year\n",
    "\n",
    "__Data for the analysis:__\n",
    "* revenue per product: table 'fact_gross_price'\n",
    "* sold quantity: table 'fact_sales_monthly'\n",
    "* discount per product: table 'fact_pre_discount'\n",
    "* region: table 'dim_customer'\n",
    "\n",
    "__Revenue is used to:__\n",
    "* track whether the company is growing or losing money over years\n",
    "* identify high-impact revenue regions\n",
    "* compute other financial metrics such as gross profit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ae3d7d-498d-40a7-a6c6-00c59b96e704",
   "metadata": {},
   "source": [
    "<h2>3.1.1. Gross revenue</h2> <a id='gross_revenue'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52904bb3-7530-4f8a-84fb-8f42d667843c",
   "metadata": {},
   "source": [
    "<h3>Total gross revenue</h3> <a id='total_gross_revenue'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae4f4e1-5bd6-4514-827d-57379e47de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating total gross revenue\n",
    "query=\"\"\"\n",
    "SELECT \n",
    "    SUM(sales.sold_quantity * price.gross_price) AS total_revenue\n",
    "FROM \n",
    "    fact_sales_monthly sales\n",
    "JOIN \n",
    "    fact_gross_price price ON sales.product_code = price.product_code AND sales.fiscal_year = price.fiscal_year\n",
    "\"\"\"\n",
    "total_revenue=pd.read_sql_query(query, con)\n",
    "total_revenue.round().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160ab4ec-787e-4ade-9dc5-acd351dca2e9",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63533351-45d7-4709-b1f9-a8f1c27fc76e",
   "metadata": {},
   "source": [
    "<h3>Gross revenue per year</h3> <a id='gross_revenue_per_year'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20fb32f-0f16-4270-852b-954d7d2ed83a",
   "metadata": {},
   "source": [
    "Checking how gross revenue has changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c775da8c-6d09-4e02-885e-d4a91da410e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating gross revenue per year\n",
    "query=\"\"\"\n",
    "SELECT\n",
    "    sales.fiscal_year,\n",
    "    CAST (SUM(sales.sold_quantity * price.gross_price) AS INTEGER) AS year_revenue\n",
    "FROM \n",
    "    fact_sales_monthly sales\n",
    "JOIN \n",
    "    fact_gross_price price ON sales.product_code = price.product_code AND sales.fiscal_year = price.fiscal_year\n",
    "GROUP BY\n",
    "    sales.fiscal_year\n",
    "ORDER BY \n",
    "    sales.fiscal_year\n",
    "\"\"\"\n",
    "year_revenue=pd.read_sql_query(query, con)\n",
    "year_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9be92-bce6-4b2b-8ace-873b8342b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting gross revenue per year\n",
    "fig_year_revenue=px.bar(year_revenue, x=\"fiscal_year\", y=\"year_revenue\", width=800, height=500)\n",
    "fig_year_revenue.update_layout(xaxis_title = 'year', yaxis_title = 'gross revenue',  title='Gross revenue per year')\n",
    "fig_year_revenue.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5592d6ba-50f1-4b2b-9c3e-f57ae009115a",
   "metadata": {},
   "source": [
    "Each year there is a growth in gross revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd05f777-7710-48a6-bba9-78494eb22f54",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c1fe3-a6fc-4410-b9d5-a9527ad5d890",
   "metadata": {},
   "source": [
    "<h3>Gross revenue growth rate</h3> <a id='gross_revenue_growth_rate'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcfcfc2-b581-4c00-b812-8a30c9d8b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating revenue growth rate\n",
    "# revenue growth rate = (current period's revenue - previous period's revenue) / previous period's revenue * 100\n",
    "year_revenue['growth_rate'] = year_revenue['year_revenue'].pct_change(periods=1)\n",
    "year_revenue['growth_rate'] = year_revenue['growth_rate'].map('{:.0%}'.format)\n",
    "year_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f118e-02cf-4d14-ba89-3eb45731844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative way to calculate revenue growth rate in SQL\n",
    "## calculating the percentage change in gross revenue between current year and previous year\n",
    "query=\"\"\"\n",
    "SELECT\n",
    "    sales.fiscal_year,\n",
    "    CAST(SUM(sales.sold_quantity * price.gross_price) AS INTEGER) AS year_revenue,\n",
    "    CAST(CASE \n",
    "        WHEN LAG(SUM(sales.sold_quantity * price.gross_price)) \n",
    "             OVER (ORDER BY sales.fiscal_year) IS NULL THEN NULL\n",
    "        ELSE \n",
    "            ((SUM(sales.sold_quantity * price.gross_price) - \n",
    "              LAG(SUM(sales.sold_quantity * price.gross_price)) \n",
    "              OVER (ORDER BY sales.fiscal_year)) /\n",
    "             LAG(SUM(sales.sold_quantity * price.gross_price)) \n",
    "             OVER (ORDER BY sales.fiscal_year)) * 100\n",
    "    END AS INTEGER) || '%' AS percentage_change\n",
    "FROM \n",
    "    fact_sales_monthly sales\n",
    "JOIN \n",
    "    fact_gross_price price ON sales.product_code = price.product_code AND sales.fiscal_year = price.fiscal_year\n",
    "GROUP BY\n",
    "    sales.fiscal_year\n",
    "ORDER BY \n",
    "    sales.fiscal_year\n",
    "\"\"\"\n",
    "year_revenue_percentage=pd.read_sql_query(query, con)\n",
    "year_revenue_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22730b24-7bf3-4394-ba16-7b0ee094ecdf",
   "metadata": {},
   "source": [
    "The change in revenue between current year and previous year is decreasing over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404ef0c-8919-4c3b-b0cb-39c4aad471bd",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3298953d-5f11-40f7-9c4f-5e4874804c7d",
   "metadata": {},
   "source": [
    "<h3>Gross revenue per region</h3> <a id='gross_revenue_per_region'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7c70ad-a554-4e71-8926-72a754de2355",
   "metadata": {},
   "source": [
    "Exploring revenue in different regions. \\\n",
    "Revenue data segmented by region helps identify high-impact revenue regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b931722-50bc-4e7f-a5bc-5b6b939f2058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating gross revenue per region\n",
    "query=\"\"\"\n",
    "SELECT\n",
    "    customer.region,\n",
    "    CAST(SUM(sales.sold_quantity * price.gross_price) AS INTEGER) AS region_revenue\n",
    "FROM \n",
    "    fact_sales_monthly sales\n",
    "JOIN \n",
    "    fact_gross_price price ON sales.product_code = price.product_code AND sales.fiscal_year = price.fiscal_year\n",
    "JOIN\n",
    "    dim_customer customer ON sales.customer_code = customer.customer_code\n",
    "GROUP BY\n",
    "    customer.region\n",
    "ORDER BY \n",
    "    region_revenue DESC\n",
    "\"\"\"\n",
    "region_revenue=pd.read_sql_query(query, con)\n",
    "region_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070e0d5-04e9-469f-85ff-2aa51bb3b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting gross revenue per region\n",
    "fig_region_revenue=px.bar(region_revenue, x=\"region\", y=\"region_revenue\", width=800, height=500)\n",
    "fig_region_revenue.update_layout(xaxis_title = 'region', yaxis_title = 'gross revenue',  title='Gross revenue per region')\n",
    "fig_region_revenue.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4026a8-4498-4f59-b1cf-52a3ff1bfb19",
   "metadata": {},
   "source": [
    "- The most profitable region is: APAC.\n",
    "- The least profitable region is: LATAM.\n",
    "- The total revenues of NA and EU regions are approximately the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123fb755-701b-4e37-9e6f-700b22337518",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e233a0a4-4fc5-45ca-93c8-8bcd28b2bd8c",
   "metadata": {},
   "source": [
    "<h3>Gross revenue per region over time</h3> <a id='gross_revenue_per_region_year'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3683c8f-6f8d-46b1-b9af-8bf753b5506d",
   "metadata": {},
   "source": [
    "Investigating:\n",
    "* how revenue has changed in regions over time\n",
    "* if the market has shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473861a2-d7e2-401d-9655-21b1b8a94973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating gross revenue per region per year\n",
    "query=\"\"\"\n",
    "SELECT\n",
    "    customer.region,\n",
    "    sales.fiscal_year,\n",
    "    CAST(SUM(sales.sold_quantity * price.gross_price) AS INTEGER) AS region_yearly_revenue\n",
    "FROM \n",
    "    fact_sales_monthly sales\n",
    "JOIN \n",
    "    fact_gross_price price ON sales.product_code = price.product_code AND sales.fiscal_year = price.fiscal_year\n",
    "JOIN\n",
    "    dim_customer customer ON sales.customer_code = customer.customer_code\n",
    "GROUP BY\n",
    "    customer.region, sales.fiscal_year\n",
    "ORDER BY \n",
    "    customer.region, sales.fiscal_year\n",
    "\"\"\"\n",
    "region_yearly_revenue=pd.read_sql_query(query, con)\n",
    "region_yearly_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dfce6d-0477-4b89-a253-6fb2381d3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the percentage change in gross revenue per region between current year and previous year\n",
    "query=\"\"\"\n",
    "WITH yearly_revenue AS (\n",
    "    SELECT\n",
    "        customer.region,\n",
    "        sales.fiscal_year,\n",
    "        CAST(SUM(sales.sold_quantity * price.gross_price) AS INTEGER) AS region_yearly_revenue\n",
    "    FROM \n",
    "        fact_sales_monthly sales\n",
    "    JOIN \n",
    "        fact_gross_price price ON sales.product_code = price.product_code AND sales.fiscal_year = price.fiscal_year\n",
    "    JOIN\n",
    "        dim_customer customer ON sales.customer_code = customer.customer_code\n",
    "    GROUP BY\n",
    "        customer.region, sales.fiscal_year\n",
    ")\n",
    "SELECT\n",
    "    region,\n",
    "    fiscal_year,\n",
    "    region_yearly_revenue,\n",
    "    CAST(CASE\n",
    "        WHEN LAG(region_yearly_revenue) OVER (PARTITION BY region ORDER BY fiscal_year) IS NULL THEN NULL\n",
    "        ELSE (\n",
    "            (region_yearly_revenue - LAG(region_yearly_revenue) OVER (PARTITION BY region ORDER BY fiscal_year)) * 100.0\n",
    "            / LAG(region_yearly_revenue) OVER (PARTITION BY region ORDER BY fiscal_year)\n",
    "        )\n",
    "    END AS INTEGER) || '%' AS percentage_change\n",
    "FROM \n",
    "    yearly_revenue\n",
    "ORDER BY \n",
    "    region, fiscal_year\n",
    "\"\"\"\n",
    "region_year_percentage=pd.read_sql_query(query, con)\n",
    "region_year_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2edaf0a-72f4-4c7c-8298-56709dff5d09",
   "metadata": {},
   "source": [
    "The revenue is growing each year in every region, except for LATAM in 2021 when there was a drop in its gross revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61054b95-6e73-44ae-ae9c-f09397745f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting revenue per region per year\n",
    "fig_revenue=px.scatter(region_yearly_revenue, x=\"fiscal_year\", y=\"region_yearly_revenue\", color='region', width=1000, height=500)\n",
    "fig_revenue.update_layout(xaxis_title = 'year', yaxis_title = 'gross revenue',  title='Annual revenue per region')\n",
    "fig_revenue.update_layout(xaxis = dict(tickmode = 'array', tickvals = region_yearly_revenue['fiscal_year']))\n",
    "fig_revenue.update_traces(marker={'size': 8})\n",
    "#fig_revenue.update_xaxes(showgrid=False)\n",
    "#fig_revenue.update_yaxes(showgrid=False)\n",
    "#fig_revenue.update_layout(template='simple_white', legend=dict(yanchor=\"top\", y=0.98, xanchor=\"left\", x=0.02))\n",
    "fig_revenue.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2647c1-1f26-4fd0-a6d1-e815c972b138",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_13'></a>\n",
    "\n",
    "* __Gross revenue:__\n",
    "    * Each year there is a growth in gross revenue.\n",
    "    * The revenue growth rate is decreasing over time.\n",
    "* __Gross revenue per region:__\n",
    "    * The most profitable region is: APAC (Asia-Pacific).\n",
    "    * The least profitable region is: LATAM (Latin America).\n",
    "    * The total revenues of NA (North America) and EU (European Union) regions are approximately the same.\n",
    "\n",
    "* __Gross revenue per region per year:__\n",
    "    * The revenue is growing each year in every region, except for LATAM in 2021 when there was a drop in its gross revenue.\n",
    "    * Over time, the analyzed market has changed only in EU and NA regions.\n",
    "    * Before 2021 NA has higher revenue than EU. From 2021 the revenue of EU starts to be higher than in NA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8194738b-aa3d-4297-9cd3-1be7e1915a44",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe216a8-316b-427f-8652-14331eb2e4dc",
   "metadata": {},
   "source": [
    "<h2>3.1.2. Net revenue</h2> <a id='net_revenue'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89a21bf-c037-45ed-b3fe-66aa9dcc8824",
   "metadata": {},
   "source": [
    "<h3>Total net revenue</h3> <a id='total_net_revenue'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7cb624-2555-412d-923e-d73655429fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating total net revenue\n",
    "query=\"\"\"\n",
    "SELECT \n",
    "    SUM(\n",
    "        (gross_price.gross_price * sales.sold_quantity) * (1 - discount.pre_invoice_discount_pct)\n",
    "    ) AS net_revenue\n",
    "FROM \n",
    "    fact_sales_monthly sales\n",
    "JOIN \n",
    "    fact_gross_price gross_price\n",
    "    ON sales.product_code = gross_price.product_code\n",
    "    AND sales.fiscal_year = gross_price.fiscal_year\n",
    "JOIN \n",
    "    fact_pre_discount discount\n",
    "    ON sales.customer_code = discount.customer_code\n",
    "    AND sales.fiscal_year = discount.fiscal_year\n",
    "\"\"\"\n",
    "net_revenue=pd.read_sql_query(query, con)\n",
    "net_revenue.round().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b32b014-f955-4e5b-a3aa-d480d15bc60a",
   "metadata": {},
   "source": [
    "<h3>Net revenue per year</h3> <a id='net_revenue_per_year'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99a85f7-c8f3-45fc-b0e8-ece59cef0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating net revenue per year\n",
    "query=\"\"\"\n",
    "SELECT \n",
    "    sales.fiscal_year,\n",
    "    SUM(\n",
    "        (gross_price.gross_price * sales.sold_quantity) * (1 - discount.pre_invoice_discount_pct)\n",
    "    ) AS year_net_revenue\n",
    "FROM \n",
    "    fact_sales_monthly sales\n",
    "JOIN \n",
    "    fact_gross_price gross_price\n",
    "    ON sales.product_code = gross_price.product_code\n",
    "    AND sales.fiscal_year = gross_price.fiscal_year\n",
    "JOIN \n",
    "    fact_pre_discount discount\n",
    "    ON sales.customer_code = discount.customer_code\n",
    "    AND sales.fiscal_year = discount.fiscal_year\n",
    "GROUP BY \n",
    "    sales.fiscal_year\n",
    "ORDER BY \n",
    "    sales.fiscal_year\n",
    "\"\"\"\n",
    "year_net_revenue=pd.read_sql_query(query, con)\n",
    "year_net_revenue.round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81579764-12b3-43dc-9b04-da7ad362c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting net revenue vs gross revenue per year\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=year_net_revenue['fiscal_year'],\n",
    "    y=year_net_revenue['year_net_revenue'],\n",
    "    name='net revenue'\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    x=year_revenue['fiscal_year'],\n",
    "    y=year_revenue['year_revenue'],\n",
    "    name='gross revenue',\n",
    "    opacity = 0.5\n",
    "))\n",
    "# barmode='overlay' to display one bar inside the other\n",
    "fig.update_layout(barmode='group', title='Yearly revenue: net vs gross')\n",
    "fig.update_layout(xaxis=dict(title=dict(text=\"year\")), yaxis=dict(title=dict(text=\"revenue\")), width=1000, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d1f344-1c34-4315-b0fe-c0fb2fd677f3",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435082a4-dd1d-4bed-9003-4840a6db5058",
   "metadata": {},
   "source": [
    "<h3>Net revenue growth rate</h3> <a id='net_revenue_growth_rate'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da018a53-5b71-4ea8-969e-2b86fd18f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating net revenue growth rate\n",
    "year_net_revenue['year_net_revenue'].pct_change(periods=1).map('{:.0%}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e4104-75a4-4042-8209-8ed6f077fe88",
   "metadata": {},
   "source": [
    "<h3>Net revenue per region</h3> <a id='net_revenue_per_region'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2cfe7-c087-45b2-a4e3-6be545a4134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating net revenue per region\n",
    "query=\"\"\"\n",
    "SELECT \n",
    "    customer.region,\n",
    "    CAST(SUM(\n",
    "        (gross_price.gross_price * sales.sold_quantity) * (1 - discount.pre_invoice_discount_pct)\n",
    "    ) AS INTEGER) AS region_net_revenue\n",
    "FROM \n",
    "    fact_sales_monthly sales\n",
    "JOIN \n",
    "    fact_gross_price gross_price\n",
    "    ON sales.product_code = gross_price.product_code\n",
    "    AND sales.fiscal_year = gross_price.fiscal_year\n",
    "JOIN \n",
    "    fact_pre_discount discount\n",
    "    ON sales.customer_code = discount.customer_code\n",
    "    AND sales.fiscal_year = discount.fiscal_year\n",
    "JOIN\n",
    "    dim_customer customer\n",
    "    ON sales.customer_code = customer.customer_code\n",
    "GROUP BY \n",
    "    customer.region\n",
    "ORDER BY \n",
    "    region_net_revenue DESC\n",
    "\"\"\"\n",
    "region_net_revenue=pd.read_sql_query(query, con)\n",
    "region_net_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08586517-f4e0-4f67-8c21-2b85bb33b7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting net revenue vs gross revenue per region\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=region_net_revenue['region'],\n",
    "    y=region_net_revenue['region_net_revenue'],\n",
    "    name='net revenue'\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    x=region_revenue['region'],\n",
    "    y=region_revenue['region_revenue'],\n",
    "    name='gross revenue',\n",
    "    opacity = 0.5\n",
    "))\n",
    "fig.update_layout(barmode='group', title='Region revenue: net vs gross')\n",
    "fig.update_layout(xaxis=dict(title=dict(text=\"region\")), yaxis=dict(title=dict(text=\"revenue\")), width=1000, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43272d3e-daa3-4682-b4aa-2f1f97a831bd",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fd1360-578a-46d7-896e-b6872574c61a",
   "metadata": {},
   "source": [
    "<h3>Net revenue per region over time</h3> <a id='net_revenue_per_region_year'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549fc659-02cf-4d84-bfbd-00d9ebe75a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating net revenue per region per year\n",
    "query=\"\"\"\n",
    "SELECT \n",
    "    customer.region,\n",
    "    sales.fiscal_year,\n",
    "    CAST(SUM(\n",
    "        (gross_price.gross_price * sales.sold_quantity) * (1 - discount.pre_invoice_discount_pct))\n",
    "    AS INTEGER) AS region_yearly_net_revenue\n",
    "FROM \n",
    "    fact_sales_monthly sales\n",
    "JOIN \n",
    "    fact_gross_price gross_price\n",
    "    ON sales.product_code = gross_price.product_code\n",
    "    AND sales.fiscal_year = gross_price.fiscal_year\n",
    "JOIN \n",
    "    fact_pre_discount discount\n",
    "    ON sales.customer_code = discount.customer_code\n",
    "    AND sales.fiscal_year = discount.fiscal_year\n",
    "JOIN\n",
    "    dim_customer customer\n",
    "    ON sales.customer_code = customer.customer_code\n",
    "GROUP BY \n",
    "    customer.region, sales.fiscal_year\n",
    "ORDER BY \n",
    "    customer.region, sales.fiscal_year\n",
    "\"\"\"\n",
    "region_yearly_net_revenue=pd.read_sql_query(query, con)\n",
    "region_yearly_net_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c545c0-54b5-4fb2-9dd2-e6528c1b6fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the percentage change in net revenue per region between current year and previous year\n",
    "query=\"\"\"\n",
    "WITH region_net_revenue AS (\n",
    "    SELECT \n",
    "    customer.region,\n",
    "    sales.fiscal_year,\n",
    "    CAST(SUM(\n",
    "        (gross_price.gross_price * sales.sold_quantity) * (1 - discount.pre_invoice_discount_pct))\n",
    "    AS INTEGER) AS region_yearly_net_revenue\n",
    "FROM \n",
    "    fact_sales_monthly sales\n",
    "JOIN \n",
    "    fact_gross_price gross_price\n",
    "    ON sales.product_code = gross_price.product_code\n",
    "    AND sales.fiscal_year = gross_price.fiscal_year\n",
    "JOIN \n",
    "    fact_pre_discount discount\n",
    "    ON sales.customer_code = discount.customer_code\n",
    "    AND sales.fiscal_year = discount.fiscal_year\n",
    "JOIN\n",
    "    dim_customer customer\n",
    "    ON sales.customer_code = customer.customer_code\n",
    "GROUP BY \n",
    "    customer.region, sales.fiscal_year\n",
    "ORDER BY \n",
    "    customer.region, sales.fiscal_year\n",
    ")\n",
    "SELECT\n",
    "    region,\n",
    "    fiscal_year,\n",
    "    region_yearly_net_revenue,\n",
    "    CAST(CASE\n",
    "        WHEN LAG(region_yearly_net_revenue) OVER (PARTITION BY region ORDER BY fiscal_year) IS NULL THEN NULL\n",
    "        ELSE (\n",
    "            (region_yearly_net_revenue - LAG(region_yearly_net_revenue) OVER (PARTITION BY region ORDER BY fiscal_year)) * 100.0\n",
    "            / LAG(region_yearly_net_revenue) OVER (PARTITION BY region ORDER BY fiscal_year)\n",
    "        )\n",
    "    END AS INTEGER) || '%' AS net_revenue_change\n",
    "FROM \n",
    "    region_net_revenue\n",
    "ORDER BY \n",
    "    region, fiscal_year\n",
    "\"\"\"\n",
    "region_yearly_net_revenue_change=pd.read_sql_query(query, con)\n",
    "region_yearly_net_revenue_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0960eb-e50e-41c6-9133-5b8c1e35145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting net revenue per region per year\n",
    "fig_net_revenue=px.scatter(region_yearly_net_revenue, x=\"fiscal_year\", y=\"region_yearly_net_revenue\", color='region', width=1000, height=500)\n",
    "fig_net_revenue.update_layout(xaxis_title = 'year', yaxis_title = 'net revenue',  title='Annual net revenue per region')\n",
    "fig_net_revenue.update_layout(xaxis = dict(tickmode = 'array', tickvals = region_yearly_net_revenue['fiscal_year']))\n",
    "fig_net_revenue.update_traces(marker={'size': 8})\n",
    "fig_net_revenue.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c0f17e-45f7-467e-892d-e9d713fb03da",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_14'></a>\n",
    "\n",
    "* Net revenue is calculated here as gross revenue minus discounts.\n",
    "* Net revenue is calculated without refunds, returns and allowances due to the lack of information on them.\n",
    "* Net revenue follows the same regional and yearly patterns as gross revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3b241c-4b44-47d4-8c5b-3cc81f666964",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaeb635-5677-46d1-a2c9-bb838cf40484",
   "metadata": {},
   "source": [
    "<h2>3.2. Gross profit</h2> <a id='gross_profit'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb1a2c-782c-4cb2-b78e-7adc3ac7a052",
   "metadata": {},
   "source": [
    "__Gross profit__ is the amount of money left after deducting manufacturing costs. \\\n",
    "gross profit = net revenue - cost of goods sold (COGS) \\\n",
    "Cost of goods sold (COGS) are direct costs associated with producing goods.\n",
    "\n",
    "*__Assumption:__*\n",
    "The manufacturing costs are stored in the table 'fact_manufacturing_cost'. \\\n",
    "Each row corresponds to a manufacturing cost per product for one production year 'cost_year'. \\\n",
    "To be able to calculate gross profit, it is necessary to merge this table not only by 'product_code', but also by 'cost_year', since COGS is different each year for every product. \\\n",
    "All other tables have the column 'fiscal_year', which is not the same as 'cost_year':\n",
    "- cost_year - year of production\n",
    "- fiscal_year - year of transaction \\\n",
    "For example, a product could be manufactured in 2018, but sold in 2019 or 2020.\n",
    "\n",
    "But to be able to calculate gross profit, an assumption is made that 'cost_year'='fiscal_year'.\n",
    "\n",
    "__Operating profit__ indicates how much a company earns from its core activities, and shows its productivity and operational efficiency. \\\n",
    "operating profit = gross profit - operating expenses \\\n",
    "Operating expenses: salaries, rent, marketing, electricity, internet (all expenses for core activities). \\\n",
    "Here it is not possible to calculate it, since there is no data on operating expenses.\n",
    "\n",
    "__Net profit__ is the amount of money the company actually earns. \\\n",
    "net profit = operating profit - (taxes + loans + interest) \\\n",
    "Here it is not possible to calculate it, since there is no data for it.\n",
    "\n",
    "__Profit per source:__\n",
    "* profit per region\n",
    "* changes in profit of different regions per year\n",
    "\n",
    "__Data for the analysis:__\n",
    "* net revenue: step 3.1.2. Net revenue\n",
    "* manufacturing cost: table 'fact_manufacturing_cost'\n",
    "* region: table 'dim_customer'\n",
    "\n",
    "__Gross profit is used to:__\n",
    "* show how much money a company earns from the sale of its products\n",
    "* understand if company's production and pricing are efficient enough to meet revenue goals\n",
    "* detect whether the company sold enough goods to cover salaries, rent, and taxes\n",
    "* compute other financial metrics such as gross margin (gross profit margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e61f84-bda5-4047-8707-3fc1261c28bd",
   "metadata": {},
   "source": [
    "<h3>Total gross profit</h3> <a id='total_gross_profit'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6f994-b7e6-49c9-8672-5da8f3eca0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating total gross profit\n",
    "query=\"\"\"\n",
    "SELECT\n",
    "    SUM((price.gross_price - cost.manufacturing_cost - price.gross_price * discount.pre_invoice_discount_pct) * sales.sold_quantity) AS gross_profit\n",
    "FROM\n",
    "    fact_sales_monthly sales\n",
    "JOIN\n",
    "    fact_gross_price price\n",
    "    ON sales.product_code = price.product_code\n",
    "    AND sales.fiscal_year = price.fiscal_year\n",
    "JOIN\n",
    "    fact_manufacturing_cost cost\n",
    "    ON sales.product_code = cost.product_code\n",
    "    AND sales.fiscal_year = cost.cost_year\n",
    "JOIN\n",
    "    fact_pre_discount discount\n",
    "    ON  sales.customer_code = discount.customer_code\n",
    "    AND sales.fiscal_year = discount.fiscal_year\n",
    "\"\"\"\n",
    "gross_profit=pd.read_sql_query(query, con)\n",
    "gross_profit.round().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2793ecd-6b58-4080-92e7-679ca2b8c58e",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52cdc7b-73e9-4b3e-bf11-ebbeaf4c20d6",
   "metadata": {},
   "source": [
    "<h3>Gross profit per year</h3> <a id='gross_profit_per_year'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437940e1-a1ec-4963-8538-1ef3b2ff0be4",
   "metadata": {},
   "source": [
    "Checking how gross profit has changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40290d1e-753f-4859-a372-ca0253ad9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating gross profit per year\n",
    "query=\"\"\"\n",
    "SELECT\n",
    "    sales.fiscal_year,\n",
    "    SUM((price.gross_price - cost.manufacturing_cost - price.gross_price * discount.pre_invoice_discount_pct) * sales.sold_quantity) AS year_profit\n",
    "FROM\n",
    "    fact_sales_monthly sales\n",
    "JOIN\n",
    "    fact_gross_price price\n",
    "    ON sales.product_code = price.product_code\n",
    "    AND sales.fiscal_year = price.fiscal_year\n",
    "JOIN\n",
    "    fact_manufacturing_cost cost\n",
    "    ON sales.product_code = cost.product_code\n",
    "    AND sales.fiscal_year = cost.cost_year\n",
    "JOIN\n",
    "    fact_pre_discount discount\n",
    "    ON  sales.customer_code = discount.customer_code\n",
    "    AND sales.fiscal_year = discount.fiscal_year\n",
    "GROUP BY\n",
    "    sales.fiscal_year\n",
    "ORDER BY \n",
    "    sales.fiscal_year\n",
    "\"\"\"\n",
    "year_profit=pd.read_sql_query(query, con)\n",
    "year_profit.round().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc151845-b992-4db6-954e-3c0e5d81462f",
   "metadata": {},
   "source": [
    "Gross profit is increasing every year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1f32f1-b5d0-47c4-a425-63f516cd4724",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de40383-66ce-44d7-aeb2-27f0a0f3da4a",
   "metadata": {},
   "source": [
    "<h3>Gross profit vs revenues per year</h3> <a id='profit_revenues_year'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec916bd-ebb0-46f2-9518-0d873179b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing gross profit with gross and net revenues per year\n",
    "gross_net_revenue = year_revenue[['fiscal_year', 'year_revenue']].merge(year_net_revenue, on=['fiscal_year'])\n",
    "profit_revenue_year = gross_net_revenue.merge(year_profit, on=['fiscal_year'])\n",
    "profit_revenue_year.round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150df04-3bb4-4068-a792-f9676bd67515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting gross profit vs gross and net revenues per year\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=year_profit['fiscal_year'],\n",
    "    y=year_profit['year_profit'],\n",
    "    name='gross profit'\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    x=year_net_revenue['fiscal_year'],\n",
    "    y=year_net_revenue['year_net_revenue'],\n",
    "    name='net revenue',\n",
    "    opacity = 0.5\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    x=year_revenue['fiscal_year'],\n",
    "    y=year_revenue['year_revenue'],\n",
    "    name='gross revenue',\n",
    "    opacity = 0.5\n",
    "))\n",
    "fig.update_layout(barmode='group', title='Metrics by year: gross revenue, net revenue, gross profit')\n",
    "fig.update_layout(xaxis=dict(title=dict(text=\"year\")), yaxis=dict(title=dict(text=\"metrics\")), width=1000, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d12b6c-4cb1-4867-9dc0-a5e096cc54f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the difference between gross and net revenues, and between gross revenue and profit per year\n",
    "profit_revenue_year['net_to_gross_revenue_%'] = profit_revenue_year['year_net_revenue'] / profit_revenue_year['year_revenue'] * 100\n",
    "profit_revenue_year['profit_to_gross_revenue_%'] = profit_revenue_year['year_profit'] / profit_revenue_year['year_revenue'] * 100\n",
    "profit_revenue_year.round().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73aee58-d790-49d6-b075-b215e15b44a2",
   "metadata": {},
   "source": [
    "The net-to-gross revenue ratio (in %) and profit to gross revenue ratio (in %) is almost the same each year.\n",
    "\n",
    "From total revenue on average:\n",
    "* gross revenue - net revenue = 100% - 77% = 23% is invested in discounts\n",
    "* gross revenue - gross profit = 100% - 47% = 53% is spent on discounts and manufacturing costs\n",
    "* 53% - 23% = 30% is invested in manufacturing costs\n",
    "\n",
    "So from total revenue:\n",
    "* 47% of money is left\n",
    "* 53% of money is spent:\n",
    "    * 23% on discounts\n",
    "    * 30% on manufacturing costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c0f343-9dc9-477c-8d90-0338740ab47a",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa049467-c7de-423f-9f9f-488abc9f2eb4",
   "metadata": {},
   "source": [
    "<h3>Gross profit per region</h3> <a id='gross_profit_per_region'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdcf72e-46b4-4ce0-8a1c-46907786721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating gross profit per region\n",
    "query=\"\"\"\n",
    "SELECT\n",
    "    customer.region,\n",
    "    CAST(SUM((price.gross_price - cost.manufacturing_cost - price.gross_price * discount.pre_invoice_discount_pct) * sales.sold_quantity) \n",
    "    AS INTEGER) AS region_profit\n",
    "FROM\n",
    "    fact_sales_monthly sales\n",
    "JOIN\n",
    "    fact_gross_price price\n",
    "    ON sales.product_code = price.product_code\n",
    "    AND sales.fiscal_year = price.fiscal_year\n",
    "JOIN\n",
    "    fact_manufacturing_cost cost\n",
    "    ON sales.product_code = cost.product_code\n",
    "    AND sales.fiscal_year = cost.cost_year\n",
    "JOIN\n",
    "    fact_pre_discount discount\n",
    "    ON  sales.customer_code = discount.customer_code\n",
    "    AND sales.fiscal_year = discount.fiscal_year\n",
    "JOIN\n",
    "    dim_customer customer\n",
    "    ON sales.customer_code = customer.customer_code\n",
    "GROUP BY\n",
    "    customer.region\n",
    "ORDER BY \n",
    "    region_profit DESC\n",
    "\"\"\"\n",
    "region_profit=pd.read_sql_query(query, con)\n",
    "region_profit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f78dead-bc52-4421-b386-16d17b5f487a",
   "metadata": {},
   "source": [
    "Gross profit shows the same most profitable (APAC) and least profitable (LATAM) regions, like gross and net revenues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2472996a-7fff-4c15-aea8-16d991f72547",
   "metadata": {},
   "source": [
    "<h3>Gross profit vs revenues per region</h3> <a id='profit_revenues_region'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783dee68-6fc9-4e2b-bb23-c74e82c937f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing gross profit with gross and net revenues per region\n",
    "gross_net_revenue_region = region_revenue.merge(region_net_revenue, on=['region'])\n",
    "profit_revenue_region = gross_net_revenue_region.merge(region_profit, on=['region'])\n",
    "profit_revenue_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c63af82-4cfb-4014-bcd0-7c5c00bc8fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting gross profit vs gross and net revenues per region\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=region_profit['region'],\n",
    "    y=region_profit['region_profit'],\n",
    "    name='gross profit'\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    x=region_net_revenue['region'],\n",
    "    y=region_net_revenue['region_net_revenue'],\n",
    "    name='net revenue',\n",
    "    opacity = 0.5\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    x=region_revenue['region'],\n",
    "    y=region_revenue['region_revenue'],\n",
    "    name='gross revenue',\n",
    "    opacity = 0.5\n",
    "))\n",
    "fig.update_layout(barmode='group', title='Metrics by region: gross revenue, net revenue, gross profit')\n",
    "fig.update_layout(xaxis=dict(title=dict(text=\"region\")), yaxis=dict(title=dict(text=\"metrics\")), width=1000, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3e65e2-101c-4779-8ffc-07b85541084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the difference between gross and net revenues, and between gross revenue and profit per region\n",
    "profit_revenue_region['net_to_gross_revenue_%'] = (profit_revenue_region['region_net_revenue'] / profit_revenue_region['region_revenue'] * 100).round().astype(int)\n",
    "profit_revenue_region['profit_to_gross_revenue_%'] = (profit_revenue_region['region_profit'] / profit_revenue_region['region_revenue'] * 100).round().astype(int)\n",
    "profit_revenue_region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1095527f-bd17-49ee-a6b8-96ee96678a04",
   "metadata": {},
   "source": [
    "The net-to-gross revenue ratio (in %) and profit to gross revenue ratio (in %) is almost the same for each region.\n",
    "\n",
    "The same percentage across all regions for the ratio between gross and net revenue can indicate that discounts are calculated based on fixed percentages (a uniform discount rate per product).\n",
    "\n",
    "The ratio between gross revenue and gross profit across all regions can be consistent when COGS is the same in each region (the percentage of revenue spent on producing the goods is the same)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f5324-e71b-43dd-96a3-6024ba751efd",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d1945a-ba60-475c-9c29-77e46a05daeb",
   "metadata": {},
   "source": [
    "<h3>Gross profit per region over time</h3> <a id='gross_profit_per_region_year'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce12c8e-9b8a-444e-9fd0-df3202d1d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating gross profit per region per year\n",
    "query=\"\"\"\n",
    "SELECT\n",
    "    customer.region,\n",
    "    sales.fiscal_year,\n",
    "    CAST(SUM((price.gross_price - cost.manufacturing_cost - price.gross_price * discount.pre_invoice_discount_pct) * sales.sold_quantity) \n",
    "    AS INTEGER) AS region_yearly_profit\n",
    "FROM\n",
    "    fact_sales_monthly sales\n",
    "JOIN\n",
    "    fact_gross_price price\n",
    "    ON sales.product_code = price.product_code\n",
    "    AND sales.fiscal_year = price.fiscal_year\n",
    "JOIN\n",
    "    fact_manufacturing_cost cost\n",
    "    ON sales.product_code = cost.product_code\n",
    "    AND sales.fiscal_year = cost.cost_year\n",
    "JOIN\n",
    "    fact_pre_discount discount\n",
    "    ON  sales.customer_code = discount.customer_code\n",
    "    AND sales.fiscal_year = discount.fiscal_year\n",
    "JOIN\n",
    "    dim_customer customer\n",
    "    ON sales.customer_code = customer.customer_code\n",
    "GROUP BY\n",
    "    customer.region, sales.fiscal_year\n",
    "ORDER BY \n",
    "    customer.region, sales.fiscal_year\n",
    "\"\"\"\n",
    "region_yearly_profit=pd.read_sql_query(query, con)\n",
    "region_yearly_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc282e-6465-4219-8860-64868d546876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting gross profit per region per year\n",
    "fig_gross_profit=px.scatter(region_yearly_profit, x=\"fiscal_year\", y=\"region_yearly_profit\", color='region', width=1000, height=500)\n",
    "fig_gross_profit.update_layout(xaxis_title = 'year', yaxis_title = 'gross profit',  title='Annual gross profit per region')\n",
    "fig_gross_profit.update_layout(xaxis = dict(tickmode = 'array', tickvals = region_yearly_profit['fiscal_year']))\n",
    "fig_gross_profit.update_traces(marker={'size': 8})\n",
    "fig_gross_profit.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c90ab09-078a-4be7-a8e0-cd1e6cf6760f",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_15'></a>\n",
    "\n",
    "* An assumption is made that 'fiscal_year'='cost_year' to be able to calculate gross profit.\n",
    "* Operating and net profits cannot be calculated since there is no data on operating expenses in any of the tables of the database.\n",
    "* Gross profit follows the same regional and yearly patterns as gross and net revenues.\n",
    "* The net-to-gross revenue ratio (in %) and profit to gross revenue ratio (in %) is almost the same each year.\n",
    "* Each year from the total revenue on average:\n",
    "    * 47% of money is left as gross profit\n",
    "    * 53% of money is spent:\n",
    "        * 23% on discounts\n",
    "        * 30% on manufacturing costs\n",
    "* The net-to-gross revenue ratio (in %) and profit to gross revenue ratio (in %) is almost the same across all regions. \\\n",
    "  It can indicate that the costs are structured similarly across all regions:\n",
    "    * a consistent discount rate\n",
    "    * a uniform pricing strategy\n",
    "    * similar levels of direct costs related to manufacturing\n",
    "* Both across years and regions, the ratios (in %) between revenues and profit are on average the same:\n",
    "    * net revenue to gross revenue: 76%\n",
    "    * gross profit to gross revenue: 47%\n",
    "* This can indicate a financial structure that is highly standardized or governed by some fixed parameters that don't change year-to-year or region-to-region.\n",
    "* Uniform percentages across regions and years can be useful for forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de47bcc2-d6f7-49e3-a108-c36a4623f11a",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb69e5-e0ab-49ad-b418-06f891b55f48",
   "metadata": {},
   "source": [
    "<h2>3.3. Gross margin</h2> <a id='gross_margin'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d89bcb-228f-4053-8dcc-96a5eab6840f",
   "metadata": {},
   "source": [
    "__Gross margin (gross profit margin, gross margin ratio)__ is the percentage of revenue (net sales) left after deducting manufacturing costs (COGS). \\\n",
    "gross margin (%) = (gross profit / net revenue) * 100 = ((net revenue - COGS) / net revenue) * 100\n",
    "\n",
    "__Operating margin (operating profit margin)__ is the share of revenue left after prime costs & core-activity expenses. \\\n",
    "operating margin (%) = (operating profit / net revenue) * 100 = ((gross profit - operating expenses) / net revenue) * 100 = ((net revenue - COGS - operating expenses) / net revenue) * 100 \\\n",
    "Here it is not possible to calculate it, since there is no data on operating expenses.\n",
    "\n",
    "__Net margin (net profit margin)__ is the percentage of revenue left after deducting all expenses. \\\n",
    "net margin (%) = (net profit / net revenue) * 100 = ((operating profit - (taxes + loans + interest)) / net revenue) * 100 = ((net revenue - all costs) / net revenue) * 100 \\\n",
    "Here it is not possible to calculate it, since there is no data for it.\n",
    "\n",
    "__Segment margin__ is the amount of profit or loss produced by one component of a business. \\\n",
    "segment margin (%) = ((segment net revenue - segment COGS) / segment net revenue)) * 100 \\\n",
    "It shows profitability across different business units, geographical regions, or product lines.\n",
    "\n",
    "__Segment geographic margins analysis:__\n",
    "* margin per geographic segment\n",
    "* margin change per year\n",
    "* margin change per geographic segment\n",
    "\n",
    "__Data for the analysis:__\n",
    "* gross profit: step 3.2. Gross profit\n",
    "* net revenue: step 3.1.2. Net revenue\n",
    "* region: table 'dim_customer'\n",
    "\n",
    "__Gross profit margin is used to:__\n",
    "* understand the business financial health\n",
    "* see what portion of the revenue from each sale is profit\n",
    "\n",
    "__Segment profit margin is used to:__\n",
    "* assess the profitability of individual regions\n",
    "* see where the company is creating the most value\n",
    "* understand which regions are not performing well\n",
    "* allocate resources properly and improve unprofitable markets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160751d2-ddc2-4540-a870-45cc029b6c7b",
   "metadata": {},
   "source": [
    "<h3>Total gross margin</h3> <a id='total_gross_margin'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8430d61c-0df1-43f3-bf87-89fcb9b3a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating total gross margin\n",
    "# gross margin (%) = (gross profit / net revenue) * 100\n",
    "margin_total = gross_profit['gross_profit'] / net_revenue['net_revenue'] * 100\n",
    "margin_total.round().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f639f907-5ad5-403e-9639-37635a847f2a",
   "metadata": {},
   "source": [
    "<h3>Gross margin per year</h3> <a id='gross_margin_per_year'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25bbff0-425d-4683-94b0-ffe38e5851ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating gross margin per year\n",
    "year_margin = year_profit.merge(year_net_revenue, on='fiscal_year')\n",
    "year_margin['year_margin_%'] = year_margin['year_profit'] / year_margin['year_net_revenue'] * 100\n",
    "year_margin.round().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db290197-2550-4fbb-8082-dc3203ea2c13",
   "metadata": {},
   "source": [
    "Gross margin is stable over time (61%), except for 2019 (62%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6addf200-8116-4c39-a623-a8c7f2400ac4",
   "metadata": {},
   "source": [
    "<h3>Gross margin per regional segment</h3> <a id='gross_margin_per_region'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815d34c8-f5c8-4f7e-9fab-a384531bebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating gross margin per region\n",
    "region_margin = region_profit.merge(region_net_revenue, on=['region'])\n",
    "region_margin['region_margin_%'] = (region_margin['region_profit'] / region_margin['region_net_revenue'] * 100).round().astype(int)\n",
    "region_margin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237515b9-1172-4884-8ba2-2272e89b941b",
   "metadata": {},
   "source": [
    "Gross margin is the same in all regions (61%), except for LATAM (60%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca6647-d5e3-44af-8b55-a02ba20bfe9f",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc6eac7-c6db-4298-b925-368785c6baa7",
   "metadata": {},
   "source": [
    "<h3>Gross margin per region over time</h3> <a id='gross_margin_per_region_year'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057d3b34-d6b0-4023-a440-c9ddd52ca43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating gross margin per region per year\n",
    "region_yearly_margin = region_yearly_profit.merge(region_yearly_net_revenue, on=['region', 'fiscal_year'])\n",
    "region_yearly_margin['region_yearly_margin_%'] = (region_yearly_margin['region_yearly_profit'] / region_yearly_margin['region_yearly_net_revenue'] * 100).round(1)\n",
    "region_yearly_margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ec61c-ac7a-4626-a8c8-9e7eb38129e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using line chart to identify trends in gross margin per region\n",
    "fig_gross_margin=px.line(region_yearly_margin, x=\"fiscal_year\", y=\"region_yearly_margin_%\", color='region', width=1000, height=500)\n",
    "fig_gross_margin.update_layout(xaxis_title = 'year', yaxis_title = 'gross margin (%)',  title='Annual gross margin per region')\n",
    "fig_gross_margin.update_layout(xaxis = dict(tickmode = 'array', tickvals = region_yearly_profit['fiscal_year']))\n",
    "fig_gross_margin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00847902-3a29-475a-be69-fd7def03768d",
   "metadata": {},
   "source": [
    "* The profit margin remains relatively stable across all regions, fluctuating between 6062% throughout the years.\n",
    "* APAC consistently maintains high margins (around 61%62%), with a slight dip in 2021 to 61%.\n",
    "* EU also maintains margins around 61% with only slight fluctuations.\n",
    "* LATAM has the lowest margins since 2020, with a further decrease in 2021 to 59.8%. \\\n",
    "  In 2022 it grew to 60.6%, still remaining the lowest amoung the regions.\n",
    "* NA has stable margins around 60.8% for 3 years. \\\n",
    "  From 2021 it starts to grow, ending in 2022 with the highest margin among the regions at 62.0%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188bcc39-dc1c-4c23-ad51-4b34ee386edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using scatter chart to identify trends in gross margin per year\n",
    "fig_gross_margin_2 = px.scatter(region_yearly_margin, x=\"fiscal_year\", y=\"region_yearly_margin_%\", color=\"region\", width=1000, height=500)\n",
    "fig_gross_margin_2.update_layout(xaxis_title = 'year', yaxis_title = 'gross margin (%)',  title='Annual gross margin per region')\n",
    "fig_gross_margin_2.update_traces(marker={'size': 8})\n",
    "fig_gross_margin_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c3c91e-b207-412d-b414-db26fb9a5286",
   "metadata": {},
   "source": [
    "* In 2020 all regions had a drop in gross margin.\n",
    "* In 2021 gross margin in APAC and LATAM kept decreasing.\n",
    "* Since gross margin = (net revenue - COGS) / net revenue, this decline can be due to:\n",
    "    * increased manufacturing costs\n",
    "    * decreased net revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4229d50-e315-4efd-aed5-c805914356bb",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ea3789-065c-447e-914b-2e192b7a1a37",
   "metadata": {},
   "source": [
    "<h3>Gross margin decline in 2020 and 2021</h3> <a id='gross_margin_decline'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5507de5-b580-4d4e-9c41-71afb7dfa900",
   "metadata": {},
   "source": [
    "Investigating the reasons for the gross margin reduction in 2020 and 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120fcf40-9c16-4eb4-9c40-462ec309e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking manufacturing costs per year\n",
    "query=\"\"\"\n",
    "SELECT\n",
    "    cost_year,\n",
    "    CAST(ROUND(SUM(manufacturing_cost), 0) AS INTEGER) AS yearly_cogs\n",
    "FROM\n",
    "    fact_manufacturing_cost\n",
    "GROUP BY\n",
    "    cost_year\n",
    "ORDER BY \n",
    "    cost_year\n",
    "\"\"\"\n",
    "yearly_cogs=pd.read_sql_query(query, con)\n",
    "\n",
    "# calculating COGS growth rate\n",
    "yearly_cogs['growth_rate'] = yearly_cogs['yearly_cogs'].pct_change(periods=1)\n",
    "yearly_cogs['growth_rate'] = yearly_cogs['growth_rate'].map('{:.0%}'.format)\n",
    "yearly_cogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce61fb-3de0-446d-8371-58cbcc8dfa9d",
   "metadata": {},
   "source": [
    "Manufacturing costs are rising every year, but the growth rate is decreasing over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff884fe7-6c7d-4793-9b7c-57ba409d3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking manufacturing costs per year accounting for sold quantity \n",
    "query=\"\"\"\n",
    "SELECT\n",
    "    sales.fiscal_year,\n",
    "    CAST(ROUND(SUM(sales.sold_quantity * costs.manufacturing_cost), 0) AS INTEGER) AS yearly_quantity_cogs\n",
    "FROM \n",
    "    fact_sales_monthly sales\n",
    "JOIN \n",
    "    fact_manufacturing_cost costs ON sales.product_code = costs.product_code AND sales.fiscal_year = costs.cost_year\n",
    "GROUP BY\n",
    "    sales.fiscal_year\n",
    "ORDER BY \n",
    "    sales.fiscal_year\n",
    "\"\"\"\n",
    "yearly_quantity_cogs=pd.read_sql_query(query, con)\n",
    "yearly_quantity_cogs\n",
    "\n",
    "# calculating COGS growth rate\n",
    "yearly_quantity_cogs['cogs_growth_rate'] = yearly_quantity_cogs['yearly_quantity_cogs'].pct_change(periods=1)\n",
    "yearly_quantity_cogs['cogs_growth_rate'] = yearly_quantity_cogs['cogs_growth_rate'].map('{:.0%}'.format)\n",
    "yearly_quantity_cogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8db812-9b51-4d1c-8827-55588b4b33e1",
   "metadata": {},
   "source": [
    "If taking into account the sold quantity, the manufacturing costs' growth rate is also decreasing over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e1154-7a23-4cb3-a3f2-b5f123d96d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking manufacturing costs per year per region\n",
    "query=\"\"\"\n",
    "SELECT\n",
    "    customer.region,\n",
    "    sales.fiscal_year,\n",
    "    CAST(ROUND(SUM(sales.sold_quantity * costs.manufacturing_cost), 0) AS INTEGER) AS region_cogs\n",
    "FROM\n",
    "    fact_sales_monthly sales\n",
    "JOIN\n",
    "    fact_manufacturing_cost costs ON sales.product_code = costs.product_code AND sales.fiscal_year = costs.cost_year\n",
    "JOIN\n",
    "    dim_customer customer ON sales.customer_code = customer.customer_code\n",
    "GROUP BY\n",
    "    customer.region, sales.fiscal_year\n",
    "ORDER BY \n",
    "    customer.region, sales.fiscal_year\n",
    "\"\"\"\n",
    "region_cogs=pd.read_sql_query(query, con)\n",
    "region_cogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c01416-06d8-472d-8ded-49738458f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting manufacturing costs per region per year\n",
    "fig_cogs=px.line(region_cogs, x=\"fiscal_year\", y=\"region_cogs\", color='region', width=1000, height=500)\n",
    "fig_cogs.update_layout(xaxis_title = 'year', yaxis_title = 'COGS',  title='Annual manufacturing costs per region')\n",
    "fig_cogs.update_layout(xaxis = dict(tickmode = 'array', tickvals = region_cogs['fiscal_year']))\n",
    "fig_cogs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbc24a4-fc35-4725-a102-fb4f14689a11",
   "metadata": {},
   "source": [
    "* The manufacturing costs are growing each year in every region, except for LATAM in 2021 when there was a drop in its COGS.\n",
    "* The net revenue is also growing each year in every region, except for LATAM in 2021 when there was a drop in its net revenue.\n",
    "* The growth rate of manufacturing costs is decreasing ove time.\n",
    "* The decline in gross margin in 2020 and 2021 cannot be explained by only increased manufacturing costs or decreased net revenue.\n",
    "* Even though revenue is growing, if the costs are growing faster than revenue, it can reduce the profit margin. \n",
    "* It is necessary to check the net revenue and manufacturing costs growth rates per region over time to see if this is the reason for reduced profit margin in 2020 and 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060a0ccc-0435-44c9-a397-79f54a18be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the percentage change in manufacturing costs per region between current year and previous year\n",
    "## Python: region_cogs.groupby(['region', 'fiscal_year']).apply(lambda x: x['region_cogs'].pct_change(periods=1).map('{:.0%}'.format))\n",
    "## Python: region_cogs.groupby(['region', 'fiscal_year'])['region_cogs'].pct_change(periods=1).map('{:.0%}'.format)\n",
    "query=\"\"\"\n",
    "WITH yearly_region_cogs AS (\n",
    "    SELECT\n",
    "        customer.region,\n",
    "        sales.fiscal_year,\n",
    "        CAST(ROUND(SUM(sales.sold_quantity * costs.manufacturing_cost), 0) AS INTEGER) AS region_cogs\n",
    "    FROM\n",
    "        fact_sales_monthly sales\n",
    "    JOIN\n",
    "        fact_manufacturing_cost costs ON sales.product_code = costs.product_code AND sales.fiscal_year = costs.cost_year\n",
    "    JOIN\n",
    "        dim_customer customer ON sales.customer_code = customer.customer_code\n",
    "    GROUP BY\n",
    "        customer.region, sales.fiscal_year\n",
    ")\n",
    "SELECT\n",
    "    region,\n",
    "    fiscal_year,\n",
    "    region_cogs,\n",
    "    CAST(CASE\n",
    "        WHEN LAG(region_cogs) OVER (PARTITION BY region ORDER BY fiscal_year) IS NULL THEN NULL\n",
    "        ELSE (\n",
    "            (region_cogs - LAG(region_cogs) OVER (PARTITION BY region ORDER BY fiscal_year)) * 100.0\n",
    "            / LAG(region_cogs) OVER (PARTITION BY region ORDER BY fiscal_year)\n",
    "        )\n",
    "    END AS INTEGER) || '%' AS cogs_change\n",
    "FROM \n",
    "    yearly_region_cogs\n",
    "ORDER BY \n",
    "    region, fiscal_year\n",
    "\"\"\"\n",
    "yearly_region_cogs=pd.read_sql_query(query, con)\n",
    "yearly_region_cogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5316cbc2-1ba4-47a8-b970-d7514ac7fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging data on manufacturing costs' growth rates with those of the net revenue\n",
    "net_revenue_cogs = region_yearly_net_revenue_change[['region', 'fiscal_year', 'net_revenue_change']].merge(yearly_region_cogs[['region', 'fiscal_year', 'cogs_change']], on=['region', 'fiscal_year'])\n",
    "net_revenue_cogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bf9e23-3e1c-4404-81a8-2965ac1e2017",
   "metadata": {},
   "source": [
    "* The faster growth of manufacturing costs than revenue caused the gross margin decline in all regions in 2020.\n",
    "* This fast rise had the biggest impact on LATAM and APAC regions in both 2020 and 2021.\n",
    "* It also influenced the gross margin of EU in 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e514c237-91fe-471f-bdf9-82b277a074a6",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_16'></a>\n",
    "\n",
    "__Gross margin:__\n",
    "* Gross margin is stable over time (61%), except for 2019 (62%).\n",
    "* Gross profit margin is the same in all regions (61%), except for LATAM (60%).\n",
    "* It means that around 61% of the revenue is left over after paying direct costs (COGS).\n",
    "* A gross profit margin ratio of 61% is considered healthy.\n",
    "* Operating and net margins cannot be calculated since there is no data for it.\n",
    "\n",
    "__Segment margin:__\n",
    "* Segment margin is calculated for 5 annual periods to determine if there is a profitable trend or underperforming regions that need to be addressed.\n",
    "\n",
    "__Gross margin trends per region:__\n",
    "* The profit margin remains relatively stable across all regions, hovering around 6062% throughout the years.\n",
    "* APAC consistently maintains high margins (around 61%62%), with a slight dip in 2021 to 61%.\n",
    "* EU also maintains margins around 61% with only slight fluctuations.\n",
    "* LATAM has the lowest margins since 2020, with a further decrease in 2021 to 59.8%. \\\n",
    "  In 2022 it grew to 60.6%, still remaining the lowest amoung the regions.\n",
    "* NA has stable margins around 60.8% for 3 years. \\\n",
    "  From 2021 it starts to grow, ending in 2022 with the highest margin among the regions at 62.0%.\n",
    "\n",
    "__Gross margin trends per year:__\n",
    "* In 2020 all regions had a drop in gross margin.\n",
    "* In 2021 gross margin in APAC and LATAM kept decreasing.\n",
    "* The profit margin analysis revealed the following:\n",
    "    * The manufacturing costs and net revenue are growing each year in every region, except for LATAM (had a drop in both in 2021).\n",
    "    * So the gross margin decline in 2020 and 2021 cannot be explained by increased manufacturing costs or decreased net revenue.\n",
    "    * The reason for reduced profit margin: the faster growth of manufacturing costs than net revenue.\n",
    "* The faster growth of COGS than net revenue:\n",
    "    * caused the gross margin decline in all regions in 2020\n",
    "    * had the biggest impact on LATAM and APAC regions in both 2020 and 2021\n",
    "    * influenced the gross margin of EU in 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003569b8-39e2-4afd-bb61-0c6dd77ce697",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4730a607-154b-41a2-9b33-425ba20ae45e",
   "metadata": {},
   "source": [
    "<h2>Financial analysis summary</h2> <a id='summary_3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e74a9-01d9-47c0-85e1-379e5d419239",
   "metadata": {},
   "source": [
    "* __Metrics and ratios__ used to assess the company's financial health:\n",
    "    * gross revenue\n",
    "    * gross revenue growth rate\n",
    "    * net revenue\n",
    "    * net revenue growth rate\n",
    "    * gross profit\n",
    "    * gross margin\n",
    "    * segment (geographic) margin\n",
    "    * other metrics cannot be calculated due to the lack of data\n",
    "\n",
    "* __Assumptions__ made:\n",
    "    1. net revenue = gross revenue - discounts \\\n",
    "      Net revenue calculation accounts only for discounts, since the dataset has no information on refunds, returns and allowances.\n",
    "    2. 'fiscal_year' = 'cost_year' \\\n",
    "      To be able to merge tables with manufacturing costs and sales data to calculate gross profit.\n",
    "\n",
    "* __Key financial indicators:__\n",
    "    * Total gross revenue is 86555909\n",
    "    * Total net revenue 66312380\n",
    "    * Total gross profit: 40622742\n",
    "    * Total gross margin: 61%\n",
    "\n",
    "* __Each year from the total revenue__ on average:\n",
    "    * 47% of money is left as gross profit\n",
    "    * 53% of money is spent:\n",
    "        * 23% on discounts\n",
    "        * 30% on manufacturing costs\n",
    "\n",
    "* __Across years and regions__, the ratios (in %) between revenues and profit are on average the same:\n",
    "    * net revenue to gross revenue: 76%\n",
    "    * gross profit to gross revenue: 47%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a195de42-6d7b-4d98-b335-0ec2d611a2f0",
   "metadata": {},
   "source": [
    "__Gross revenue:__\n",
    "* It grows every year in every region, except for LATAM in 2021.\n",
    "* The growth rate is decreasing over time.\n",
    "* The most profitable region is APAC (Asia-Pacific).\n",
    "* The least profitable region is LATAM (Latin America).\n",
    "* The total revenues of NA (North America) and EU (European Union) regions are approximately the same.\n",
    "* Over time, the market has changed only in EU and NA regions. \\\n",
    "  Before 2021 NA has higher revenue than EU. From 2021 the revenue of EU starts to be higher than in NA.\n",
    "\n",
    "__Net revenue:__\n",
    "* It follows the same regional and yearly patterns as gross revenue.\n",
    "\n",
    "__Gross profit:__\n",
    "* It follows the same regional and yearly patterns as gross and net revenues.\n",
    "* The net-to-gross revenue ratio (in %) and profit to gross revenue ratio (in %) is almost the same across years and regions.\n",
    "* Such uniform percentages can:\n",
    "    * indicate a highly standardized financial structure with fixed parameters that don't change year-to-year or region-to-region\n",
    "    * suggest that the costs are structured similarly across all regions:\n",
    "        * a consistent discount rate\n",
    "        * a uniform pricing strategy\n",
    "        * similar levels of direct costs related to manufacturing\n",
    "    * be useful for forecasting\n",
    "\n",
    "__Gross margin:__\n",
    "* It is stable over time (61%), except for 2019 (62%).\n",
    "* It is the same in all regions (61%), except for LATAM (60%).\n",
    "* A gross margin of 61% is considered healthy: around 61% of the revenue is left over after paying direct costs (COGS).\n",
    "\n",
    "__Segment (regional) margin:__\n",
    "* The profit margin remains stable across all regions, fluctuating between 6062% throughout the years.\n",
    "* The faster growth of manufacturing costs than net revenue:\n",
    "    * caused the gross margin decline in all regions in 2020\n",
    "    * had the biggest impact on LATAM and APAC regions in both 2020 and 2021 \\\n",
    "      It can be that in these years LATAM and APAC were mostly buying products with high manufacturing costs. \n",
    "    * influenced the gross margin of EU in 2019\n",
    "\n",
    "__Financial metrics per geographic region:__\n",
    "* __*APAC*__ consistently maintains high margins (around 61%62%), with a slight dip in 2021 to 61%. \\\n",
    "  It shows a very strong upward trajectory, with profit nearly tripling from 2019 to 2022 and revenue growing by about 5 times over the same period.\n",
    "* __*EU*__ also maintains margins around 61% with only slight fluctuations. \\\n",
    "  It grows steadily, though at a slower rate compared to APAC. Revenue and profit both more than quadrupled from 2018 to 2022, but the increase is more linear.\n",
    "* __*LATAM*__ has the lowest margins since 2020, with a further decrease in 2021 to 59.8%. \\\n",
    "  In 2022 it grew to 60.6%, still remaining the lowest amoung the regions. \\\n",
    "  This region shows slower growth in both profit and revenue.\n",
    "* __*NA*__ has stable margins around 60.8% for 3 years. \\\n",
    "  From 2021 it starts to grow, ending in 2022 with the highest margin among the regions at 62.0%. \\\n",
    "  This region shows healthy growth but has a more moderate increase in revenue and profit compared to APAC and EU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcbe961-4a1c-4126-9498-f0d6de30ff25",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2a620e-8c15-4a56-be7c-15f653bffa3a",
   "metadata": {},
   "source": [
    "<h1>4. Hypothesis testing</h1> <a id='hypothesis'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1aa887-cf1f-4a94-a6c1-44989ff3595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7794b6-f70f-4351-91ee-327bc17cbe34",
   "metadata": {},
   "source": [
    "Exploring the connection between manufacturing costs and gross margin to understand how costs impact profitability.\n",
    "\n",
    "Hypothesis: \\\n",
    "Rising manufacturing costs negatively impact the companys gross profit margins.\n",
    "\n",
    "To check this hypothesis, it is necessary to investigate:\n",
    "* average gross margins over time\n",
    "* relationship between manufacturing costs and gross margins\n",
    "\n",
    "Null hypotheses H0:\n",
    "1. There is no difference between gross margins of different years.\n",
    "2. There is no relationship between manufacturing costs and gross margins. \\\n",
    "   (Manufacturing costs do not affect gross profit margin.)\n",
    "\n",
    "Alternative hypotheses HA:\n",
    "1. There is a difference between gross margins of different years.\n",
    "2. There is a relationship between manufacturing costs and gross margins. \\\n",
    "   (Manufacturing costs affect gross profit margin.)\n",
    "\n",
    "Testing the hypothesis by using:\n",
    "1. a statistical test to compare average gross margins of different years\n",
    "2. two statistical tests to assess the relationship between manufacturing costs and gross profit margins\n",
    "\n",
    "The chosen significance level for the statistical tests is 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e747212-dc37-40bd-8cb8-a40badd6e292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a significance level to 5%\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc5a0f7-9ab9-4f5e-b44a-0a14c39a8fcc",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c74f30-7dd9-49f0-bea9-29ce31370b79",
   "metadata": {},
   "source": [
    "<h2>4.1. Data preparation</h2> <a id='data_preparation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6cc7a7-3fa8-49d8-bdab-a9c27b3f7219",
   "metadata": {},
   "source": [
    "<h3>EDA</h3> <a id='data_preparation_eda'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a2962a-88a0-4359-a819-182c5ede2d08",
   "metadata": {},
   "source": [
    "Preparing data on gross profit margin per product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea02d414-67ab-4e8b-b03b-34317531ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating gross margin per product\n",
    "# gross margin = gross profit / net revenue\n",
    "query=\"\"\"\n",
    "SELECT\n",
    "    sales.product_code,\n",
    "    sales.customer_code,\n",
    "    cost.cost_year,\n",
    "    cost.manufacturing_cost,\n",
    "    (price.gross_price - price.gross_price * discount.pre_invoice_discount_pct - cost.manufacturing_cost) /\n",
    "    (price.gross_price - price.gross_price * discount.pre_invoice_discount_pct)\n",
    "    AS margin\n",
    "FROM\n",
    "    fact_sales_monthly sales\n",
    "JOIN\n",
    "    fact_gross_price price\n",
    "    ON sales.product_code = price.product_code\n",
    "    AND sales.fiscal_year = price.fiscal_year\n",
    "JOIN\n",
    "    fact_manufacturing_cost cost\n",
    "    ON sales.product_code = cost.product_code\n",
    "    AND sales.fiscal_year = cost.cost_year\n",
    "JOIN\n",
    "    fact_pre_discount discount\n",
    "    ON  sales.customer_code = discount.customer_code\n",
    "    AND sales.fiscal_year = discount.fiscal_year\n",
    "\"\"\"\n",
    "cost_margin=pd.read_sql_query(query, con)\n",
    "cost_margin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfadb147-8cf8-4dc1-b2fb-7421b445665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview of the data in the table 'cost_margin'\n",
    "cost_margin.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54f91b5-0b43-4bec-9351-a830332b20d0",
   "metadata": {},
   "source": [
    "There are no missing values in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc879f-a723-47f5-b33b-2343c090bb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the years range\n",
    "cost_margin['cost_year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3032a1-c22a-4b2f-a425-aa92dae1af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of unique products per year\n",
    "cost_margin.groupby('cost_year')['product_code'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e39cf-8f76-4ebb-aaba-28cc67a2409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of products per year\n",
    "cost_margin.groupby('cost_year')['product_code'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc11e1f-081d-42df-a252-7f286a9c2833",
   "metadata": {},
   "source": [
    "To ensure that sample sizes are large enough for statistical significance, \\\n",
    "the calculations will be performed not by unique products, but by products per year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4671f9-cbfc-4d67-99c4-174190135212",
   "metadata": {},
   "source": [
    "Overview of the total manufacturing costs and total gross margins each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb06d38-3d00-4c94-af60-1bd0c2d66d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manufacturing costs vs gross profit margin per year\n",
    "cogs_margin = yearly_quantity_cogs[['fiscal_year', 'yearly_quantity_cogs']].merge(year_margin[['fiscal_year', 'year_margin_%']].round(), on=['fiscal_year'])\n",
    "cogs_margin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f622c90-a008-41da-b69e-1e6b87515521",
   "metadata": {},
   "source": [
    "* Manufacturing costs are rising every year.\n",
    "* Gross margin is stable over time (61%), except for 2019 (62%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec28f1d2-f0cb-47f9-ba64-2e69d064ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an average gross margin per product per year\n",
    "cost_margin.groupby('cost_year')['margin'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df91aa19-3e36-4a6a-9d27-f02597cbf55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an average manufacturing cost per product per year\n",
    "cost_margin.groupby('cost_year')['manufacturing_cost'].mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa2581b-cb2e-40d2-80ba-def8dbf80322",
   "metadata": {},
   "source": [
    "A drop in the average manufacturing cost per product in 2019 can be a reason to a rise in the total gross margin in 2019 to 62%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3f76f2-fa6e-4ad3-a50e-9659ec0c2cee",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c14941f-d21f-415b-b9ac-67309f42d04e",
   "metadata": {},
   "source": [
    "<h3>Outliers and normality</h3> <a id='data_preparation_outliers'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3041460e-bfa3-4bd6-98a6-a168a6250d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general statistics on manufacturing costs and gross margins\n",
    "cost_margin[['manufacturing_cost', 'margin']].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe30ffc-d576-4df9-8b38-b6764fe1381d",
   "metadata": {},
   "source": [
    "* The majority of products have profit margin 0.61 and GOGS 6.24\n",
    "* The minimal manufacturing cost is 4.2\n",
    "* The maximal manufacturing cost is 9.2\n",
    "* The minimal profit margin is 0.55\n",
    "* The maximal profit margin is 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27315df-8816-48b0-98dd-35cad854de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a histogram to check normality of the manufacturing cost distribution\n",
    "plt.hist(cost_margin['manufacturing_cost'], bins=15, color='steelblue')\n",
    "plt.xlabel('manufacturing cost')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Distribution of manufacturing cost values')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea482c-df62-49c5-a08a-32e1d219eee8",
   "metadata": {},
   "source": [
    "The manufacturing cost distribution has several peaks. \\\n",
    "It does not follow the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c48430-a706-4ae0-b827-7345cea25ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings warnings to be ignored \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca4c89-d4ae-4938-8d54-c599effcd61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the distribution for normality using Shapiro-Wilk test\n",
    "stat_costs, p_costs = stats.shapiro(cost_margin['manufacturing_cost'])\n",
    "print(f\"Manufacturing costs normality p-value: {p_costs}\")\n",
    "if p_costs > 0.05:\n",
    "    print(\"Manufacturing costs have the normal distribution.\")\n",
    "else:\n",
    "    print(\"Manufacturing costs do not follow the normal distribution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd8d3e7-43d9-4555-8896-5df0f82f5119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a histogram to check normality of the gross margin distribution\n",
    "plt.hist(cost_margin['margin'], bins=20, color='steelblue')\n",
    "plt.xlabel('gross margin')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Distribution of gross margin values')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df8cc3-2569-4991-943f-1fd51ff67057",
   "metadata": {},
   "source": [
    "The gross margin distribution has 2 peaks. \\\n",
    "It does not follow the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe10092-ff65-4174-9023-e5e9a2f26b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the distributions for normality using Shapiro-Wilk test\n",
    "stat_margin, p_margin = stats.shapiro(cost_margin['margin'])\n",
    "print(f\"Gross margin normality p-value: {p_margin}\")\n",
    "if p_margin > 0.05:\n",
    "    print(\"Gross margin values have the normal distribution.\")\n",
    "else:\n",
    "    print(\"Gross margin values do not follow the normal distribution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceedacdf-e247-4be6-8b73-3097422540ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a boxplot to check for outliers in the manufacturing cost distribution\n",
    "fig=px.box(cost_margin, y=['manufacturing_cost'], title='Distribution of manufacturing costs',  width=1000, height=500)\n",
    "fig.update_layout(xaxis_title = 'manufacturing cost ', yaxis_title = 'value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ad9f1-dd41-4fb6-9803-4728abb27dd5",
   "metadata": {},
   "source": [
    "There are no outliers in the manufacturing costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c03f0b3-410a-46bd-9102-776e886e2caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a boxplot to check for outliers in the gross margin distribution\n",
    "fig=px.box(cost_margin, y=['margin'], title='Distribution of gross margin values',  width=1000, height=500)\n",
    "fig.update_layout(xaxis_title = 'gross profit margin ', yaxis_title = 'value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e4d5f9-d574-4a6c-bb3c-03a5344b36e5",
   "metadata": {},
   "source": [
    "In gross margin:\n",
    "* There are no outliers below the lower bound.\n",
    "* There are outliers above the upper bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f669c-7afd-45b4-aa80-8c196625c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating percentiles to define margin outliers\n",
    "print(np.percentile(cost_margin['margin'], [95, 97, 98, 99]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b1d393-c372-4d61-90d2-cc184fb205c6",
   "metadata": {},
   "source": [
    "* The outliers start from the 98th percentile.\n",
    "* The margin 0.685 can be defined as the lower limit from which the profit margin starts to be considered an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da951db-b40d-4ad2-b080-506ee6e90084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the outliers via the percentile and saving them in a variable\n",
    "margin_outlier = np.percentile(cost_margin['margin'], [98])\n",
    "margin_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501186b8-a192-498e-acf9-0609e95f639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a selection of products with margin equal to or more than the 98th percentile\n",
    "## margin_outlier returns a numpy.ndarray object with one element, and not a value\n",
    "## margin_outlier[0] returns the value from the container\n",
    "outliers = cost_margin[cost_margin['margin'] >= margin_outlier[0]]\n",
    "outliers['margin'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9caf02-a320-4546-a965-9993716d4c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping these outliers\n",
    "filtered_cost_margin = cost_margin.drop(outliers.index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a3df2a-3e27-4f72-8cc6-66bcc2091988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if there are no more outliers in the filtered dataset\n",
    "filtered_cost_margin[filtered_cost_margin['margin'] >= margin_outlier[0]]['margin'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0247a316-a515-460e-8c9b-77f254115149",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_17'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a87fda3-9a0c-470e-b8a6-20f4b5af1c6d",
   "metadata": {},
   "source": [
    "* A table 'cost_margin' is created with manufacturing costs and gross profit margin per product.\n",
    "* The table contains data for 5 years: 2018-2022.\n",
    "* To ensure sufficient sample sizes the tests will be performed accounting for all products each year.\n",
    "* The manufacturing cost and gross margin distributions do not follow the normal distribution.\n",
    "* The manufacturing cost values do not have outliers.\n",
    "* The gross margin values have outliers above the upper bound, starting from the 98th percentile.\n",
    "* A table 'filtered_cost_margin' is created without the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bacba55-1a86-48c1-ad3b-be52de83c2da",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ab047-fad7-45d5-86f7-c4e17c1914a0",
   "metadata": {},
   "source": [
    "<h2>4.2. Statistical test 1: average gross margin</h2> <a id='statistical_test_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d24f6f-df60-473b-bbd9-b898c8561c5d",
   "metadata": {},
   "source": [
    "H0: There is no difference between gross margins of different years. \\\n",
    "HA: There is a difference between gross margins of different years.\n",
    "\n",
    "Average gross profit margin is a number that varies per product per year -> the data is continuous for this metric.\n",
    "\n",
    "Steps in hypothesis testing for continuous data:\n",
    "1. check normality (samples distribution): Shapiro test\n",
    "2. if normal distribution -> check the equality of variances: Levene's test \\\n",
    "   2.1. variances are equal: t-test \\\n",
    "   2.2. variances are not equal: modified t-test\n",
    "3. if not normal distribution: mann-whitney u test\n",
    "\n",
    "The test will be performed on both raw (including outliers) and clean data (without outliers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf99f7e-0506-4857-a5af-20592bc6085b",
   "metadata": {},
   "source": [
    "<h3>Data aggregation</h3> <a id='data_preparation_aggregation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b9ae21-41c5-4ef0-93f7-c4de0b151bcf",
   "metadata": {},
   "source": [
    "Creating groups for the hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b69ee1-8e8e-4764-a6b8-4b7beba262e7",
   "metadata": {},
   "source": [
    "The hypothesis will be tested in 3 different scenarios:\n",
    "1. a case with the biggest difference in manufacturing costs: years 2018 and 2022\n",
    "3. a case with the difference in total gross margin values: years 2018 (61%) and 2019 (62%)\n",
    "4. a case with almost equal sample sizes: years 2020 and 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82360317-cbc9-46ce-b349-2372032d6054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into groups\n",
    "group_2018 = cost_margin[cost_margin['cost_year']==2018]\n",
    "group_2019 = cost_margin[cost_margin['cost_year']==2019]\n",
    "group_2020 = cost_margin[cost_margin['cost_year']==2020]\n",
    "group_2021 = cost_margin[cost_margin['cost_year']==2021]\n",
    "group_2022 = cost_margin[cost_margin['cost_year']==2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c177be89-b71b-411b-a6cf-9d19aea5dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the filtered data into groups\n",
    "group_2018_clean = filtered_cost_margin[filtered_cost_margin['cost_year']==2018]\n",
    "group_2019_clean = filtered_cost_margin[filtered_cost_margin['cost_year']==2019]\n",
    "group_2020_clean = filtered_cost_margin[filtered_cost_margin['cost_year']==2020]\n",
    "group_2021_clean = filtered_cost_margin[filtered_cost_margin['cost_year']==2021]\n",
    "group_2022_clean = filtered_cost_margin[filtered_cost_margin['cost_year']==2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3b38b-b9b4-4b9c-9264-cfadb46a3b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the split was done correctly\n",
    "groups = [group_2018, group_2019, group_2020, group_2021, group_2022]\n",
    "for group in groups:\n",
    "    print(group['cost_year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e86413b-83bf-403b-8854-ebaa18299051",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_clean = [group_2018_clean, group_2019_clean, group_2020_clean, group_2021_clean, group_2022_clean]\n",
    "for group in groups_clean:\n",
    "    print(group['cost_year'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ea8acb-dd1e-486f-a8c8-33445a26e0c8",
   "metadata": {},
   "source": [
    "There are now 2 test sets:\n",
    "* raw: group_2018, group_2019, group_2020, group_2021, group_2022\n",
    "* clean: group_2018_clean, group_2019_clean, group_2020_clean, group_2021_clean, group_2022_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92a1b4-0bcf-4d1c-bc72-e1f3059bfb8f",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e948c-dd92-49dc-8f09-20fcf966217c",
   "metadata": {},
   "source": [
    "<h3>Case 1: biggest difference in manufacturing costs</h3> <a id='case_2018_2022'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98975e10-3d97-4a2b-82fb-6e1997de6ca6",
   "metadata": {},
   "source": [
    "Testing the hypothesis for  years 2018 and 2022 when the difference in manufacturing costs is the biggest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b83a9d-1d6a-4cf8-8537-56baaf72a27b",
   "metadata": {},
   "source": [
    "<h4>raw data</h4> <a id='case_2018_2022_raw'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3fcba0-9452-4340-b028-1cd08537f278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of each group\n",
    "print(\"Group 2018 size:\", group_2018['margin'].count())\n",
    "print(\"Group 2022 size:\", group_2022['margin'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d143e717-671d-4de3-bcee-417e3af066b9",
   "metadata": {},
   "source": [
    "The group sizes are not equal. \\\n",
    "Group 2022 has 21% less data than group 2018. \\\n",
    "The hypothesis test requirement for a fair split between groups is not satisfied. \\\n",
    "It will be harder to rely on the test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d4f9c1-d6aa-44ff-919a-71ed199e1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean value of each group\n",
    "print(\"Group 2018 mean gross margin:\", group_2018['margin'].mean())\n",
    "print(\"Group 2022 mean gross margin:\", group_2022['margin'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab922e6-5c1e-48d2-a9af-64e1cd5841fa",
   "metadata": {},
   "source": [
    "The average gross margin of 2 groups look similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe75413a-2d87-4ecb-b42c-8e18fcd987bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting histograms to compare the distributions of the groups' gross profit margins\n",
    "plt.subplots(figsize=(8,7))\n",
    "plt.hist(group_2018['margin'], bins=50, color='steelblue', edgecolor='black', alpha=0.7, label='group 2018')\n",
    "plt.hist(group_2022['margin'], bins=50, color='lime', edgecolor='black', alpha=0.3, label='group 2022')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('gross profit margin')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Distribution of gross margins per group')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806955a6-0fa2-49bb-82f7-c6ca50f1bf0b",
   "metadata": {},
   "source": [
    "The distributions of the groups' gross margins look similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e9c304-7cdf-4c60-9a1c-890cfe4aa39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if groups distributions are normal with Shapiro-Wilk test\n",
    "stat_2018, p_2018 = stats.shapiro(group_2018['margin'])\n",
    "stat_2022, p_2022 = stats.shapiro(group_2022['margin'])\n",
    "\n",
    "print(f\"Group 2018 normality p-value: {p_2018}\")\n",
    "print(f\"Group 2022 normality p-value: {p_2022}\")\n",
    "\n",
    "if p_2018 > alpha and p_2022 > alpha:\n",
    "    print(\"Both groups have the normal distribution.\")\n",
    "else:\n",
    "    print(\"The groups do not follow the normal distribution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fcafc1-a698-4e0a-b0a1-f03965f177e8",
   "metadata": {},
   "source": [
    "Running a statistical Mann-Whitney U test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b8c37-3499-4859-b1d4-661ab6930f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mann-whitney U test for the not normal distribution\n",
    "statist, p_value = stats.mannwhitneyu(group_2018['margin'], group_2022['margin'])\n",
    "print(p_value)\n",
    "if p_value < alpha:\n",
    "    print('Reject H0')\n",
    "else:\n",
    "    print('Fail to Reject H0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f770241d-1ff4-427b-ba03-6a7df38a1f63",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "* p-value = 0.0001 < 0.05\n",
    "* The null hypothesis that there is no difference in gross margins of 2018 and 2022 is rejected.\n",
    "* Based on the raw data, there is a difference between gross profit margins in 2018 and 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0651ed45-9fd4-4456-b0db-82a6f72b9bd2",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63220305-dc1e-4d12-9d74-d87e45b9695e",
   "metadata": {},
   "source": [
    "<h4>clean data</h4> <a id='case_2018_2022_clean'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62431903-b0a4-4aa9-96dd-939fbeabe71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of each group\n",
    "print(\"Clean group 2018 size:\", group_2018_clean['margin'].count())\n",
    "print(\"Clean group 2022 size:\", group_2022_clean['margin'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e9962d-c9a2-455b-ad48-a906c8c5609e",
   "metadata": {},
   "source": [
    "The group sizes are not equal. \\\n",
    "Filtered group 2022 has 21% less data than filtered group 2018. \\\n",
    "The hypothesis test requirement for a fair split between groups is not satisfied. \\\n",
    "It will be harder to rely on the test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a541737b-41de-43ea-b064-ea86111b45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean values of each group\n",
    "print(\"Clean group 2018 mean gross margin:\", group_2018_clean['margin'].mean())\n",
    "print(\"Clean group 2022 mean gross margin:\", group_2022_clean['margin'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc832645-159b-42d3-80ec-14fe8b8b41e4",
   "metadata": {},
   "source": [
    "The average gross margin of filtered group 2022 is slightly higher than of filtered group 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63a6ced-7e67-4f32-a10d-ea88d44012bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting histograms to compare the distributions of the filtered groups' gross profit margins\n",
    "plt.subplots(figsize=(8,7))\n",
    "plt.hist(group_2018_clean['margin'], bins=50, color='steelblue', edgecolor='black', alpha=0.7, label='group 2018 clean')\n",
    "plt.hist(group_2022_clean['margin'], bins=50, color='lime', edgecolor='black', alpha=0.3, label='group 2022 clean')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('gross profit margin')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Distribution of gross margins per filtered group')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3187b900-724e-4317-82a0-cc1e703f09e6",
   "metadata": {},
   "source": [
    "The distributions of the filtered groups' gross margins look similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8997e9-7b2b-430d-98e1-46724ab38bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking normality with Shapiro-Wilk test\n",
    "stat_2018_clean, p_2018_clean = stats.shapiro(group_2018_clean['margin'])\n",
    "stat_2022_clean, p_2022_clean = stats.shapiro(group_2022_clean['margin'])\n",
    "\n",
    "print(f\"Clean group 2018 normality p-value: {p_2018_clean}\")\n",
    "print(f\"Clean group 2022 normality p-value: {p_2022_clean}\")\n",
    "\n",
    "if p_2018_clean > alpha and p_2022_clean > alpha:\n",
    "    print(\"Both filtered groups have the normal distribution.\")\n",
    "else:\n",
    "    print(\"The filtered groups do not follow the normal distribution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd0145-ca30-4d8b-8174-692968d49791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mann-whitney U test for the not normal distribution\n",
    "statist, p_value = stats.mannwhitneyu(group_2018_clean['margin'], group_2022_clean['margin'])\n",
    "print(p_value)\n",
    "if p_value < alpha:\n",
    "    print('Reject H0')\n",
    "else:\n",
    "    print('Fail to Reject H0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95922945-9fb1-4768-96b5-1985bb28f0b7",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "* p-value = 0.0001 < 0.05\n",
    "* The null hypothesis that there is no difference in gross margins of 2018 and 2022 is rejected.\n",
    "* Based on the filtered data, there is a difference between gross profit margins in 2018 and 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b9bfeb-0588-4294-a1d3-12f5ae06349b",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169cf8e5-65d2-4243-8e6f-dc12ea891135",
   "metadata": {},
   "source": [
    "<h3>Case 2: difference in gross margins</h3> <a id='case_2018_2019'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab30307-1545-4a53-b74a-34a3fe82359c",
   "metadata": {},
   "source": [
    "Testing the hypothesis for years 2018 and 2019 when there was a difference in total gross profit margins:\n",
    "* 2018: gross margin = 61%\n",
    "* 2019: gross margin = 62%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4025d9-728b-4746-ace7-d74880c08638",
   "metadata": {},
   "source": [
    "<h4>raw data</h4> <a id='case_2018_2019_raw'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000139c0-8acd-4e5d-ab81-925950e7f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of each group\n",
    "print(\"Group 2018 size:\", group_2018['margin'].count())\n",
    "print(\"Group 2019 size:\", group_2019['margin'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b246be3-5fef-4ee5-a351-5c1e53828d66",
   "metadata": {},
   "source": [
    "The group sizes are not equal. \\\n",
    "Group 2018 has almost twice (49%) less data than group 2019. \\\n",
    "The hypothesis test requirement for a fair split between groups is not satisfied. \\\n",
    "It will be harder to rely on the test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104fc244-e091-4d5b-927f-15740dcea1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean value of each group\n",
    "print(\"Group 2018 mean gross margin:\", group_2018['margin'].mean())\n",
    "print(\"Group 2019 mean gross margin:\", group_2019['margin'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b027bf-ff9a-4d25-b96d-a52c89b2aa8c",
   "metadata": {},
   "source": [
    "The average gross margin of group 2019 is slightly higher than of group 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6d5cb7-df27-41d0-9556-de6da802b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting histograms to compare the distributions of the groups' gross profit margins\n",
    "plt.subplots(figsize=(8,7))\n",
    "plt.hist(group_2018['margin'], bins=50, color='steelblue', edgecolor='black', alpha=0.7, label='group 2018')\n",
    "plt.hist(group_2019['margin'], bins=50, color='lime', edgecolor='black', alpha=0.3, label='group 2019')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('gross profit margin')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Distribution of gross margins per group')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ccb37a-5655-4072-a2f2-e617e925ef5a",
   "metadata": {},
   "source": [
    "The distribution of group 2018 is narrower and has less peaks than group 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc4d28-1157-4c63-86e6-e1e23a43dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if groups distributions are normal with Shapiro-Wilk test\n",
    "stat_2018, p_2018 = stats.shapiro(group_2018['margin'])\n",
    "stat_2019, p_2019 = stats.shapiro(group_2019['margin'])\n",
    "\n",
    "print(f\"Group 2018 normality p-value: {p_2018}\")\n",
    "print(f\"Group 2019 normality p-value: {p_2019}\")\n",
    "\n",
    "if p_2018 > alpha and p_2019 > alpha:\n",
    "    print(\"Both groups have the normal distribution.\")\n",
    "else:\n",
    "    print(\"The groups do not follow the normal distribution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c51e338-9502-4d01-be8f-ecb40d4246a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mann-whitney U test for the not normal distribution\n",
    "statist, p_value = stats.mannwhitneyu(group_2018['margin'], group_2019['margin'])\n",
    "print(p_value)\n",
    "if p_value < alpha:\n",
    "    print('Reject H0')\n",
    "else:\n",
    "    print('Fail to Reject H0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233145db-e47e-4337-a35d-bec8fd666c50",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "* p-value = 0.0000 < 0.05\n",
    "* The null hypothesis that there is no difference in gross margins of 2018 and 2019 is rejected.\n",
    "* Based on the raw data, there is a difference between gross profit margins in 2018 and 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99346f44-1c13-4078-a42c-7cdc75de81a1",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f10fcde-f79a-4c01-b5dc-0032d8a9e643",
   "metadata": {},
   "source": [
    "<h4>clean data</h4> <a id='case_2018_2019_clean'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287d86f2-7270-4ff9-bc4d-c643e1a02016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of each group\n",
    "print(\"Clean group 2018 size:\", group_2018_clean['margin'].count())\n",
    "print(\"Clean group 2019 size:\", group_2019_clean['margin'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835df50d-aebd-4e7a-82e4-69176d5dcfde",
   "metadata": {},
   "source": [
    "The group sizes are not equal. \\\n",
    "Filtered group 2018 has almost twice (48%) less data than filtered group 2019. \\\n",
    "The hypothesis test requirement for a fair split between groups is not satisfied. \\\n",
    "It will be harder to rely on the test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223dd0e7-4d68-4fd4-80e0-de4b85a83dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean values of each group\n",
    "print(\"Clean group 2018 mean gross margin:\", group_2018_clean['margin'].mean())\n",
    "print(\"Clean group 2019 mean gross margin:\", group_2019_clean['margin'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17dcbb3-5ec9-42c0-8838-603a54bee735",
   "metadata": {},
   "source": [
    "The average gross margin of filtered group 2019 is slightly higher than of filtered group 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce87c5-5e5a-4886-9885-5924536569ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting histograms to compare the distributions of the filtered groups' gross profit margins\n",
    "plt.subplots(figsize=(8,7))\n",
    "plt.hist(group_2018_clean['margin'], bins=50, color='steelblue', edgecolor='black', alpha=0.7, label='group 2018 clean')\n",
    "plt.hist(group_2019_clean['margin'], bins=50, color='lime', edgecolor='black', alpha=0.3, label='group 2019 clean')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('gross profit margin')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Distribution of gross margins per filtered group')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6809fa61-825a-4b8f-acbc-6cfd2a64cf2e",
   "metadata": {},
   "source": [
    "The distribution of group 2018 is narrower than of group 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3230a0b0-1262-4e8a-b587-523859af2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking normality with Shapiro-Wilk test\n",
    "stat_2018_clean, p_2018_clean = stats.shapiro(group_2018_clean['margin'])\n",
    "stat_2019_clean, p_2019_clean = stats.shapiro(group_2019_clean['margin'])\n",
    "\n",
    "print(f\"Clean group 2018 normality p-value: {p_2018_clean}\")\n",
    "print(f\"Clean group 2019 normality p-value: {p_2019_clean}\")\n",
    "\n",
    "if p_2018_clean > alpha and p_2019_clean > alpha:\n",
    "    print(\"Both filtered groups have the normal distribution.\")\n",
    "else:\n",
    "    print(\"The filtered groups do not follow the normal distribution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea92069-f090-41a5-862d-f69a8336c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mann-whitney U test for the not normal distribution\n",
    "statist, p_value = stats.mannwhitneyu(group_2018_clean['margin'], group_2019_clean['margin'])\n",
    "print(p_value)\n",
    "if p_value < alpha:\n",
    "    print('Reject H0')\n",
    "else:\n",
    "    print('Fail to Reject H0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f31bb05-51a4-45bb-a92f-b40470d9fb57",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "* p-value = 0.0000 < 0.05\n",
    "* The null hypothesis that there is no difference in gross margins of 2018 and 2019 is rejected.\n",
    "* Based on the filtered data, there is a difference between gross profit margins in 2018 and 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ebacea-fc8b-4171-ba8b-f2bc2f9608a3",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8edd20f-997d-4f05-a7e7-53963258dbe7",
   "metadata": {},
   "source": [
    "<h3>Case 3: equal sample sizes</h3> <a id='case_2020_2021'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dd8f81-8f39-430a-b594-3b5a840b0ccb",
   "metadata": {},
   "source": [
    "Testing the hypothesis for years 2020 and 2021 with almost equal group sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ada205-a8d9-416b-9a32-f8ac41764346",
   "metadata": {},
   "source": [
    "<h4>raw data</h4> <a id='case_2020_2021_raw'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac719fd1-8aa1-4b23-b3bc-0386272817e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of each group\n",
    "print(\"Group 2020 size:\", group_2020['margin'].count())\n",
    "print(\"Group 2021 size:\", group_2021['margin'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a840b5-6b8b-4f94-9aa5-3a8de772b543",
   "metadata": {},
   "source": [
    "The sample sizes are almost equal. \\\n",
    "Group 2020 has 4% less data than group 2011. \\\n",
    "The hypothesis test requirement for a fair split between groups is satisfied. \\\n",
    "The test results will be more precise than in the previous two cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdc79e-c75d-497c-9507-a494b828cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean value of each group\n",
    "print(\"Group 2020 mean gross margin:\", group_2020['margin'].mean())\n",
    "print(\"Group 2021 mean gross margin:\", group_2021['margin'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182e204f-7593-42c4-ad40-aed18d72fff3",
   "metadata": {},
   "source": [
    "The average gross margin of group 2021 is slightly higher than of group 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09740553-ed32-4242-abf3-4031a1faa929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting histograms to compare the distributions of the groups' gross profit margins\n",
    "plt.subplots(figsize=(8,7))\n",
    "plt.hist(group_2020['margin'], bins=50, color='steelblue', edgecolor='black', alpha=0.7, label='group 2020')\n",
    "plt.hist(group_2021['margin'], bins=50, color='lime', edgecolor='black', alpha=0.3, label='group 2021')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('gross profit margin')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Distribution of gross margins per group')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45c8175-5457-4b9e-a66d-f176395e2c2c",
   "metadata": {},
   "source": [
    "The distributions of the groups' gross margins look similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f14fb-6f13-40cd-a6e8-002ec17d1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if groups distributions are normal with Shapiro-Wilk test\n",
    "stat_2020, p_2020 = stats.shapiro(group_2020['margin'])\n",
    "stat_2021, p_2021 = stats.shapiro(group_2021['margin'])\n",
    "\n",
    "print(f\"Group 2020 normality p-value: {p_2020}\")\n",
    "print(f\"Group 2021 normality p-value: {p_2021}\")\n",
    "\n",
    "if p_2020 > alpha and p_2021 > alpha:\n",
    "    print(\"Both samples have normal distribution.\")\n",
    "else:\n",
    "    print(\"The samples do not follow normal distribution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b3ca0-9d50-4665-ad64-7e87c1ed3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mann-whitney U test for the not normal distribution\n",
    "statist, p_value = stats.mannwhitneyu(group_2020['margin'], group_2021['margin'])\n",
    "print(p_value)\n",
    "if p_value < alpha:\n",
    "    print('Reject H0')\n",
    "else:\n",
    "    print('Fail to Reject H0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06893a2-d672-45d1-b42a-b5d1a4be4e4c",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "* p-value = 0.0036 < 0.05\n",
    "* The null hypothesis that there is no difference in gross margins of 2020 and 2021 is rejected.\n",
    "* Based on the raw data, there is a difference between gross profit margins in 2020 and 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d2b63b-ccac-417b-9384-71768b8a0f53",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda0406-31a5-4e4b-80bd-45b7a8303618",
   "metadata": {},
   "source": [
    "<h4>clean data</h4> <a id='case_2020_2021_clean'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f06354-18c1-4300-a2f0-56cc666ed970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of each group\n",
    "print(\"Clean group 2020 size:\", group_2020_clean['margin'].count())\n",
    "print(\"Clean group 2021 size:\", group_2021_clean['margin'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa9dc27-75ce-4381-8b7d-9240f5989e9f",
   "metadata": {},
   "source": [
    "The sample sizes are almost equal. \\\n",
    "Group 2020 has 5% less data than group 2011. \\\n",
    "The hypothesis test requirement for a fair split between groups is satisfied. \\\n",
    "The test results will be more precise than in the previous two cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287b66f4-b1c4-4320-b3ed-17efd8dc498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean values of each group\n",
    "print(\"Clean group 2020 mean gross margin:\", group_2020_clean['margin'].mean())\n",
    "print(\"Clean group 2021 mean gross margin:\", group_2021_clean['margin'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c69139-a880-476a-bd33-6a7ee1d529a8",
   "metadata": {},
   "source": [
    "The average gross margin of filtered group 2021 is higher than of filtered group 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90927b3e-d48d-40fd-b5fe-d93b64b578bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting histograms to compare the distributions of the filtered groups' gross profit margins\n",
    "plt.subplots(figsize=(8,7))\n",
    "plt.hist(group_2020_clean['margin'], bins=50, color='steelblue', edgecolor='black', alpha=0.7, label='group 2020 clean')\n",
    "plt.hist(group_2021_clean['margin'], bins=50, color='lime', edgecolor='black', alpha=0.3, label='group 2021 clean')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('gross profit margin')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Distribution of gross margins per filtered group')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea8241-1511-4510-a29a-c6e25ff0ef86",
   "metadata": {},
   "source": [
    "The distributions of the filtered groups' gross margins look similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5daba-5cc0-43d7-bd98-53a4d2f226f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking normality with Shapiro-Wilk test\n",
    "stat_2020_clean, p_2020_clean = stats.shapiro(group_2020_clean['margin'])\n",
    "stat_2021_clean, p_2021_clean = stats.shapiro(group_2021_clean['margin'])\n",
    "\n",
    "print(f\"Clean group 2020 normality p-value: {p_2020_clean}\")\n",
    "print(f\"Clean group 2021 normality p-value: {p_2021_clean}\")\n",
    "\n",
    "if p_2020_clean > alpha and p_2021_clean > alpha:\n",
    "    print(\"Both filtered groups have the normal distribution.\")\n",
    "else:\n",
    "    print(\"The filtered groups do not follow the normal distribution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56595ad5-84c4-4c84-8a7a-42f32b7bee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mann-whitney U test for the not normal distribution\n",
    "statist, p_value = stats.mannwhitneyu(group_2020_clean['margin'], group_2021_clean['margin'])\n",
    "print(p_value)\n",
    "if p_value < alpha:\n",
    "    print('Reject H0')\n",
    "else:\n",
    "    print('Fail to Reject H0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ccc23f-6c5b-47c0-8578-a20ce5b8b438",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "* p-value = 0.0000 < 0.05\n",
    "* The null hypothesis that there is no difference in gross margins of 2020 and 2021 is rejected.\n",
    "* Based on the filtered data, there is a difference between gross profit margins in 2020 and 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a00655-feaa-45e1-b767-4bdcae4751ee",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_18'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ab359b-b8e8-4952-abff-06b3462171dd",
   "metadata": {},
   "source": [
    "* The data is split into groups per year.\n",
    "* 2 test sets are created: with raw and clean data.\n",
    "* The hypothesis is tested in 3 different scenarios:\n",
    "    1. a case with the biggest difference in manufacturing costs: years 2018 and 2022\n",
    "    2. a case with the difference in total gross margin values: years 2018 (61%) and 2019 (62%)\n",
    "    3. a case with almost equal sample sizes: years 2020 and 2021\n",
    "* In cases 1 and 2 the test requirement for a fair split between the groups is not satisfied:\n",
    "    * group 2022 has 21% less data than group 2018\n",
    "    * group 2018 has almost twice (49%) less data than group 2019\n",
    "* The chosen significance level is 5%.\n",
    "* All groups do not follow the normal distribution according to Shapiro-Wilk test.\n",
    "* Mann-Whitney U test is used to test the hypothesis.\n",
    "* Based on both raw and filtered data, the null hypothesis that there is no difference between gross margins of different years is rejected at the 5% significance level.\n",
    "* There is a 95% probability that the difference between gross margins of different years is the result of a true difference between groups being compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426cbd44-319e-4733-a979-77792cf3b160",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba1bf12-348e-43a7-b145-b6119cbe93fa",
   "metadata": {},
   "source": [
    "<h2>4.3. Statistical tests 2 and 3: relationship between manufacturing cost and gross margin</h2> <a id='statistical_test_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b2e6c-b2e5-40d8-9663-c2dd35420b8a",
   "metadata": {},
   "source": [
    "To explore a relationship between manufacturing cost and gross margin, the following analyses will be conducted:\n",
    "* correlation analysis: to check if there is a relationship between the 2 variables\n",
    "* regression analysis: to check if the relationship is linear\n",
    "\n",
    "The following tests will be performed:\n",
    "* Spearman's Rank Correlation for correlation analysis\n",
    "* Linear least-squares regression for regression analysis\n",
    "\n",
    "Spearman's hypothesis testing:\n",
    "* H0: There is no relationship between manufacturing cost and gross margin.\n",
    "* HA: There is a significant relationship between manufacturing cost and gross margin.\n",
    "\n",
    "Linear regression hypothesis testing:\n",
    "* H0: There is no linear relationship between manufacturing cost and gross margin.\n",
    "* HA: There is a statistically significant linear relationship between manufacturing cost and gross margin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff625eb5-e6cd-4412-bf8d-41ff7fe3694e",
   "metadata": {},
   "source": [
    "<h3>Correlation analysis</h3> <a id='correlation_analysis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e483000-29c1-42c3-946f-ab21089a817e",
   "metadata": {},
   "source": [
    "Spearman's Rank Correlation test will be used to perform the correlation analysis because:\n",
    "* manufacturing costs and gross margins are not normally distributed\n",
    "* gross margin has outliers\n",
    "\n",
    "Spearman's Rank Correlation:\n",
    "* is a nonparametric test, so it does not require the data to be normally distributed or free of outliers\n",
    "* works by ranking the data, rather than relying on raw values, which reduces the impact of extreme values\n",
    "* assesses the strength and direction of the relationship between variables\n",
    "* doesn't assume a linear relationship between variables and can detect non-linear associations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7c6a10-7ac5-4a46-bf2a-349d89daae64",
   "metadata": {},
   "source": [
    "The scipy.stats.spearmanr function is used to compute Spearman's rank correlation test.\n",
    "\n",
    "The function returns:\n",
    "* Spearman's correlation coefficient: indicates the strength and direction of the relationship\n",
    "    * 0: no correlation\n",
    "    * +1: a strong positive correlation\n",
    "    * -1: a strong negative correlation\n",
    "* p-value: tells whether the correlation is statistically significant (whether the observed correlation is unlikely to have occurred by chance)\n",
    "    * p-value < 0.05: the correlation is statistically significant (the null hypothesis can be rejected)\n",
    "    * p-value > 0.05: suggests no statistically significant correlation (the null hypothesis cannot be rejected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df388bde-babd-4d9a-b484-1cd7f2da9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman's Rank Correlation test\n",
    "corr, p_value = stats.spearmanr(cost_margin['manufacturing_cost'], cost_margin['margin'])\n",
    "print(f\"Spearman's rank correlation coefficient: {corr}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject H0: There is a statistically significant relationship between manufacturing costs and gross profit margin.\")\n",
    "else:\n",
    "    print(\"Fail to reject H0: There is no statistically significant relationship between manufacturing costs and gross profit margin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154469f1-f57a-4f36-b335-fcacf8dd96c6",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "* The correlation coefficient of -0.024 suggests a negative relationship between manufacturing costs and margins.\n",
    "* The p-value of 0.000 is less than 0.05, which indicates that the correlation is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ea1f41-1419-463d-84f8-eda99bb6380d",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2306bbd4-240c-4bcb-bc83-6c247efa7817",
   "metadata": {},
   "source": [
    "<h3>Regression analysis</h3> <a id='regression_analysis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d8e033-f206-43fc-9ab2-5e361801c728",
   "metadata": {},
   "source": [
    "Checking linearity with the regression analysis:\n",
    "* The linear least-squares regression function stats.linregress is used to check if there is a linear relationship between manufacturing costs and gross margins.\n",
    "* A scatter plot is used to visualize the relationship between manifacturing costs and gross margins.\n",
    "* A linear correlation (regression) line is used to visualize a trend in the relationship between the 2 variables: \\\n",
    "  regression line = slope * cost_margin['manufacturing_cost'] + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68786e4-306f-47d3-9c2d-f2a89c5d79a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cost_margin['manufacturing_cost'], cost_margin['margin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae536e0f-05aa-44cc-a004-8831a6529d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot to visualize the relationship\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.scatter(cost_margin['manufacturing_cost'], cost_margin['margin'], color='steelblue', alpha=0.5)\n",
    "plt.title('Relationship between manufacturing costs and gross margins')\n",
    "plt.xlabel('manufacturing cost')\n",
    "plt.ylabel('gross profit margin')\n",
    "\n",
    "# plotting the regression line\n",
    "plt.plot(cost_margin['manufacturing_cost'], slope * cost_margin['manufacturing_cost'] + intercept, color='orange',  alpha=0.8, linewidth=2)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93db2ee-d610-4281-9c18-855b83d8d988",
   "metadata": {},
   "source": [
    "The regression line is slightly descending, which indicates a negative trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e11e0-e49b-4a8f-9535-aa83b0feb44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the regression parameters\n",
    "print(f\"slope: {slope}\")\n",
    "print(f\"r value: {r_value}\")\n",
    "\n",
    "# printing the result of the linearity check\n",
    "print(f\"p-value: {p_value}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject H0: The linear relationship between manufacturing costs and gross profit margin is statistically significant.\")\n",
    "else:\n",
    "    print(\"Fail to reject H0: The linear relationship between manufacturing costs and gross profit margin is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995b3851-6b26-435d-8716-2fad1fb3d7bc",
   "metadata": {},
   "source": [
    "__Slope__ = the coefficient of the independent variable (here: manufacturing_cost). \\\n",
    "It represents:\n",
    "1. the rate of change in the dependent variable (margin) for a unit change in the independent variable (manufacturing_cost)\n",
    "2. the strength of the relationship:\n",
    "    * slope = 0: manufacturing costs have no significant effect on gross margin\n",
    "    * slope != 0: manufacturing costs do significantly affect gross margin\n",
    "3. the direction of the relationship:\n",
    "    * slope is positive: as manufacturing costs increase, gross margin also increases (positive relationship)\n",
    "    * slope is negative: as manufacturing costs increase, gross margin decreases (negative relationship)\n",
    "\n",
    "Here: for every 1 unit increase in manufacturing cost, margin decreases by 0.0009 units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1ffb98-459e-419e-a06c-c94ffa0d51af",
   "metadata": {},
   "source": [
    "__r value__ = the correlation coefficient. \\\n",
    "It measures the strength and direction of the linear relationship between the two variables:\n",
    "* r = +1: perfect positive linear correlation\n",
    "* 1 > r  0.8: strong positive linear correlation\n",
    "* 0.8 > r  0.4: moderate positive linear correlation\n",
    "* 0.4 > r > 0: weak positive linear correlation\n",
    "* r = 0: no linear relationship\n",
    "* 0 > r  0.4: weak negative linear correlation\n",
    "* 0.4 > r  0.8: moderate negative linear correlation\n",
    "* 0.8 > r > 1: strong negative linear correlation\n",
    "* r = 1: perfect negative linear correlation\n",
    "\n",
    "Here: there is a weak negative linear relationship between manufacturing cost and margin (r value = -0.03)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82af218c-fefa-4c5f-928a-5dc2b6fb5af3",
   "metadata": {},
   "source": [
    "__p-value__ = a measure of the statistical significance of the relationship between the two variables. \\\n",
    "It tests the null hypothesis that there is no linear relationship between manufacturing cost and margin:\n",
    "* p-value < 0.05: there is a statistically significant linear relationship between manufacturing cost and margin (the null hypothesis can be rejected)\n",
    "* p-value > 0.05: the relationship is not statistically significant (the null hypothesis cannot be rejected)\n",
    "\n",
    "Here: the linear relationship between manufacturing cost and margin is statistically significant at the 5% significance level (p-value < 0.05)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b44f0-fe6f-4f22-ab11-402b964a693d",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "\n",
    "Manufacturing costs statistically significantly (p-value less than 0.05) affect gross margin via the linear relationship:\n",
    "* This is a weak negative linear correlation (r value = -0.03).\n",
    "* For every 1 unit increase in manufacturing cost, margin decreases by 0.0009 units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf66ea-7867-422f-9114-c3a588128235",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_19'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84808f0c-c95a-4cb9-aa3c-0414e15b5765",
   "metadata": {},
   "source": [
    "* 2 tests are performed to explore the relationship between manufacturing cost and gross margin:\n",
    "  1. Spearman's Rank Correlation: to see if there is a relationship between the 2 variables\n",
    "  2. Linear least-squares regression: to check if the relationship is linear\n",
    "* The chosen significance level is 5%.\n",
    "* The null hypothesis that there is no (linear) relationship between manufacturing cost and gross margin is rejected at the 5% significance level.\n",
    "* The negative correlation between manufacturing cost and gross margin is statistically significant (p-value < 0.05), but weak (Spearman's correlation coefficient = -0.024).\n",
    "* The negative linear relationship between manufacturing cost and margin is statistically significant (p-value < 0.05), but weak (r value = -0.03).\n",
    "* For every 1 unit increase in manufacturing cost, margin decreases by 0.0009 units.\n",
    "* Rising manufacturing costs do negatively affect gross profit margins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d30ac92-d540-44c9-b095-4ef7e4cbbb2b",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ccee2-c8c4-46be-b76a-06912e53042e",
   "metadata": {},
   "source": [
    "<h2>Hypothesis testing summary</h2> <a id='summary_4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc60b928-4a6c-4cc5-baeb-5ab6088d8808",
   "metadata": {},
   "source": [
    "__Hypothesis:__ rising manufacturing costs negatively impact the companys gross profit margins.\n",
    "\n",
    "__Steps__ in testing the hypothesis:\n",
    "1. prepare data\n",
    "2. check if there is a difference in average gross margins\n",
    "3. evaluate the relationship between manufacturing costs and gross margins\n",
    "\n",
    "__Data:__\n",
    "* manufacturing costs and gross margins do not follow the normal distribution\n",
    "* manufacturing cost values do not have outliers\n",
    "* gross margin values have outliers from the 98th percentile\n",
    "\n",
    "__Data preparation:__\n",
    "* table 'cost_margin' with manufacturing costs and gross profit margin per product\n",
    "* table 'filtered_cost_margin' without outliers\n",
    "\n",
    "The following __statistical tests__ are used:\n",
    "1. nonparametric Mann-Whitney U test: to see if average gross  margins vary per year\n",
    "2. nonparametric Spearman's Rank Correlation: to check if there is a relationship between manufacturing costs and gross margins\n",
    "3. linear least-squares regression: to examine if this relationship is linear\n",
    "\n",
    "__Tests settings:__\n",
    "* the chosen significance level for all tests is 5%\n",
    "* the tests are performed accounting for all products each year to ensure sufficient sample sizes\n",
    "\n",
    "__Test 1: average gross margins__\n",
    "* H0: There is no difference between gross margins of different years. \\\n",
    "  HA: There is a difference between gross margins of different years.\n",
    "* Mann-Whitney U test is used to test the hypothesis, because:\n",
    "    * average gross margin is a continuous metric\n",
    "    * all groups do not follow the normal distribution according to Shapiro-Wilk test\n",
    "* the data is split into groups per year\n",
    "* the test is performed on both raw and clean data\n",
    "* the hypothesis is tested in 3 different scenarios:\n",
    "    1. a case with the biggest difference in manufacturing costs: years 2018 and 2022\n",
    "    2. a case with the difference in total gross margin values: years 2018 (61%) and 2019 (62%)\n",
    "    3. a case with almost equal sample sizes: years 2020 and 2021\n",
    "* in cases 1 and 2 the test requirement for a fair split between the groups is not satisfied:\n",
    "    * group 2022 has 21% less data than group 2018\n",
    "    * group 2018 has almost twice (49%) less data than group 2019\n",
    "* the null hypothesis is rejected at the 5% significance level, based on both raw and clean data\n",
    "* there is a difference between gross profit margins in all 3 cases\n",
    "\n",
    "__Test 2: relationship between manufacturing costs and gross margins__\n",
    "* H0: There is no relationship between manufacturing cost and gross margin. \\\n",
    "  HA: There is a relationship between manufacturing cost and gross margin.\n",
    "* Spearmans Rank Correlation test is used to perform the correlation analysis, because:\n",
    "    * manufacturing costs and gross margins are not normally distributed\n",
    "    * gross margin values have outliers\n",
    "* the null hypothesis is rejected at the 5% significance level\n",
    "* there is a relationship between manufacturing cost and gross margin\n",
    "* the correlation is negative and weak (Spearman's correlation coefficient = -0.024)\n",
    "\n",
    "__Test 3: linearity__\n",
    "* H0: There is no linear relationship between manufacturing cost and gross margin. \\\n",
    "  HA: There is a linear relationship between manufacturing cost and gross margin.\n",
    "* linear least-squares regression is used to perform the regression analysis\n",
    "* the null hypothesis is rejected at the 5% significance level\n",
    "* there is a linear relationship between manufacturing cost and gross margin\n",
    "* the relationship is negative and weak (r value = -0.03)\n",
    "\n",
    "__*Conclusions:*__\n",
    "* There is a statistically significant difference between average gross margins of different years.\n",
    "* The negative correlation between manufacturing cost and gross margin is statistically significant, but weak.\n",
    "* The negative linear relationship between manufacturing cost and margin is statistically significant, but weak.\n",
    "* For every 1 unit increase in manufacturing cost, margin decreases by 0.0009 units.\n",
    "* Rising manufacturing costs negatively affect the companys gross profit margins, but this impact is not big."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6428cc32-beb0-4a5f-b4f3-3541a4fc4f17",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30b1e1-918c-48ee-a103-cae470d3c356",
   "metadata": {},
   "source": [
    "<h1>5. ML model</h1> <a id='ml_model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60440d8-7c98-4f73-bfde-962d333f51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# method for converting categorical variables into a binary format\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# sklearn class to selectively apply data transformation to different columns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# parametric transformer to make data more normal\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "# learning algorithms\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# models' evaluation metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# function that performs hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a4002c-8ea8-455b-a573-8e11f91b01d9",
   "metadata": {},
   "source": [
    "Building a regression model for profit prediction.\n",
    "\n",
    "__Goal:__ profit forecast based on the available features.\n",
    "\n",
    "__Target:__ gross profit.\n",
    "\n",
    "__Task type:__ a regression task since the target is a continuous variable.\n",
    "\n",
    "__Learning algorithms:__\n",
    "* Linear Regression\n",
    "* Random Forest Regressor\n",
    "\n",
    "__Steps:__ \n",
    "* aggregate data:\n",
    "    * select columns from the database\n",
    "    * creating additional columns\n",
    "* exploratory data analysis:\n",
    "    * missing values\n",
    "    * duplicate values\n",
    "    * statistics of numerical columns\n",
    "    * visualize distributions\n",
    "    * define outliers\n",
    "* split data:\n",
    "    * into training, validation, and test sets\n",
    "    * each set into features and target\n",
    "* preprocess data:\n",
    "    * encode categorical variables\n",
    "    * transform outliers\n",
    "    * scale (normalize) numerical variables\n",
    "* create 2 models:\n",
    "    * Linear Regression model\n",
    "    * Random Forest Regressor model\n",
    "* evaluate models\n",
    "* hyperparameter tuning\n",
    "* validate models\n",
    "* test model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82040365-fb6b-4a1e-bd7f-af9f58d8eda1",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c713b39e-6a7f-4ea1-840e-25e3cbbe767a",
   "metadata": {},
   "source": [
    "<h2>5.1. Data preparation</h2> <a id='data_preparation_ml'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30236dba-d9ac-46d7-aa06-ffd78a7e8246",
   "metadata": {},
   "source": [
    "<h3>Data aggregation</h3> <a id='data_aggregation_ml'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e5a87-7c43-4303-9361-429ab4facce6",
   "metadata": {},
   "source": [
    "Creating a table with data needed for building the ML model:\n",
    "* selecting the required columns from the database\n",
    "* feature engineering: creating an additional column 'profit_per_unit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893704d7-d21c-4f0e-9511-7d8b3672dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataframe with the required columns\n",
    "query=\"\"\"\n",
    "SELECT\n",
    "    sales.date,\n",
    "    customer.region,\n",
    "    sales.fiscal_year,\n",
    "    price.gross_price,\n",
    "    cost.manufacturing_cost,\n",
    "    discount.pre_invoice_discount_pct,\n",
    "    sales.sold_quantity,\n",
    "    (price.gross_price - price.gross_price * discount.pre_invoice_discount_pct - cost.manufacturing_cost) AS profit_per_unit\n",
    "FROM\n",
    "    fact_sales_monthly sales\n",
    "JOIN\n",
    "    dim_customer customer\n",
    "    ON sales.customer_code = customer.customer_code\n",
    "JOIN\n",
    "    fact_gross_price price\n",
    "    ON sales.product_code = price.product_code\n",
    "    AND sales.fiscal_year = price.fiscal_year\n",
    "JOIN\n",
    "    fact_manufacturing_cost cost\n",
    "    ON sales.product_code = cost.product_code\n",
    "    AND sales.fiscal_year = cost.cost_year\n",
    "JOIN\n",
    "    fact_pre_discount discount\n",
    "    ON  sales.customer_code = discount.customer_code\n",
    "    AND sales.fiscal_year = discount.fiscal_year\n",
    "\"\"\"\n",
    "df=pd.read_sql_query(query, con)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851aa6ee-9d08-46b2-9ba9-892649169ec2",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0860fe9d-fc64-41d0-9a2c-8b7a9398429c",
   "metadata": {},
   "source": [
    "<h3>EDA</h3> <a id='eda_ml'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea71889-afbb-474e-86ce-40f666793d4d",
   "metadata": {},
   "source": [
    "Steps:\n",
    "* check missing values\n",
    "* check duplicate values\n",
    "* check statistics of numerical columns\n",
    "* visualize the columns' distributions via box plots\n",
    "* define outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7fd0d8-ec97-46dd-b40a-da123ed608ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general information about the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ebbcd-ea3d-4511-b0ff-9d1b9f66f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44033c8-3efd-4721-8fd1-8299a0302bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'keep=False' shows all occurrences of duplicates (not just the 1st occurence)\n",
    "df[df.duplicated(keep=False)].head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eab5ec-97f5-4eda-827c-c0287e53f8c5",
   "metadata": {},
   "source": [
    "There are 28 duplicate rows. \\\n",
    "The original dataset has no duplicate values according to the step 1: data preprocessing. \\\n",
    "These 28 duplicates occured because the columns 'customer_code' and 'product_code' are not included in the aggregated ML dataset. \\\n",
    "Since they represent true correct values from different customers, it is better not to remove them in order to keep the data close to the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614224b1-d353-4902-b891-173d1a89c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking statistics of the numerical columns\n",
    "df[['gross_price', 'manufacturing_cost', 'pre_invoice_discount_pct', 'sold_quantity', 'profit_per_unit']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688511c6-e3a7-4c10-aa4e-338a13c89df3",
   "metadata": {},
   "source": [
    "__Checking outliers via box plots__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6361d713-6072-45d6-952d-923964f23223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the distribution of values in the numerical columns to check for outliers\n",
    "for column in ['gross_price', 'manufacturing_cost', 'pre_invoice_discount_pct', 'sold_quantity', 'profit_per_unit']:\n",
    "    px.box(df, y=column, title=f'The distribution of {column}').update_layout(xaxis_title=column, yaxis_title='value').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b42906a-b33c-48b3-8727-73fe92ba8622",
   "metadata": {},
   "source": [
    "There are no outliers in the columns:\n",
    "* gross_price\n",
    "* manufacturing_cost\n",
    "\n",
    "There are outliers in the columns:\n",
    "* pre_invoice_discount_pct: below the lower bound 0.0953\n",
    "* sold_quantity: above the upper bound 119\n",
    "* profit_per_unit: above the upper bound 15.412"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5acbeb-9eab-42e7-b94b-5105f8070c6f",
   "metadata": {},
   "source": [
    "__Defining outliers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ab569-aaf2-46f9-87e3-554e2a59a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating percentiles to define outliers in discount values\n",
    "print(np.percentile(df['pre_invoice_discount_pct'], [3, 4, 5, 5.8, 5.9, 6, 7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5502b83b-5a7c-4458-861d-354f100e13c3",
   "metadata": {},
   "source": [
    "The discount outliers start between 5th and 6th percentile. \\\n",
    "The 5.9th percentile with the value 0.0953 can be defined as the upper limit below which the discount values starts to be considered an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c5334a-389e-4801-84d2-893594464a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating percentiles to define outliers in sold quantities\n",
    "print(np.percentile(df['sold_quantity'], [85, 86, 87, 88, 89, 89.2, 89.3, 90]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff0fa68-043a-44bd-9b16-aaebb6727f1b",
   "metadata": {},
   "source": [
    "The sold quantity outliers start between 89th and 90th percentile. \\\n",
    "The 89.2th percentile can be defined as the lower limit from which the sold quantities start to be considered an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467b9e9-984c-4342-801a-4896dd6f25ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating percentiles to define outliers in profit values\n",
    "print(np.percentile(df['profit_per_unit'], [95, 97, 98, 98.8, 98.9, 99]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a2703-004a-4951-99e9-0f862fba1175",
   "metadata": {},
   "source": [
    "The profit outliers start from 98.8th percentile. \\\n",
    "The 98.8th percentile can be defined as the lower limit from which the profit values start to be considered an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d808267-5eea-444c-9fc5-c67f2b2ac618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the total amount of outliers in the dataframe\n",
    "outliers_number = df[(df['pre_invoice_discount_pct']<0.0953) | (df['sold_quantity']>119) | (df['profit_per_unit']>15.412)]['profit_per_unit'].count()\n",
    "outliers_procent = \"{:.1%}\".format(outliers_number/len(df))\n",
    "outliers_procent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac99a98-bded-4321-9c3d-66f7d5460314",
   "metadata": {},
   "source": [
    "Outliers represent 16.3% of the data. \\\n",
    "In this case it is better:\n",
    "- not to delete these observations\n",
    "- use transforming techniques or imputation not to lose the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b90d66-9ed8-4c3c-aa13-9e9a7dec4091",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "* The dataframe has no missing values.\n",
    "* The dataframe has 28 duplicate rows.\n",
    "* The duplicate rows represent identical orders, but from different customers.\n",
    "* These values are kept to correctly represent the original dataset.\n",
    "* There are no outliers in the columns 'gross_price' and 'manufacturing_cost'.\n",
    "* There are outliers in 3 columns: 'pre_invoice_discount_pct', 'sold_quantity', 'profit_per_unit'.\n",
    "* Outliers represent 16.3% of the data.\n",
    "* The outliers will be transformed after splitting the data to prevent data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb1f17a-e4dc-4f7f-8d44-fb4dbd51816f",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a36596e-427f-4ab4-9946-30ec446a96c4",
   "metadata": {},
   "source": [
    "<h3>Data split</h3> <a id='split_ml'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfee5f5-732a-4b04-80d7-7b04cd7f8072",
   "metadata": {},
   "source": [
    "Splitting the data before feature engineering is essential in order to prevent data leakage. \\\n",
    "Data leakage happens when information from outside the training dataset is used to create the model.\n",
    "\n",
    "Steps:\n",
    "* split the source dataset into a training, a validation, and a test set\n",
    "* split each set into features and target\n",
    "\n",
    "The target feature that is to be predicted by using the rest of the features is gross profit, stored in the column 'profit_per_unit'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ac066-1aaa-4015-b977-99b538727be2",
   "metadata": {},
   "source": [
    "__Splitting the source data into a training set, a validation set, and a test set__\n",
    "\n",
    "Since the test set doesn't exist separately, the source data has to be split:\n",
    "* into three parts: training, validation, and test\n",
    "* in a 3:1:1 ratio (60% : 20% : 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560099d-44fd-4334-8c13-7c64e1721284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocating 80% of data to the training set and 20% to the test set\n",
    "df_80, df_test = train_test_split(df, train_size=0.8, test_size=0.2, random_state=84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5117bb23-6701-4778-947b-196fdcc14360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the remaining 80% of data into training and validating sets\n",
    "df_train, df_valid = train_test_split(df_80, train_size=0.75, test_size=0.25, random_state=84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d43334-71d7-440d-8dd1-2324c3bf2fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the split between the sets\n",
    "display(df_80.shape)\n",
    "display(df_train.shape)\n",
    "display(df_valid.shape)\n",
    "display(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce38b48-add8-44ea-a89f-a28c1e8b072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the datasets' percentages\n",
    "display(\"Training set: {:.1%}\".format(len(df_train)/len(df)))\n",
    "display(\"Validation set: {:.1%}\".format(len(df_valid)/len(df)))\n",
    "display(\"Test set: {:.1%}\".format(len(df_test)/len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bcb1b5-6e38-4f85-b25f-970bb493c7b2",
   "metadata": {},
   "source": [
    "The dataset df is correctly split into 3 new datasets: df_train (60%), df_valid (20%), df_test (20%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7185fb-5425-4abf-a0d9-228dc0e33687",
   "metadata": {},
   "source": [
    "__Splitting the data of the 3 sets into features and target__\n",
    "\n",
    "The target feature that is to be predicted by using the rest of the features is gross profit, stored in the column 'profit_per_unit'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e81071d-a833-4e4f-aeab-12948bcb92e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring variables for features and target of the training set\n",
    "features_train = df_train.drop('profit_per_unit', axis=1)\n",
    "# real y values, known to model\n",
    "target_train = df_train['profit_per_unit']\n",
    "# checking the split by printing the size of the tables stored in these 2 variables\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf099dee-b960-458a-bec4-410d1365a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring variables for features and target of the validating set\n",
    "features_valid = df_valid.drop('profit_per_unit', axis=1)\n",
    "# real y values, unknown to model\n",
    "target_valid = df_valid['profit_per_unit']\n",
    "# checking the split\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decaba16-de6b-47d1-b364-1d82ee8f30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring variables for features and target of the test set\n",
    "features_test = df_test.drop('profit_per_unit', axis=1)\n",
    "# real y values, unknown to model\n",
    "target_test = df_test['profit_per_unit']\n",
    "# checking the split\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5606315-cbd5-48dd-9e1b-c910195a56ec",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "* The source dataset is split into 3 sets: df_train, df_valid, df_test.\n",
    "* The corresponding sets' sizes are: 60%, 20%, 20%.\n",
    "* Each set is split into features and target: features_train, target_train, features_valid, target_valid, features_test, target_test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db23bdb-3bf1-4ba7-b63f-a767601ba151",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366f0213-b71d-4e9d-a1ed-6f50ed2451e8",
   "metadata": {},
   "source": [
    "<h3>Feature engineering</h3> <a id='feature_engineering_ml'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a644de-0504-412b-8f30-b57a3fae0617",
   "metadata": {},
   "source": [
    "Steps:\n",
    "* encode categorical variables\n",
    "* transform outliers\n",
    "* scale numerical variables\n",
    "\n",
    "All encoding and transformation techniques should be fit on the training data and applied to both training and test sets to avoid data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce443f4-ebb7-49b0-ba72-404907da0c94",
   "metadata": {},
   "source": [
    "<h4>Encoding categorical variables</h4> <a id='categorical_variables_ml'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aa236c-ceb1-4da3-ab08-cc6d40e3cf8b",
   "metadata": {},
   "source": [
    "In ML regression models it is necessary to handle categorical variables, because:\n",
    "* regression algorithms require numeric input\n",
    "* raw categorical variables (like product_code, region, customer_code) cannot be directly used by all models\n",
    "* if left as they are (as strings or non-numeric values), the algorithms will either throw an error or misinterpret the data, leading to incorrect results\n",
    "\n",
    "Categorical variables can be encoded using the following techniques:\n",
    "* Label encoding:\n",
    "    * for ordinal categorical variables, where the order of the categories matters\n",
    "* One-Hot encoding:\n",
    "    * for nominal categorical variables (variables where there is no inherent order)\n",
    "    * creates a new separate binary (0/1) column for each unique category from the original column\n",
    "* Frequency encoding:\n",
    "    * for high cardinality categorical variables (variables with many unique categories) \n",
    "    * replaces each category in a variable with the frequency or count of that category in the dataset\n",
    "    * creates 1 column where each category is replaced by its frequency count\n",
    "    * helps prevent a large number of dummy variables (which would occur in One-Hot encoding)\n",
    "* Binary encoding\n",
    "    * for high cardinality categorical variables\n",
    "    * converts each category into binary numbers and breaks these binary values into separate columns\n",
    "\n",
    "In this project the categorical variables will be handled as follows:\n",
    "* date:\n",
    "    1. convert to a datetime object\n",
    "    2. extract year, month and day\n",
    "    3. remove the original column\n",
    "* region:\n",
    "    * encode using One-Hot encoding method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449b685c-07f0-47bb-bc6c-99869e0c89a4",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e512b59-f95c-48c8-b161-94edf2f1af4c",
   "metadata": {},
   "source": [
    "__Transforming the column 'date'__ \\\n",
    "(converting to a datetime object and extracting year, month and day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e142e74-0711-4da9-8e48-c52bf21434e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a custom function to transform the date data for features\n",
    "def transform_date(features_train, features_valid, features_test):\n",
    "    features = [features_train, features_valid, features_test]\n",
    "    for feature in features:\n",
    "        # converting the 'date' column to a datetime object\n",
    "        feature['date'] = pd.to_datetime(feature['date'])\n",
    "        # extracting year, month and day\n",
    "        feature['year'] = feature['date'].dt.year\n",
    "        feature['month'] = feature['date'].dt.month\n",
    "        feature['day'] = feature['date'].dt.day\n",
    "        # dropping the original 'date' column\n",
    "        feature.drop(columns=['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f48e6-ee12-4fd0-87bd-e5f9e75ef9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_date(features_train, features_valid, features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a61259-5f2c-4694-b4c5-56e6ca746139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if date transformation went correctly on the training set\n",
    "features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db91bd0d-a554-4746-863e-a1cdccf70ea0",
   "metadata": {},
   "source": [
    "For profit prediction, it is beneficial to keep both calendar year and fiscal year, because:\n",
    "* they capture different temporal influences on profit:\n",
    "    * calendar year captures global trends, seasonality, and external factors (e.g., market conditions, public holidays, etc.)\n",
    "    * fiscal year captures company-specific trends, budgeting, and internal cycles\n",
    "* it allows the model to learn from different sources of time-based patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fc20cf-a254-47dd-bcbd-61845b2d5b67",
   "metadata": {},
   "source": [
    "__Encoding the column 'region'__ \\\n",
    "(using One-Hot encoding method)\n",
    "\n",
    "2 ways:\n",
    "1. pandas get_dummies() for data cleaning and EDA: df = pd.get_dummies(df, columns=['region'])\n",
    "2. OneHotEncoder() to transform a categorical column to multiple binary columns for machine learning \\\n",
    "   It saves the exploded categories into its object, which is useful when applying the same data preprocessing on the validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d26a7a-478e-4869-a675-6a46235205d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the transformer\n",
    "## sparse_output=False: the encoder returns and array instead of a sparse matrix\n",
    "## sparse_output=False is necessary when a dataframe should be returned as output\n",
    "### old version of the parameter: sparse\n",
    "### new version of the parameter: sparse_output\n",
    "encoder = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3613102f-b81d-437b-bc7e-19cca6cb8633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a ColumnTransformer to apply the transformation only to 1 categorical column 'region'\n",
    "## remainder='passthrough': to keep other columns unchanged\n",
    "ohe = ColumnTransformer(transformers=[('cat', encoder, ['region'])], remainder=\"passthrough\")\n",
    "ohe.set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a728dc6e-f855-4dae-9ed1-fa4967da72f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting and transforming the training data\n",
    "features_train = ohe.fit_transform(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7edc4-f9c8-48d9-b034-cc961425caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the transformation\n",
    "features_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965483d3-39cf-4155-886e-64030f0b6ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the validation data using the same transformer to ensure consistency\n",
    "features_valid = ohe.transform(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63988f1c-9f7d-431d-8e2c-c0f06c560b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the test data\n",
    "features_test = ohe.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a520ad6b-1ae5-4c0f-86be-7f8360db606a",
   "metadata": {},
   "source": [
    "__Conclusion:__ \\\n",
    "The categorical variables are handled as follows:\n",
    "* date:\n",
    "    * converted to a datetime object\n",
    "    * year, month and day are extracted\n",
    "    * the original 'date' column is removed\n",
    "* region: encoded using One-Hot encoding method\n",
    "\n",
    "Both calendar and fiscal years are kept to:\n",
    "* capture different influences on profit\n",
    "* allow the model to learn from different sources of time-based patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31a08e-00e3-4b17-8ceb-8836bf1f726c",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c7a4f4-1c9f-40c7-bf6a-eff2b30635e6",
   "metadata": {},
   "source": [
    "<h4>Transforming outliers</h4> <a id='transforming_outliers_ml'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dbd13c-a7ee-4096-a2ba-d067617e3265",
   "metadata": {},
   "source": [
    "The ways to deal with outliers:\n",
    "* removing\n",
    "* replacing \\\n",
    "  In the imputation of outliers, one of these values can be used: mean, median, zero value. \\\n",
    "  Median value is not affected by outliers.\n",
    "* transforming \\\n",
    "  Transforming techniques reduce the variation caused by extreme values by converting these values into smaller ones. \\\n",
    "  This method helps to make data normal if it has too many extreme values or skewed.\n",
    "\n",
    "In this dataset:\n",
    "* the values of outliers are rational:\n",
    "    * discounts of 5%-9% make sense\n",
    "    * high sold quantities can be due to either big orders or are for small hardware parts\n",
    "    * high profit values can be for products like desktop computers, laptops, graphic cards\n",
    "* in order to preserve the correct representation of this data it is better to use a transforming technique\n",
    "\n",
    "For a dataset:\n",
    "* before the train-test split it is more convenient to use winsorizing\n",
    "* after the train-test split it is more convenient to use clipping\n",
    "\n",
    "Winsorization restricts outliers to a certain percentile range (usually 1st and 99th or 5th and 95th percentiles), \\\n",
    "so that the data remains more robust and doesn't skew the model.\n",
    "\n",
    "Winsorizing:\n",
    "* replaces outliers with the nearest non-outlier value\n",
    "* sets extreme values equal to a specified percentile of the data \\\n",
    "  (e.g. a 90% winsorization sets all observations greater than the 95th percentile equal to the value at the 95th percentile \\\n",
    "   and all observations less than the 5th percentile equal to the value at the 5th percentile)\n",
    "* can be applied to the test data too\n",
    "\n",
    "In clipping, outliers are replaced with the largest value that is not considered an outlier. \\\n",
    "The effect is the same as winsorizing. \\\n",
    "The difference: in clipping values are used, in winsorizing - percentiles.\n",
    "\n",
    "The numpy.clip() function:\n",
    "* an interval is passed as an array with values to clip\n",
    "* values outside the interval boundary are assigned to boundary values (interval edges)\n",
    "* can be applied to the test data too\n",
    "\n",
    "The numpy.clip() function will be used to limit the effect of outliers on the ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d6c322-51e5-47d1-9c51-059b3d478dbe",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd7db13-7cba-4ccd-b1d5-5cec40abaa0c",
   "metadata": {},
   "source": [
    "__Transforming the numerical features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f0c0d-b12f-44c6-92b2-c49e9d620fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipping outliers in the column 'pre_invoice_discount_pct'\n",
    "# using the parameters to set the fixed values for capping\n",
    "# outliers start below the value 0.0953\n",
    "## the value of the upper limit is set to None to indicate an open interval, since there are no outliers above the upper bound\n",
    "lower_limit = 0.0953\n",
    "features_train['remainder__pre_invoice_discount_pct'] = np.clip(features_train['remainder__pre_invoice_discount_pct'], a_min=lower_limit, a_max=None)\n",
    "features_valid['remainder__pre_invoice_discount_pct'] = np.clip(features_valid['remainder__pre_invoice_discount_pct'], a_min=lower_limit, a_max=None)\n",
    "features_test['remainder__pre_invoice_discount_pct'] = np.clip(features_test['remainder__pre_invoice_discount_pct'], a_min=lower_limit, a_max=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f01d61-6f9a-4ef6-a180-dc806b1d1c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the distribution of discount values for outliers in the features sets after the transformation\n",
    "features = [features_train, features_valid, features_test]\n",
    "names = ['train', 'validate', 'test']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# adding a box plot for each dataframe in features\n",
    "for i, df in enumerate(features):\n",
    "    # setting the name for each trace\n",
    "    trace_name = f\"{names[i]}\"\n",
    "    fig.add_trace(go.Box(y=df['remainder__pre_invoice_discount_pct'], name=trace_name))\n",
    "\n",
    "fig.update_layout(title='Distribution of discount values after transformation', xaxis_title = 'features set', yaxis_title = 'value')\n",
    "fig.show()\n",
    "\n",
    "# using matplotlib\n",
    "#plt.boxplot ([features_train['remainder__pre_invoice_discount_pct'], features_valid['remainder__pre_invoice_discount_pct'], features_test['remainder__pre_invoice_discount_pct']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b31272-b72f-42c5-8df7-40a15332a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipping outliers in the column 'sold_quanity'\n",
    "# outliers start above the value 119\n",
    "# the value of the lower limit is set to None to indicate an open interval, since there are no outliers below the lower bound\n",
    "upper_limit_1 = 119\n",
    "features_train['remainder__sold_quantity'] = np.clip(features_train['remainder__sold_quantity'], a_min=None, a_max=upper_limit_1)\n",
    "features_valid['remainder__sold_quantity'] = np.clip(features_valid['remainder__sold_quantity'], a_min=None, a_max=upper_limit_1)\n",
    "features_test['remainder__sold_quantity'] = np.clip(features_test['remainder__sold_quantity'], a_min=None, a_max=upper_limit_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7565dcb-561c-4d8b-ad73-9248d7f0ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the distribution of sold quantity values for outliers in the features sets  after the transformation\n",
    "fig = go.Figure()\n",
    "for i, df in enumerate(features):\n",
    "    trace_name = f\"{names[i]}\"\n",
    "    fig.add_trace(go.Box(y=df['remainder__sold_quantity'], name=trace_name))\n",
    "fig.update_layout(title='Distribution of sold quantity values after transformation', xaxis_title = 'features set', yaxis_title = 'value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ca6319-4ab5-4d0c-badc-8e677c2885ab",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edda28d4-0935-404e-825d-11d497b7259c",
   "metadata": {},
   "source": [
    "__Transforming the target__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64aa2b-2445-4523-99d3-be1da251ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipping outliers in the target column 'profit_per_unit'\n",
    "# outliers start above the value 15.41\n",
    "# the value of the lower limit is set to None to indicate an open interval, since there are no outliers below the lower bound\n",
    "upper_limit_2 = 15.41\n",
    "target_train = np.clip(target_train, a_min=None, a_max=upper_limit_2)\n",
    "target_valid = np.clip(target_valid, a_min=None, a_max=upper_limit_2)\n",
    "target_test = np.clip(target_test, a_min=None, a_max=upper_limit_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a9d582-b6a4-47b5-801c-7ad152d21bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the distribution of profit values for outliers in the target sets after the transformation\n",
    "targets = [target_train, target_valid, target_test]\n",
    "\n",
    "fig = go.Figure()\n",
    "for i, df in enumerate(targets):\n",
    "    trace_name = f\"{names[i]}\"\n",
    "    fig.add_trace(go.Box(y=df, name=trace_name))\n",
    "fig.update_layout(title='Distribution of profit values after transformation', xaxis_title = 'target set', yaxis_title = 'value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201858b2-c09d-4659-ada8-55e7c902413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the total amount of outliers in the features sets after the transformation\n",
    "for name, df in zip(names, features):\n",
    "    outliers_number = df[(df['remainder__pre_invoice_discount_pct']<lower_limit) | (df['remainder__sold_quantity']>upper_limit_1)]['remainder__sold_quantity'].count()\n",
    "    outliers_procent = \"{:.1%}\".format(outliers_number/len(df))\n",
    "    display(f'The percentage of outliers in the {name} set features: {outliers_procent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175f305-4abd-41c5-bc5f-829c6fc24b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the total amount of outliers in the target sets after the transformation\n",
    "for name, df in zip(names, targets):\n",
    "    outliers_number = df[df>upper_limit_2].count()\n",
    "    outliers_procent = \"{:.1%}\".format(outliers_number/len(df))\n",
    "    display(f'The percentage of outliers in the {name} set target: {outliers_procent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab3c4ad-5320-40de-a7ff-4159146ccb1a",
   "metadata": {},
   "source": [
    "__Conclusion:__ \\\n",
    "The transforming clipping technique is used:\n",
    "* to preserve the correct representation of the data\n",
    "* to limit the effect of the outliers on the ML model\n",
    "\n",
    "The numpy.clip() function is applied to:\n",
    "* the numerical features 'pre_invoice_discount_pct' and 'sold_quanity'\n",
    "* the target variable 'profit_per_unit'\n",
    "* the parameters are used to set the fixed values for capping the lower and upper limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fb00a6-787e-49d9-9766-df76209c303c",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b00cfa-fcda-4cdd-af43-fb5e720a7f0a",
   "metadata": {},
   "source": [
    "<h4>Scaling numerical variables</h4> <a id='numerical_variables_ml'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f177d11f-2c83-4e2a-87f3-692784d49e45",
   "metadata": {},
   "source": [
    "Normalization (feature scaling) is the process of adjusting features' values to a common scale without distorting differences in the data. \\\n",
    "The goals of scaling:\n",
    "* to improve model convergence and performance when the features have vastly different scales or distributions\n",
    "* to ensure the features are on a comparable scale while accounting for the distribution of the data\n",
    "\n",
    "Normalizing (scaling) data is necessary when:\n",
    "* features have vastly different ranges (scales) \\\n",
    "  to ensure that both features are treated equally by the model\n",
    "* the distribution of the data is not normal \\\n",
    "  to make the data with varying distributions suitable for ML algorithms\n",
    "* required by algorithms (such as PCA, linear regression, logistic regression, lasso, ridge regression, k-nearest neighbors, k-means clustering, etc.) \\\n",
    "  to perform effectively\n",
    "\n",
    "Normalizing data is not necessary when:\n",
    "* all the features are already on a similar scale\n",
    "* non-gradient-based algorithms are used (such as tree-based models: Random Forest, XGBoost, etc.) \\\n",
    "In these cases normalization does not improve the model performance, since they are not sensitive to scaling or feature normalization. \\\n",
    "Tree-based models can handle unscaled or skewed data since decision trees are not affected by the magnitude or distribution of features.\n",
    "\n",
    "In regression models:\n",
    "* without normalization: \\\n",
    "  one variable can dominate the model due to its higher range, skewing the regression line and limiting the influence of other variables on the predictions.\n",
    "* with normalization: \\\n",
    "  all features contribute equally to the models learning process, allowing the regression line to more accurately capture the combined influence of all variables on the target. \\\n",
    "  This balanced fit provides a more reliable model output by reducing the impact of scale differences.\n",
    "\n",
    "Feature scaling methods:\n",
    "1. Normalization \\\n",
    "   = the process of the linear transformation of original data to a common scale with a fixed range (0, 1) \\\n",
    "   minimum and maximum values are used for scaling \\\n",
    "   affected by outliers \\\n",
    "   changes the shape of the data distribution \\\n",
    "   maintains the relative data relationships\n",
    "\n",
    "   is used in:\n",
    "    * unknown or not normal distribution\n",
    "    * distance-based algorithms (k-nearest neighbors) to prevent features with larger scales from dominating the distance calculations\n",
    "    * algorithms and neural networks that require data to be on a consistent scale\n",
    "   \n",
    "   is not suitable:\n",
    "    * when data has outliers, as the scaling relies on minimum and maximum values\n",
    "    * for data with non-uniform distributions, as it compresses the data toward the outer boundaries of the scaling range\n",
    "2. Standardization (Z-Score normalization) \\\n",
    "   = the process of transforming data to have a mean = 0 and a standard deviation = 1 \\\n",
    "   mean and standard deviation are used for scaling \\\n",
    "   less sensitive to outliers \\\n",
    "   changes the range of data \\\n",
    "   does not change the relationships between the data points\n",
    "\n",
    "   is used in:\n",
    "    * algorithms that require features to have a common scale\n",
    "    * gradient-based algorithms (linear regression, logistic regression) to ensure balanced contributions from each feature and improving optimization\n",
    "    * dimensionality reduction techniques (PCA), where different feature scales distort the analysis\n",
    "   \n",
    "   is not suitable:\n",
    "    * when data has outliers, as the scaling relies on mean\n",
    "    * for data with not normal distributions, as it assumes a normal distribution pattern\n",
    "3. Robust Scaling \\\n",
    "   = the process of transforming data to have a median = 0 and a IQR = 1 \\\n",
    "   median and interquartile range (IQR) are used for scaling \\\n",
    "   unaffected by outliers \\\n",
    "   maintains the relative relationships between data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16be81c7-af4f-4377-b0c1-74ee131c5b64",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a544e1d6-391f-4e6e-ad92-957295e2c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the distributions of the numerical features in the training set before scaling\n",
    "fig = px.box(features_train[['remainder__gross_price', 'remainder__manufacturing_cost', 'remainder__pre_invoice_discount_pct', 'remainder__sold_quantity']])\n",
    "fig.update_layout(title='Distribution of training set\\'s numerical features before scaling', xaxis_title = 'feature', yaxis_title = 'value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb329a56-a7c3-4796-a733-f2081ed33731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the distributions and scales of the numerical variables in the training set\n",
    "features_train[['remainder__gross_price', 'remainder__manufacturing_cost', 'remainder__pre_invoice_discount_pct', 'remainder__sold_quantity']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bb3978-0cb1-467a-bde4-26eced717f15",
   "metadata": {},
   "source": [
    "Comparison of the box plots and main statistics of the continuous variables reveals that they have different scales. \\\n",
    "Therefore, feature scaling is a necessary step in preparing data for prediction of profit values with a Linear Regression model. \\\n",
    "The Random Forest and XGBoost models do not require scaling, but normalization will not harm their performance. \\\n",
    "So for consistency across models, the same transformation will be applied to different models.\n",
    "\n",
    "Numerical features characteristics:\n",
    "* do not have outliers\n",
    "* are not normally distributed\n",
    "* are skewed\n",
    "\n",
    "In this case the most suitable method for scaling is the Power Transformer:\n",
    "* is not overly sensitive to extreme values\n",
    "* reduces skewness by making features more normally distributed\n",
    "* normalizes skewed data without transforming it into a specific distribution (e.g. uniform)\n",
    "* is non-parametric and works for both positive and negative values\n",
    "\n",
    "The Power Transformer transforms the data by applying a power transformation to make features more symmetric:\n",
    "* the Yeo-Johnson method can handle both positive and negative values\n",
    "* the Box-Cox transformation only works with positive data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f926069-2179-4f72-919f-4937b26edd9e",
   "metadata": {},
   "source": [
    "In this project the following numerical variables will be scaled:\n",
    "* gross_price\n",
    "* manufacturing_cost\n",
    "* pre_invoice_discount_pct\n",
    "* sold_quantity\n",
    "\n",
    "The scikit-learn library PowerTransformer will be used to normalize them.\n",
    "\n",
    "Method: Yeo-Johnson transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694e86b-0064-420e-b21a-d0bd02ffb1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the scaler\n",
    "scaler = PowerTransformer(method='yeo-johnson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483fe423-7f3e-4fc6-9458-5e5000a63d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features using PowerTransformer\n",
    "# fitting the scaler to the training data and transforming it\n",
    "features_train[['remainder__gross_price', 'remainder__manufacturing_cost', 'remainder__pre_invoice_discount_pct', 'remainder__sold_quantity']] = \\\n",
    "scaler.fit_transform(features_train[['remainder__gross_price', 'remainder__manufacturing_cost', 'remainder__pre_invoice_discount_pct', 'remainder__sold_quantity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103d56e-3580-433c-898d-ab11760376fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the distributions of the numerical features in the training set after scaling\n",
    "fig = px.box(features_train[['remainder__gross_price', 'remainder__manufacturing_cost', 'remainder__pre_invoice_discount_pct', 'remainder__sold_quantity']])\n",
    "fig.update_layout(title='Distribution of training set\\'s numerical features after scaling', xaxis_title = 'feature', yaxis_title = 'value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d94c7-c4c1-40e2-bf35-d61444882a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the validation data using the same scaler\n",
    "features_valid[['remainder__gross_price', 'remainder__manufacturing_cost', 'remainder__pre_invoice_discount_pct', 'remainder__sold_quantity']] = \\\n",
    "scaler.transform(features_valid[['remainder__gross_price', 'remainder__manufacturing_cost', 'remainder__pre_invoice_discount_pct', 'remainder__sold_quantity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c0e191-baec-4e50-bb0f-428d1422dc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the distributions of the numerical features in the validation set after scaling\n",
    "fig = px.box(features_valid[['remainder__gross_price', 'remainder__manufacturing_cost', 'remainder__pre_invoice_discount_pct', 'remainder__sold_quantity']])\n",
    "fig.update_layout(title='Distribution of validation set\\'s numerical features after scaling', xaxis_title = 'feature', yaxis_title = 'value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f380c31-31c5-4b0a-86c5-904626d5696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the test data using the same scaler\n",
    "features_test[['remainder__gross_price', 'remainder__manufacturing_cost', 'remainder__pre_invoice_discount_pct', 'remainder__sold_quantity']] = \\\n",
    "scaler.transform(features_test[['remainder__gross_price', 'remainder__manufacturing_cost', 'remainder__pre_invoice_discount_pct', 'remainder__sold_quantity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897393a2-ce4b-44d3-b29e-921c8b7bb96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the distributions of the numerical features in the test set after scaling\n",
    "fig = px.box(features_test[['remainder__gross_price', 'remainder__manufacturing_cost', 'remainder__pre_invoice_discount_pct', 'remainder__sold_quantity']])\n",
    "fig.update_layout(title='Distribution of test set\\'s numerical features after scaling', xaxis_title = 'feature', yaxis_title = 'value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931416fc-9ea9-40c1-a09c-f327cad8a597",
   "metadata": {},
   "source": [
    "__Conclusion:__ \\\n",
    "The following numerical variables are scaled:\n",
    "* gross_price\n",
    "* manufacturing_cost\n",
    "* pre_invoice_discount_pct\n",
    "* sold_quantity\n",
    "\n",
    "The Yeo-Johnson method from scikit-learn library PowerTransformer is used to:\n",
    "* normalize the distribution of skewed features\n",
    "* ensure that all features are on the same scale to prevent any feature from dominating the others\n",
    "* improve the Linear Regression models performance without harming Random Forest or XGBoost performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1c4ddf-0ea7-4253-8517-da5f2018819d",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763ac2a1-6d1c-4728-b5fc-5033b8a8c63a",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_20'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fc6da8-95b7-4951-959c-e399f96a3f2d",
   "metadata": {},
   "source": [
    "The data is prepared for ML models as follows:\n",
    "\n",
    "1. __Data aggregation:__\n",
    "    * the needed columns are selected from the database\n",
    "    * an additional column 'profit_per_unit' is created\n",
    "    * the table 'df' is created with all the necessary columns\n",
    "\n",
    "2. __EDA:__\n",
    "    * the dataframe has no missing values\n",
    "    * the dataframe has 28 duplicate rows, which represent identical orders, but from different customers\n",
    "    * the duplicate values are kept to correctly represent the original dataset\n",
    "    * there are no outliers in the columns 'gross_price' and 'manufacturing_cost'\n",
    "    * there are outliers in 3 columns: 'pre_invoice_discount_pct', 'sold_quantity', 'profit_per_unit'\n",
    "    * outliers represent 16.3% of the data\n",
    "\n",
    "3. __Data split:__\n",
    "    * the source dataset is split into 3 sets: df_train, df_valid, df_test\n",
    "    * the corresponding sets' sizes are: 60%, 20%, 20%\n",
    "    * each set is split into features and target: features_train, target_train, features_valid, target_valid, features_test, target_test\n",
    "    * the target feature is gross profit, stored in the column 'profit_per_unit'\n",
    "\n",
    "4. __Feature engineering:__\n",
    "    * all transformations are performed after splitting the data to prevent data leakage\n",
    "    * the fit_transform() method is used on the training data to transform it and learn the transforming parameters\n",
    "    * the transform() method is used to transform the validation and test data using the same transformer \\\n",
    "      The parameters learned by using the training data help transform the validation and test data.\n",
    "\n",
    "4.1 __Encoding categorical variables__ \\\n",
    "The categorical variables are handled as follows:\n",
    "* the 'date' column is decomposed into features: year, month, day\n",
    "* the original 'date' column is deleted from the features\n",
    "* the column 'region' is encoded using One-Hot encoding method\n",
    "* both calendar and fiscal years are kept to:\n",
    "    * capture different influences on profit\n",
    "    * allow the model to learn from different sources of time-based patterns\n",
    "\n",
    "4.2 __Transforming outliers__ \\\n",
    "The transforming clipping technique is used:\n",
    "* to preserve the correct representation of the data\n",
    "* to limit the effect of the outliers on the ML model\n",
    "\n",
    "The numpy.clip() function is applied to:\n",
    "* the numerical features 'pre_invoice_discount_pct' and 'sold_quanity'\n",
    "* the target variable 'profit_per_unit'\n",
    "* the parameters are used to set the fixed values for capping the lower and upper limits\n",
    "\n",
    "4.3 __Scaling numerical variables__ \\\n",
    "The following numerical variables are scaled:\n",
    "* gross_price\n",
    "* manufacturing_cost\n",
    "* pre_invoice_discount_pct\n",
    "* sold_quantity\n",
    "\n",
    "The Yeo-Johnson method from scikit-learn library PowerTransformer is used to:\n",
    "* normalize the distribution of skewed features\n",
    "* ensure that all features are on the same scale to prevent any feature from dominating the others\n",
    "* improve the Linear Regression models performance without harming Random Forest or XGBoost performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1997f277-1fd9-4479-9f8d-d63016eca186",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd2092-893b-40c9-bd94-8c5374f4c91d",
   "metadata": {},
   "source": [
    "<h2>5.2. Models building and validation</h2> <a id='model_building_ml'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94270a5a-a49a-4e1d-9ddd-00f1d74b0037",
   "metadata": {},
   "source": [
    "The target feature gross profit is a continuous variable.\n",
    "\n",
    "Profit prediction is a regression task.\n",
    "\n",
    "The models best suited for this purpose are regression models, like Linear Regression, Random Forest Regressor, XGBoost.\n",
    "\n",
    "2 regression models are built in this project:\n",
    "1. Linear Regression model\n",
    "2. Random Forest Regressor model\n",
    "\n",
    "The models are trained on the training set. \\\n",
    "The training set is used to build a model, to create connections between x and y, and to fit the parameters of the model.\n",
    "  \n",
    "The quality of different models is investigated by changing hyperparameters. \\\n",
    "The validation set is used to tune hyperparameters of the trained model to improve its quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae053fc4-8ea2-45a1-8466-f7442aba7e6a",
   "metadata": {},
   "source": [
    "<h3>Linear Regression model</h3> <a id='linear_regression_ml'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38927d6e-be0b-4d8b-880f-7726a47f03c0",
   "metadata": {},
   "source": [
    "A linear regression model is used to predict the continuous target variable gross profit as a function of other features. \\\n",
    "This model works well when there's a linear relationship between input features and output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bc6e6e-1aa7-4d48-b441-0972175f6e47",
   "metadata": {},
   "source": [
    "__Model creation and validation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b42149c-29cb-467a-9385-978ad1c2671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model\n",
    "model_linear = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4e2e0-27d2-4faf-b23c-95546ef837c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model on the train dataset using fit() method\n",
    "model_linear.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0110b371-ad4a-4e79-a51a-fe8b76444373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the trained model to predict y values in the validation set\n",
    "predictions_linear = model_linear.predict(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e935ea-afa2-43c2-8297-b44c0ceb1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the model to see how well it fits the data and how accurately it predicts the target variable\n",
    "# checking the models quality on validation set\n",
    "r2 = r2_score(target_valid, predictions_linear).round(4)\n",
    "mae = mean_absolute_error(target_valid, predictions_linear).round(4)\n",
    "mse = mean_squared_error(target_valid, predictions_linear).round(4)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Metrics of the linear regression model:\")\n",
    "print(f\"R2: {r2}, MAE: {mae}, MSE: {mse}, RMSE: {rmse.round(4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b07abb-059d-46ae-9dde-089bd7498bd2",
   "metadata": {},
   "source": [
    "__Evaluation metrics:__\n",
    "\n",
    "_*R (coefficient of determination)*_\n",
    "* measures how well the features predict the target's changes\n",
    "* shows the proportion of the variance in the target variable that is predictable from the input features\n",
    "* doesn't account for overfitting or other potential problems\n",
    "* higher R indicates a better fit\n",
    "\n",
    "R value:\n",
    "* 1: the model explains 100% of the variance in the target\n",
    "* 0: the model does not explain any of the variance\n",
    "* negative: the model is performing worse than a simple mean-based model\n",
    "\n",
    "_*MAE (Mean Absolute Error)*_\n",
    "* shows how accurate the predictions are\n",
    "* measures the average prediction error in the target variable\n",
    "* is not sensitive to large errors\n",
    "* lower MAE indicates a better model: predictions are closer to actual values\n",
    "\n",
    "_*MSE (Mean Squared Error)*_\n",
    "* shows how large the errors are\n",
    "* is the average of the squared differences between predicted and actual values\n",
    "* indicates how far off the model's predictions are from the actual values\n",
    "* is sensitive to large errors\n",
    "* lower MSE indicates a better fit: the errors are smaller\n",
    "\n",
    "_*RMSE (Root Mean Squared Error)*_\n",
    "* shows how close the predicted values are to the actual values\n",
    "* measures the average error size between predicted and actual values\n",
    "* displays the error in the original units of the target variable\n",
    "\n",
    "RMSE value:\n",
    "* low: the models predictions are close to the actual values (better model performance, smaller error)\n",
    "* high: the models predictions are far from the actual values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c998745-15cb-4f57-b85b-3d65e4523854",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371bd97d-3963-4989-9890-b034f6d06ae0",
   "metadata": {},
   "source": [
    "__Hyperparameter tuning__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba14d690-c30f-4f3e-9941-3be9bad55eb7",
   "metadata": {},
   "source": [
    "__The hyperparameter tuning__ is used to improve the model's quality. \\\n",
    "It allows to discover the hyperparameter combination that delivers the best model performance.\n",
    "\n",
    "2 methods for hyperparameter tuning:\n",
    "* grid search\n",
    "* random search\n",
    "\n",
    "__Grid search__\n",
    "* exhaustively searches over the hyperparameter space\n",
    "* a set of hyperparameters is specified\n",
    "* all possible combinations are tried (the model is trained and evaluated for every combination of hyperparameters)\n",
    "* can be computationally expensive\n",
    "\n",
    "__Random Search__\n",
    "* randomly samples a given number of hyperparameter combinations from the grid\n",
    "* is more optimal than grid search as it does not try every combination\n",
    "* can be more efficient when there are a large number of hyperparameters to tune or a large search space\n",
    "* requires more time to execute compared to grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401750e1-3d71-4e63-af42-b658a6b7869c",
   "metadata": {},
   "source": [
    "For standard linear regression:\n",
    "* there are not many hyperparameters to tune\n",
    "* the grid search will be used to tune its hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f96c62-58fd-4790-b5f6-f1d84f4e2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining hyperparameters grid to tune: a dictionary containing hyperparameter values to search over\n",
    "param_grid = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True,False],\n",
    "    'n_jobs': [1,5,10,15,None],\n",
    "    'positive': [True,False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5992f6c9-e2b0-470b-bca8-617be8f9c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up GridSearchCV for Linear Regression\n",
    "# cv=5: 5 times cross-validated grid search over the hyperparameter grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LinearRegression(),\n",
    "    param_grid=param_grid,\n",
    "    cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5491eb17-cfa4-4185-b0fa-f0fc14bb7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting GridSearchCV to the training data\n",
    "grid_search.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0499892c-688d-4390-903b-cbb956104dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing best hyperparameters\n",
    "# best_params_ attribute of the fitted GridSearchCV object shows the best combination of hyperparameters \n",
    "print(\"Best hyperparameters for linear regression model:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8176376-d9cb-4da9-9bcf-2fe1e29fb5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retraining the model on the training set with the best hyperparameters found from Grid Search \n",
    "best_linear_model = LinearRegression(\n",
    "    fit_intercept=grid_search.best_params_['fit_intercept'],\n",
    "    copy_X=grid_search.best_params_['copy_X'],\n",
    "    n_jobs=grid_search.best_params_['n_jobs'],\n",
    "    positive=grid_search.best_params_['positive'])\n",
    "\n",
    "best_linear_model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb32d3d-30e2-4eb0-9c42-41bcc582a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the retrained model on the validation set\n",
    "predictions_grid = best_linear_model.predict(features_valid)\n",
    "grid_r2 = r2_score(target_valid, predictions_grid).round(4)\n",
    "grid_mae = mean_absolute_error(target_valid, predictions_grid).round(4)\n",
    "grid_mse = mean_squared_error(target_valid, predictions_grid).round(4)\n",
    "grid_rmse = np.sqrt(grid_mse)\n",
    "print(\"Metrics of the best linear regression model:\")\n",
    "print(f\"R2: {grid_r2}, MAE: {grid_mae}, MSE: {grid_mse}, RMSE: {grid_rmse.round(4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687efeb0-4317-4f4f-a877-9d9837844d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra:\n",
    "# model interpretation by examining the coefficients to see which features impact gross profit\n",
    "#coefficients = pd.DataFrame(best_linear_model.coef_, features_train.columns, columns=['Coefficient'])\n",
    "#print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adb01da-dda2-4b7e-8d58-58be7532ae43",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "\n",
    "The models quality did not change after hyperparameter tuning.\n",
    "\n",
    "Metrics of the best linear regression model in the validation set:\n",
    "* R2 (coefficient of determination): 0.9684 \\\n",
    "  the model predicts 97% of the target's changes\n",
    "* MAE (Mean Absolute Error): 0.274 \\\n",
    "  the model's predictions are off by 0.274 units from the actual values \\\n",
    "  (the average error size between predicted and true values is 0.274)\n",
    "* MSE (Mean Squared Error): 0.1363 \\\n",
    "  the models predictions are close to the actual values \\\n",
    "  the average squared difference between predicted and actual values is 0.1363 \\\n",
    "  this is a relatively small error given the target variables range (5.31 - 15.41) \\\n",
    "  it suggests the models predictions are quite accurate within that range\n",
    "* RMSE (Root Mean Squared Error): 0.3692 \\\n",
    "  the models predictions deviate by 0.3692 units (in the same units as the target variable) from the actual values \\\n",
    "  (the average error between predicted and true values is 0.374 units) \\\n",
    "  this is a relatively small error compared to the range of the target variable \\\n",
    "  it suggests the model is performing well\n",
    "\n",
    "Comparison of MSE and MAE:\n",
    "* MSE is lower than MAE\n",
    "* this suggests the models errors are generally small and dont have large outliers\n",
    "\n",
    "Comparison of RMSE and MAE:\n",
    "* RMSE is higher than MAE, because RMSE gives more weight to larger errors\n",
    "* this indicates that the model might have some larger errors (outliers)\n",
    "* both MAE and RMSE are relatively small compared to the range of the target variable\n",
    "\n",
    "Comparison of MSE and RMSE:\n",
    "* both MSE and RMSE are relatively small in comparison to the target range\n",
    "* it indicates that the models predictions are close to the actual values, with an error of 0.37 units\n",
    "\n",
    "The model is performing well with fairly small errors.\\\n",
    "The model with the best performance is saved as 'best_linear_model'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b2309-c16d-4fdc-a491-139f564a3c7e",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1795f7-14cc-4a9d-a4dd-4f70775580a5",
   "metadata": {},
   "source": [
    "<h3>Random Forest Regressor model</h3> <a id='random_forest_ml'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edf0a05-c683-4c8d-91a5-68405c4d7027",
   "metadata": {},
   "source": [
    "A Random Forest Regressor model predicts a continuous target variable by using an ensemble of decision trees. \\\n",
    "This model can handle more complex and non-linear relationships, and provide better performance for datasets with many features.\n",
    "\n",
    "This learning algorithm:\n",
    "* is considered to have a higher accuracy\n",
    "* trains multiple independent trees in parallel\n",
    "* the final output is determined by the majority vote of the trees\n",
    "* helps to improve results and avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e96b60-8f3a-4ccc-96ad-79ba04776754",
   "metadata": {},
   "source": [
    "__Model creation and validation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c9f24-8df3-42e7-99d1-6c188656ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model\n",
    "model_forest = RandomForestRegressor(n_estimators=5, random_state=84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042537eb-3da5-4708-a6ce-2e2043273cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "model_forest.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d875d1-d8fe-44b0-abf8-59a9a9ecfb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the trained model to predict y values in the validation set\n",
    "predictions_forest = model_forest.predict(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b301651e-ddc5-40ac-9fd1-5a5aa6cbe9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the model to see how well it fits the data and how accurately it predicts the target variable\n",
    "# checking the models quality on validation set\n",
    "r2_forest = r2_score(target_valid, predictions_forest).round(4)\n",
    "mae_forest = mean_absolute_error(target_valid, predictions_forest).round(4)\n",
    "mse_forest = mean_squared_error(target_valid, predictions_forest).round(4)\n",
    "rmse_forest = np.sqrt(mse_forest).round(4)\n",
    "\n",
    "print(\"Metrics of the random forest regressor model:\")\n",
    "print(f\"R2: {r2_forest}, MAE: {mae_forest}, MSE: {mse_forest}, RMSE: {rmse_forest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f93702a-aedf-4d81-9141-ad7577a803e5",
   "metadata": {},
   "source": [
    "__Hyperparameter tuning__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac620a-2819-4763-870e-a2d1cd866811",
   "metadata": {},
   "source": [
    "Steps to improve the model's quality:\n",
    "* detecting the most important hyperparameter of the learning algorithm\n",
    "* finding the best value for this hyperparameter:\n",
    "    * iterating over different hyperparameter values\n",
    "    * comparing the quality of different model versions\n",
    "    * choosing the model with the best performance\n",
    "\n",
    "The most important hyperparameter of the Random Forest Regressor is n_estimators. \\\n",
    "This hyperparameter sets the number of trees in the forest. \\\n",
    "The quality of the end result is directly proportional to the number of trees, but so is the duration of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342b863-2507-438d-bb27-163242b58fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the best, most optimal number of trees\n",
    "best_est = 0\n",
    "best_r2 = 0\n",
    "for n in range(1, 11):\n",
    "\t# creating a model and setting the number of trees\n",
    "    model = RandomForestRegressor(n_estimators=n, random_state=84)\n",
    "\t# training the model\n",
    "    model.fit(features_train, target_train)\n",
    "    # making predictions\n",
    "    predictions = model.predict(features_valid)\n",
    "\t# calculating r2 on validation set\n",
    "    r2 = r2_score(target_valid, predictions)\n",
    "    if r2 > best_r2:\n",
    "        # saving best r2\n",
    "        best_r2 = r2\n",
    "        # saving number of estimators corresponding to best r2\n",
    "        best_est = n\n",
    "print(\"The optimal number of estimators =\", best_est, \", with coefficient of determination R on validation set:\", best_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be10f6-7f5b-4488-a740-f3b18bd8dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retraining the model with the most optimal hyperparameter n_estimators=10\n",
    "best_forest_model = RandomForestRegressor(n_estimators=10, random_state=84)\n",
    "best_forest_model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a9f33c-3e87-4936-ad93-e333255d7d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the retrained model on the validation set\n",
    "predictions_est = best_forest_model.predict(features_valid)\n",
    "est_r2 = r2_score(target_valid, predictions_est).round(4)\n",
    "est_mae = mean_absolute_error(target_valid, predictions_est).round(4)\n",
    "est_mse = mean_squared_error(target_valid, predictions_est).round(4)\n",
    "est_rmse = np.sqrt(est_mse).round(4)\n",
    "print(\"Metrics of the best random forest regressor model:\")\n",
    "print(f\"R2: {est_r2}, MAE: {est_mae}, MSE: {est_mse}, RMSE: {est_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8042a-d52d-4d33-86f3-9df51aa56369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra\n",
    "# checking feature importance for random forest regressor model\n",
    "# feature_importance = pd.DataFrame(best_forest_model.feature_importances_, features_train.columns, columns=['Importance'])\n",
    "# feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "# print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a34a27f-1458-4900-b5cb-fd6d3b1007ef",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "\n",
    "The models quality slightly changed after hyperparameter tuning:\n",
    "* before (with n=5): R2: 0.9993, MAE: 0.0115, MSE: 0.0032, RMSE: 0.0566\n",
    "* after (with n=10): R2: 0.9993, MAE: 0.0114, MSE: 0.003, RMSE: 0.0548\n",
    "\n",
    "The hyperparameter tuning helped find the optimal number of trees and improved the model's quality. \\\n",
    "The tried number of estimators is from 1 to 10. \\\n",
    "The number of estimators=10 gives the highest quality of the model.\n",
    "\n",
    "Metrics of the best random forest regressor model in the validation set:\n",
    "* R2: 0.9993 \\\n",
    "  the model predicts 99% of the target's changes\n",
    "* MAE: 0.0114 \\\n",
    "  the model's predictions are off by 0.0114 units from the actual values\n",
    "* MSE: 0.003 \\\n",
    "  the models predictions are close to the actual values \\\n",
    "  the average squared difference between predicted and actual values is 0.003\n",
    "* RMSE: 0.0548 \\\n",
    "  the models predictions deviate by 0.0548 units (in the same units as the target variable) from the actual values\n",
    "\n",
    "The model with the best performance is saved as 'best_forest_model'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c462e7ac-0a5c-4de4-99e9-86531a086917",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b4da23-6977-48ea-8ca1-462c6d04267f",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_21'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff79a89-abd4-4979-ae07-328e7f63a619",
   "metadata": {},
   "source": [
    "2 regression models are built in this project:\n",
    "1. Linear Regression model\n",
    "2. Random Forest Regressor model\n",
    "\n",
    "These models are chosen, because:\n",
    "* the target feature gross profit is a continuous variable\n",
    "* profit prediction is a regression task\n",
    "\n",
    "__Linear Regression model:__\n",
    "* to explore the linear relationship between profit and other features\n",
    "* the models quality did not change after hyperparameter tuning\n",
    "* it is performing well with fairly small errors\n",
    "* the model with the best performance is saved as 'best_linear_model'\n",
    "\n",
    "__Random Forest Regressor model:__\n",
    "* to investigate the non-linear relationships between the variables\n",
    "* the models quality slightly improved after hyperparameter tuning\n",
    "* the number of estimators=10 gives the highest quality of the model\n",
    "* the model with the best performance is saved as 'best_forest_model'\n",
    "\n",
    "__Evaluation metrics of the best models:__\n",
    "* linear regression model \\\n",
    "  R2: 0.9684, MAE: 0.274, MSE: 0.1363, RMSE: 0.3692\n",
    "* random forest regressor model \\\n",
    "  R2: 0.9993, MAE: 0.0114, MSE: 0.003, RMSE: 0.0548\n",
    "\n",
    "__Based on the quality on the validation data:__\n",
    "* the best model is the random forest regressor\n",
    "* it outperforms the linear regression model in all metrics\n",
    "\n",
    "The final performance of the random forest regressor model will be checked with the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfdea11-9876-463a-9cb9-218a45c5c78f",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a628800-a183-4d83-b4a5-c6aeb7967d86",
   "metadata": {},
   "source": [
    "<h2>5.3. Testing model</h2> <a id='model_testing_ml'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc60421d-1a94-40f3-a161-cbcfe106c06e",
   "metadata": {},
   "source": [
    "Checking the quality of the best model on the test data.\n",
    "\n",
    "The best model, based on the metrics on the validation data: random forest regressor.\n",
    "\n",
    "The test set is used to:\n",
    "* test the best model\n",
    "* count the number of errors in it\n",
    "* compare the main evaluation metrics with the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba1dfe-3c9f-4e8a-bdd6-b43f833104f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting answers in the training set\n",
    "predictions_train_forest = best_forest_model.predict(features_train)\n",
    "# predicting answers in the test set\n",
    "predictions_test_forest = best_forest_model.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e048f34-4683-43fb-917e-2ec2f4327833",
   "metadata": {},
   "source": [
    "Counting the number of errors in the test set results.\n",
    "\n",
    "Since the target variables range: 5.31 - 15.41:\n",
    "* 10% deviation from the actual value is between 0.5 and 1.5 units\n",
    "* the threshold is set to 1 unit\n",
    "\n",
    "If a prediction is within 1 unit of the actual value, it's not considered an error. \\\n",
    "If a prediction differs from the actual target by more than 1, it's counted as an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba84484c-1b3f-401d-a394-8ff5f27ec1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the absolute errors (residuals)\n",
    "absolute_errors = np.abs(predictions_test_forest - target_test)\n",
    "\n",
    "# defining a threshold\n",
    "threshold = 1\n",
    "\n",
    "# counting how many predictions deviate from the true values by more than 1 unit\n",
    "number_errors = np.sum(absolute_errors > threshold)\n",
    "\n",
    "print(f\"The number of errors (predictions with absolute error > {threshold}): {number_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc2cb4-6cc1-49b8-84e0-1f9b6bacfa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the main metrics of the training and test sets\n",
    "print('Main evaluation metrics of the Random Forest Regressor model')\n",
    "\n",
    "print('R2')\n",
    "print('Training set:', r2_score(target_train, predictions_train_forest).round(4))\n",
    "print('Test set:', r2_score(target_test, predictions_test_forest).round(4))\n",
    "\n",
    "print('MAE')\n",
    "print('Training set:', mean_absolute_error(target_train, predictions_train_forest).round(4))\n",
    "print('Test set:', mean_absolute_error(target_test, predictions_test_forest).round(4))\n",
    "\n",
    "print('MSE')\n",
    "print('Training set:', mean_squared_error(target_train, predictions_train_forest).round(4))\n",
    "print('Test set:', mean_squared_error(target_test, predictions_test_forest).round(4))\n",
    "\n",
    "print('RMSE')\n",
    "print('Training set:', np.sqrt(mean_squared_error(target_train, predictions_train_forest)).round(4))\n",
    "print('Test set:', np.sqrt(mean_squared_error(target_test, predictions_test_forest)).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff99849-9786-44d6-83b1-462067ba97ee",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3> <a id='conclusion_22'></a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6f79e8-b792-47a6-aea7-e2a03430dcea",
   "metadata": {},
   "source": [
    "The quality of the random forest regressor model is checked on the test data.\n",
    "\n",
    "The number of errors (predictions with absolute error > 1): 0\n",
    "\n",
    "__The number of errors__ is calculated as follows:\n",
    "* a deviation margin is based on the target variables range (5.31 - 15.41)\n",
    "* an acceptable deviation margin is set to 10%, or 1 unit difference between the actual and predicted values\n",
    "* more than 10% deviation from the true value is considered as an error\n",
    "\n",
    "__Evaluation metrics of the model:__\n",
    "* on the training set:\n",
    "R2: 0.9999, MAE: 0.0045, MSE: 0.0006, RMSE: 0.0243\n",
    "* on the test set:\n",
    "R2: 0.9992, MAE: 0.0121, MSE: 0.0033, RMSE: 0.0578\n",
    "\n",
    "__R2 (coefficient of determination)__\n",
    "* training set: the model predicts 99,99% of the variation in the target \\\n",
    "  This is almost perfect, suggesting that the model fits the training data very well.\n",
    "* test set: the model predicts 99,92% of the variation in the target \\\n",
    "  This is still an extremely good performance. \\\n",
    "  The small decrease from training to test set is very minor, indicating good generalization to unseen data. \\\n",
    "The model seems to be fitting both the training and test data extremely well, with minimal overfitting.\n",
    "\n",
    "__MAE (Mean Absolute Error)__\n",
    "* training set: the model's predictions are off by 0.0045 units from the actual values\n",
    "* test set: the model's predictions are off by 0.0121 units from the actual values \\\n",
    "The model is very accurate on both the training and test sets. \\\n",
    "The test set error is slightly higher than the training set, which is expected due to natural variation in the data. \\\n",
    "However, the increase is very small, indicating that the model is generalizing well to new data.\n",
    "\n",
    "__MSE (Mean Squared Error)__\n",
    "* training set: the average squared difference between the predicted and actual values is very small: 0.0006\n",
    "* test set: the average squared difference between the predicted and actual values is 0.0033 \\\n",
    "  It is higher than the training MSE, but still relatively small in absolute terms. \\\n",
    "The difference between training and test MSE suggests a small amount of overfitting. \\\n",
    "A larger MSE difference would indicate that there might be larger errors on the test set compared to the training set, \\\n",
    "since MSE is sensitive to large errors due to the squaring of residuals. \\\n",
    "However, the model is still performing very well on the test set, and the test set error is still very low.\n",
    "\n",
    "__RMSE (Root Mean Squared Error)__\n",
    "* training set: the models predictions deviate by 0.0243 units from the actual values\n",
    "* test set: the models predictions deviate by 0.0578 units from the actual values \\\n",
    "  It is larger than the training RMSE, but it is still a very small error in the context of the real-world data. \\\n",
    "The slight increase in RMSE from training to test set suggests that the model is experiencing a small amount of overfitting. \\\n",
    "However, the magnitude of the error is very small, indicating the model is still highly accurate.\n",
    "\n",
    "__Overall:__\n",
    "1. The model performs exceptionally well on the training set, with very small errors in terms of R2, MAE, MSE, and RMSE.\n",
    "2. The model performs almost as well on the test set, with a very slight decrease in performance across all metrics.\n",
    "3. The very small increase in MSE and RMSE from the training to test set suggests a slight overfitting, \\\n",
    "   but this is not a major concern given the overall strong performance.\n",
    "4. The model is highly accurate and generalizes well to unseen data, with minimal overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70868e7a-7fab-4d8e-89a4-445953bdf467",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bbe2c0-b1eb-4e57-8682-6f689abd593c",
   "metadata": {},
   "source": [
    "<h2>ML model summary</h2> <a id='summary_5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21d2e7-999a-4c8f-9387-6e071fd469fb",
   "metadata": {},
   "source": [
    "__Goal:__ create a model for profit prediction based on the available features.\n",
    "\n",
    "__Target:__ gross profit.\n",
    "\n",
    "__Task type:__ a regression task since the target is a continuous variable.\n",
    "\n",
    "__Chosen learning algorithms:__\n",
    "* Linear Regression\n",
    "* Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f14301e-4962-4a92-9d31-71d3d521bf64",
   "metadata": {},
   "source": [
    "__The data is prepared as follows:__\n",
    "* the table 'df' is created with the columns selected from the database, and the calculated column 'profit_per_unit'\n",
    "* the dataframe has no missing values\n",
    "* the duplicate values are kept to correctly represent the original dataset\n",
    "* 3 columns have outliers: 'pre_invoice_discount_pct', 'sold_quantity', 'profit_per_unit', which represent 16.3% of the data\n",
    "* the dataset is split into 3 sets: df_train, df_valid, df_test, in the 3:1:1 ratio\n",
    "* each set is split into features and target\n",
    "* the target feature is gross profit, stored in the column 'profit_per_unit'\n",
    "* all transformations are performed after splitting the data to prevent data leakage\n",
    "* the categorical variables are handled as follows:\n",
    "    * the 'date' column is decomposed into features: year, month, day\n",
    "    * the original 'date' column is deleted from the features\n",
    "    * the column 'region' is encoded using One-Hot encoding method\n",
    "    * both calendar and fiscal years are kept for ML purposes\n",
    "* the outliers are transformed:\n",
    "    * in the numerical features 'pre_invoice_discount_pct' and 'sold_quanity', and in the target variable 'profit_per_unit'\n",
    "    * by using the numpy.clip()function and its parameters to set the fixed values for capping the lower and upper limits\n",
    "* the numerical variables are scaled:\n",
    "    * in the columns 'gross_price', 'manufacturing_cost', 'pre_invoice_discount_pct', 'sold_quantity'\n",
    "    * by using the Yeo-Johnson method from scikit-learn library PowerTransformer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dd9400-505e-49f4-89dd-fa6aa1c49ce4",
   "metadata": {},
   "source": [
    "__2 regression models are built:__\n",
    "\n",
    "1. Linear Regression model\n",
    "    * to explore the linear relationship between profit and other features\n",
    "    * the models quality did not change after hyperparameter tuning\n",
    "    * the model with the best performance is saved as 'best_linear_model'\n",
    "    * evaluation metrics: R2: 0.9684, MAE: 0.274, MSE: 0.1363, RMSE: 0.3692\n",
    "2. Random Forest Regressor model\n",
    "    * to investigate the non-linear relationships between the variables\n",
    "    * the models quality slightly improved after hyperparameter tuning\n",
    "    * the number of estimators=10 gives the highest quality of the model\n",
    "    * the model with the best performance is saved as 'best_forest_model'\n",
    "    * evaluation metrics: R2: 0.9993, MAE: 0.0114, MSE: 0.003, RMSE: 0.0548\n",
    "* the training set is used to build the models, to create connections between x and y, and to fit the parameters of the models\n",
    "* the validation set is used to check the quality of different models, and to tune their hyperparameters to improve the quality\n",
    "* based on the quality on the validation data:\n",
    "    * the best model is the random forest regressor\n",
    "    * it outperforms the linear regression model in all metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee91d3-c043-406b-8990-2dd9d976aba8",
   "metadata": {},
   "source": [
    "__The Random Forest Regressor model's test:__\n",
    "* the test set is used to check the quality of the model\n",
    "* the number of errors: 0\n",
    "    * __assumption__: an error is more than 10% deviation from the true value\n",
    "    * 1 unit (10%) difference between the actual and predicted values is an acceptable deviation margin\n",
    "* evaluation metrics:\n",
    "    * on the training set:\n",
    "      R2: 0.9999, MAE: 0.0045, MSE: 0.0006, RMSE: 0.0243\n",
    "    * on the test set:\n",
    "      R2: 0.9992, MAE: 0.0121, MSE: 0.0033, RMSE: 0.0578\n",
    "* the model performs exceptionally well on the training set, with very small errors\n",
    "* the model performs almost as well on the test set, with a very slight decrease in performance across all metrics\n",
    "* the very small increase in MSE and RMSE from the training to test set suggests a slight overfitting\n",
    "* the model is highly accurate and generalizes well to unseen data, with minimal overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d411e688-e7bf-4909-b8b6-e993bba42eae",
   "metadata": {},
   "source": [
    "__*Conclusions:*__\n",
    "1. The best model for profit forecast: Random Forest Regressor model, saved as 'best_forest_model'.\n",
    "2. The most optimal number of estimators is 10.\n",
    "3. The model predicts 99,92% of the variation in the target.\n",
    "4. It is a highly accurate model which generalizes well to unseen data, with minimal overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f3024f-9896-47da-8612-66b850d135ec",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d6a25-8054-4617-a98f-cc049206d6a8",
   "metadata": {},
   "source": [
    "<h2>Project summary</h2> <a id='project_summary'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed905e0-51ef-4be3-8492-3fb44fc32ddb",
   "metadata": {},
   "source": [
    "__The goal:__ assess the financial health of the AtliQ Hardware company.\n",
    "\n",
    "__Data description:__\n",
    "* a database in the SQLite format\n",
    "* lack of information on all product categories\n",
    "\n",
    "__Assumptions made:__\n",
    "1. net revenue = gross revenue - discounts \\\n",
    "   Net revenue calculation accounts only for discounts, since the dataset has no information on refunds, returns and allowances.\n",
    "2. 'fiscal_year' = 'cost_year' \\\n",
    "   To be able to merge tables with manufacturing costs and sales data to calculate gross profit.\n",
    "\n",
    "__Metrics and ratios__ used to assess the company's financial health:\n",
    "* gross revenue\n",
    "* gross revenue growth rate\n",
    "* net revenue\n",
    "* net revenue growth rate\n",
    "* gross profit\n",
    "* gross margin\n",
    "* segment (geographic) margin\n",
    "\n",
    "__Key financial indicators:__\n",
    "* total gross revenue is 86555909\n",
    "* total net revenue 66312380\n",
    "* total gross profit: 40622742\n",
    "* total gross margin: 61%\n",
    "\n",
    "__Gross and net revenues__\n",
    "* They grow every year in every region, except for LATAM in 2021.\n",
    "* The growth rate is decreasing over time.\n",
    "* The most profitable region is APAC (Asia-Pacific).\n",
    "* The least profitable region is LATAM (Latin America).\n",
    "* The total revenues of NA (North America) and EU (European Union) regions are approximately the same.\n",
    "* Over time, the market has changed only in EU and NA regions.\n",
    "  Before 2021 NA has higher revenue than EU. From 2021 the revenue of EU starts to be higher than in NA.\n",
    "\n",
    "__Gross profit__\n",
    "* It follows the same regional and yearly patterns as gross and net revenues.\n",
    "* The net-to-gross revenue ratio and profit to gross revenue ratio is almost the same across years and regions.\n",
    "\n",
    "__Gross margin__\n",
    "* It is stable over time (61%), except for 2019 (62%).\n",
    "* It is the same in all regions (61%), except for LATAM (60%).\n",
    "* A gross margin of 61% is considered healthy: around 61% of the revenue is left over after paying direct costs.\n",
    "\n",
    "__Segment (regional) margin__\n",
    "* The profit margin remains stable across all regions, fluctuating between 6062% throughout the years.\n",
    "* The faster growth of manufacturing costs than net revenue:\n",
    "    * caused the gross margin decline in all regions in 2020\n",
    "    * had the biggest impact on LATAM and APAC regions in both 2020 and 2021\n",
    "      It can be that in these years LATAM and APAC were mostly buying products with high manufacturing costs.\n",
    "    * influenced the gross margin of EU in 2019\n",
    "\n",
    "__The company has healthy metrics across years and regions.__ \\\n",
    "__Each year from the total revenue__ on average:\n",
    "* 61% is left over as gross margin after paying direct costs\n",
    "* 47% is left over as gross profit\n",
    "* 53% is spent:\n",
    "  * 23% on discounts\n",
    "  * 30% on manufacturing costs\n",
    "\n",
    "Across years and regions, __the ratios between revenues and profit__ are on average the same:\n",
    "* net revenue to gross revenue: 76%\n",
    "* gross profit to gross revenue: 47%\n",
    "* gross profit to net revenue: 61% \n",
    "\n",
    "__Hypothesis testing__\n",
    "* Hypothesis: rising manufacturing costs negatively impact the companys gross profit margins.\n",
    "* There is a statistically significant negative linear relationship between manufacturing costs and gross profit margins.\n",
    "* But this relationship is statistically weak: for every 1 unit increase in manufacturing cost, margin decreases by 0.0009 units.\n",
    "* So rising manufacturing costs do negatively affect the companys gross profit margins, but this impact is not big.\n",
    "\n",
    "__ML model__\n",
    "* A regression model is created for profit forecast: 'best_forest_model'.\n",
    "* The model predicts 99,92% of the variation in the target.\n",
    "* It is a highly accurate model which generalizes well to unseen data, with minimal overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bfe38e-ad9e-4004-b912-9e5f16c8cc56",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223dcd11-5a19-46b6-9e62-1e4ace4d34f3",
   "metadata": {},
   "source": [
    "<h2>Conclusions and recommendations</h2> <a id='recommendations'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5a9b8-8793-45a3-95f6-ec812f5f3c8e",
   "metadata": {},
   "source": [
    "__The profit-to-revenue ratios__ remain consistent across years and regions, suggesting the following:\n",
    "* a highly standardized financial structure with fixed parameters that don't change year-to-year or region-to-region\n",
    "* the costs are structured similarly across all regions:\n",
    "    * a consistent discount rate\n",
    "    * a uniform pricing strategy\n",
    "    * similar levels of direct costs related to manufacturing\n",
    "\n",
    "__Benefits of the fixed financial strategy:__\n",
    "* predictability \\\n",
    "The stable and consistent relationships between financial metrics across time and geography can suggest that this is a highly predictable business model. \\\n",
    "This can be beneficial for forecasting and strategic planning.\n",
    "\n",
    "__Disadvantages of the fixed financial strategy:__\n",
    "* missed opportunities for optimization \\\n",
    "Difficult to discover regional or yearly differences to optimize the business performance (such as adjusting pricing, discounts, or costs) due to the lack of variation.\n",
    "* a lack of flexibility in the pricing or cost structure \\\n",
    "Future changes in the market (like rising costs, inflation, or shifts in customer preferences) could potentially disrupt this predictability.\n",
    "\n",
    "__*Recommendation 1:*__ \\\n",
    "If the company wants to explore growth or expansion, this predictability can provide a solid base for understanding how changes in gross revenue will impact net revenue and gross profit. \\\n",
    "The created regression model 'best_forest_model' can be used for profit forecast.\n",
    "\n",
    "__*Recommendation 2:*__ \\\n",
    "It could be useful to test new financial models by introducing slight changes to variables like discount rates or gross prices to see how the financial metrics respond.\n",
    "\n",
    "__*Recommendation 3:*__ \\\n",
    "It can be worth investigating if there are areas where the company can tailor its strategies for different regions or market conditions, which could lead to improved margins or more profitable revenue streams.\n",
    "\n",
    "__*Recommendation 4:*__ \\\n",
    "There is a trend that the gross margin declines when manufacturing costs grow faster than net revenue. \\\n",
    "To improve profitability during such periods, consider:\n",
    "* reducing manufacturing costs\n",
    "* increasing net revenue by:\n",
    "    * raising prices\n",
    "    * increasing sales volume\n",
    "    * lowering discounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037c53d7-a658-4525-8e09-489d731e962e",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4100a163-e2c5-4319-9a29-f59b914e0074",
   "metadata": {},
   "source": [
    "<h2>Regional trends</h2> <a id='regional_trends'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f254d2d-8194-460d-b5c6-70e4228d260e",
   "metadata": {},
   "source": [
    "__APAC (Asia-Pacific):__\n",
    "* APAC stands out as the fastest-growing region, especially in profit and revenue.\n",
    "* It consistently maintains high margins (around 61%62%), with a slight dip in 2021 to 61%.\n",
    "* The growth trend from 2018 to 2022 is very strong, with profit nearly tripling from 2019 to 2022 and revenue growing by about 5 times over the same period.\n",
    "* This region might be benefiting from a combination of market expansion and increasing demand.\n",
    "\n",
    "__EU (European Union):__\n",
    "* The EU region's performance is solid, with a consistent margin and steady growth in both revenue and profit.\n",
    "* Revenue and profit both more than quadrupled from 2018 to 2022, but the increase is more linear.\n",
    "* The growth trajectory is not as sharp as APAC's, but it is stable and indicative of a healthy market presence.  \n",
    "\n",
    "__NA (North America):__\n",
    "* NA had stable margins around 60.8% for 3 years. \n",
    "* From 2021 it starts to grow, ending in 2022 with the highest margin across all regions at 62.0%.\n",
    "* This region shows healthy growth but has a more moderate increase in revenue and profit compared to APAC and EU.\n",
    "\n",
    "__LATAM (Latin America):__\n",
    "* LATAM, while growing, is a smaller region in terms of absolute numbers.\n",
    "* It had the lowest margins since 2020, with a further decrease in 2021 to 59.8%.\n",
    "* In 2022 it grew to 60.6%, still remaining the lowest amoung the regions.\n",
    "* The overall growth from 2018 to 2022 is still positive, but at a slower rate compared to other regions.\n",
    "* It might be facing local market challenges or slower growth opportunities.\n",
    "\n",
    "__Overall:__\n",
    "While all regions show growth, APAC is the standout performer in terms of both profit and revenue increases, \\\n",
    "whereas EU, NA, and LATAM all show more stable, but less explosive trajectories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9e2cc-0a9a-418d-b083-a3afb335cf49",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea105b7-0a79-4e75-849f-50ee4e0493c8",
   "metadata": {},
   "source": [
    "<h2>Recommendations by region</h2> <a id='recommendations_region'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a19c248-ec0e-44c5-9499-e565a4555285",
   "metadata": {},
   "source": [
    "__APAC (Asia-Pacific):__\n",
    "* APAC is the high-growth region, with significant improvements in both revenue and profit year on year.\n",
    "* APAC should be prioritized for expansion, given its rapid growth.\n",
    "* Understanding the drivers behind its success (such as market expansion, new product offerings, or operational efficiencies) could be crucial for replicating this success in other regions.\n",
    "\n",
    "__EU (European Union):__\n",
    "* EU has steady growth and consistent margins, contributing reliably but without the explosive growth seen in APAC.\n",
    "* EU may be targeted for steady, sustainable growth strategies that capitalize on its stable performance.\n",
    "\n",
    "__NA (North America):__\n",
    "* NA maintains strong profitability and revenue but at a more moderate pace compared to APAC.\n",
    "* NA seems to have opportunities for optimization, particularly in maintaining margins while pursuing higher growth.\n",
    "\n",
    "__LATAM (Latin America):__\n",
    "* LATAM's growth is slower and more volatile, with occasional setbacks, but still showing an upward trend overall.\n",
    "* LATAM could benefit from analyzing its downturns to identify and address the factors behind its slower growth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa95064-f198-4dfc-a672-4df2434f0d21",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
